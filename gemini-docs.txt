Gerar uma chave da API Gemini
Receba uma chave da API Gemini e faça sua primeira solicitação de API em minutos.
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Conheça os modelos
2.5 Pro
Nosso modelo de pensamento mais poderoso, com recursos para raciocínio complexo e muito mais
2.0 Flash
Nosso modelo multimodal mais recente, com recursos de última geração e recursos aprimorados
2.0 Flash-Lite
Nosso modelo multimodal mais rápido e econômico com ótimo desempenho para tarefas de alta frequência
Explore a API
Geração de imagens nativas
Gere e edite imagens altamente contextuais de forma nativa com o Gemini 2.0 Flash.
Explorar o contexto longo
Insira milhões de tokens nos modelos do Gemini e extraia insights de imagens, vídeos e documentos não estruturados.
Gerar saídas estruturadas
Limite o Gemini para responder com JSON, um formato de dados estruturado adequado para processamento automatizado.
Modelos
/
Gemini API reference
A API Gemini permite acessar os modelos generativos mais recentes do Google. Esta referência de API fornece informações detalhadas sobre as classes e os métodos disponíveis nos SDKs da API Gemini. Escolha um idioma e siga as etapas de configuração para começar a criar.
Instalar a biblioteca da API Gemini
Observação: estamos lançando um novo conjunto de bibliotecas da API Gemini, o SDK do Google Gen AI.
Usando o Python 3.9+, instale o pacote google-genai usando o seguinte comando pip:
pip install -q -U google-genai
Faça sua primeira solicitação
Use o método generateContent para enviar uma solicitação à API Gemini.
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash", contents="Explain how AI works in a few words"
)
print(response.text)
A seguir
Se você está começando a usar a API, confira os guias a seguir, que vão ajudar a entender o modelo de programação da API Gemini:
Guia de início rápido da API Gemini
Guia de modelos do Gemini
Design de comandos
Você também pode consultar os guias de recursos, que apresentam diferentes recursos da API Gemini e fornecem exemplos de código:
Geração de texto
Cache de contexto
Embeddings
Ajuste
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Preços da API Gemini Developer
Pré-lançamento do Gemini 2.5 Pro
Gemini 2.0 Flash
Gemini 2.0 Flash-Lite
Gemma 3
O "nível sem custo financeiro" da API Gemini é oferecido pelo serviço da API com limites de taxa mais baixos para fins de teste. O uso é totalmente sem custo financeiro em todos os países disponíveis. O "nível pago" da API Gemini tem limites de taxa mais altos, mais recursos e diferentes formas de processamento de dados.
Fazer upgrade para o nível pago
Pré-lançamento do Gemini 2.5 Pro
Testar no Google AI Studio
Nosso modelo multiuso de última geração, que se destaca em programação e tarefas de raciocínio complexas.
Os modelos de pré-lançamento podem mudar antes de se tornarem estáveis e disponíveis para todos.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo, use "gemini-2.5-pro-exp-03-25" US$ 1,25, comandos <= 200 mil tokens
US$2,50, comandos > 200 mil tokens
Preço de saída (incluindo tokens de pensamento) Sem custo, use "gemini-2.5-pro-exp-03-25" US$ 10,00, comandos <= 200 mil tokens
US$15,00, comandos > 200 mil
Preço do armazenamento em cache de contexto Indisponível Indisponível
Embasamento com a Pesquisa Google Sem custo financeiro, até 500 RPD 1.500 RPD (sem custo financeiro), depois US $35 / 1.000 solicitações
Usado para melhorar nossos produtos Sim Não
Gemini 2.0 Flash
Nosso modelo multimodal mais equilibrado com ótimo desempenho em todas as tarefas, com uma janela de contexto de 1 milhão de tokens e criado para a era dos agentes.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,10 (texto / imagem / vídeo)
US$0,70 (áudio)
Preço de saída Sem custo financeiro US$ 0,40
Preço do armazenamento em cache de contexto Sem custo financeiro US$ 0,025 / 1.000.000 tokens (texto/imagem/vídeo)
US$0,175 / 1.000.000 tokens (áudio)
Disponível em 15 de abril de 2025
Armazenamento em cache de contexto Sem custo financeiro, até 1.000.000 de tokens de armazenamento por hora
Disponível em 15 de abril de 2025 US$ 1,00 / 1.000.000 tokens por hora
Disponível em 15 de abril de 2025
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Sem custo financeiro, até 500 RPD 1.500 RPD (sem custo financeiro), depois US $35 / 1.000 solicitações
Usado para melhorar nossos produtos Sim Não
Gemini 2.0 Flash-Lite
Nosso modelo menor e mais econômico, criado para uso em grande escala.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,075
Preço de saída Sem custo financeiro US$ 0,30
Preço do armazenamento em cache de contexto Disponível em 15 de abril de 2025 Disponível em 15 de abril de 2025
Armazenamento em cache de contexto Disponível em 15 de abril de 2025 Disponível em 15 de abril de 2025
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível Indisponível
Usado para melhorar nossos produtos Sim Não
Nosso modelo de geração de imagens de última geração, disponível para desenvolvedores no nível pago da API Gemini.
Nível gratuito Nível pago, por imagem em USD
Preço da imagem Indisponível US$ 0,03
Usado para melhorar nossos produtos Sim Não
Gemma 3
Nosso modelo aberto leve e de última geração, criado com a mesma tecnologia que alimenta nossos modelos Gemini.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro Indisponível
Preço de saída Sem custo financeiro Indisponível
Preço do armazenamento em cache de contexto Sem custo financeiro Indisponível
Armazenamento em cache de contexto Sem custo financeiro Indisponível
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível Indisponível
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Flash
Nosso modelo multimodal mais rápido, com ótimo desempenho para tarefas diversas e repetitivas e uma janela de contexto de 1 milhão de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,075, comandos <= 128 mil tokens
US$0,15, comandos > 128 mil tokens
Preço de saída Sem custo financeiro US$ 0,30, comandos <= 128 mil tokens
US$0,60, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Sem custo financeiro, até 1 milhão de tokens de armazenamento por hora US$ 0,01875, comandos <= 128 mil tokens
US$0,0375, comandos > 128 mil tokens
Armazenamento em cache de contexto Sem custo financeiro US$ 1,00 por hora
Preço de ajuste Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro. Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro.
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Flash-8B
Nosso modelo mais pequeno para casos de uso de inteligência mais simples, com uma janela de contexto de 1 milhão de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,0375, comandos <= 128 mil tokens
US$0,075, comandos > 128 mil tokens
Preço de saída Sem custo financeiro US$ 0,15, comandos <= 128 mil tokens
US$0,30, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Sem custo financeiro, até 1 milhão de tokens de armazenamento por hora US$ 0,01, solicitações <= 128 mil tokens
US$0,02, solicitações > 128 mil tokens
Armazenamento em cache de contexto Sem custo financeiro US$ 0,25 por hora
Preço de ajuste Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro. Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro.
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Pro
Testar no Google AI Studio
Nosso modelo de série Gemini 1.5 com a maior inteligência, com uma janela de contexto de 2 milhões de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 1,25, solicitações de até 128 mil tokens
US$2,50, solicitações de mais de 128 mil tokens
Preço de saída Sem custo financeiro US$ 5,00, comandos <= 128 mil tokens
US$10,00, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Indisponível US$ 0,3125, comandos <= 128 mil tokens
US$0,625, comandos > 128 mil tokens
Armazenamento em cache de contexto Indisponível US$ 4,50 por hora
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Text Embedding 004
Nosso modelo de embedding de texto de última geração.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro Indisponível
Preço de saída Sem custo financeiro Indisponível
Preço de ajuste Indisponível Indisponível
[*] O uso do Google AI Studio é sem custo financeiro em todas as regiões disponíveis. Consulte as Perguntas frequentes sobre faturamento para mais detalhes.
[**] Os preços podem ser diferentes dos listados aqui e dos oferecidos na Vertex AI. Para conferir os preços da Vertex, consulte a página de preços da Vertex AI.
[***] Se você estiver usando a recuperação dinâmica para otimizar custos, apenas as solicitações que contêm pelo menos um URL de suporte de embasamento da Web na resposta são cobradas pela integração com a Pesquisa Google. Os custos do Gemini sempre se aplicam. Os limites de taxa estão sujeitos a alterações.
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

Modelos
/
Documentos
Confira o repositório do Gemma Cookbook para ver exemplos de geração e ajuste. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Gemma 3
Uma coleção de modelos abertos leves e de última geração criados com base na mesma pesquisa e tecnologia que alimentam nossos modelos do Gemini 2.0
Testar o Gemma 3 no Google AI Studio
Processar tarefas complexas
A janela de contexto de 128 mil tokens do Gemma 3 permite que seus aplicativos processem e entendam grandes quantidades de informações, possibilitando recursos de IA mais sofisticados.
Alcance o mundo inteiro instantaneamente
Com o Gemma 3, você se comunica com facilidade em vários idiomas. Desenvolva aplicativos que alcancem um público global, com suporte para mais de 140 idiomas.
Entender palavras e imagens
Crie facilmente aplicativos que analisam imagens, textos e vídeos, abrindo novas possibilidades para aplicativos interativos e inteligentes.
Leia o blog
Crie com o melhor modelo de aceleração única do mundo
Começar a criar com o Gemma
Guia do Gemma
Exemplos práticos e tutoriais sobre os modelos abertos do Google
Conheça os notebooks
Hugging face
Comece a usar o Gemma com a biblioteca Transformers do Hugging Face.
Keras
Use o Keras com um back-end JAX para ajustar o Gemma com o LoRA e o treinamento distribuído de paralelismo de modelo em TPUs.
Ollama
Execute a inferência localmente em um modelo do Gemma usando o Ollama.
Biblioteca Python do Gemma
Converse e ajuste o Gemma com a nova biblioteca Gemma Python.
Pesquisa avançada com o Gemma
TxGemma
NEW
Uma coleção de modelos abertos para acelerar o desenvolvimento de tratamentos.
Download from Hugging Face
ShieldGemma 2
NOVO
O ShieldGemma 2 oferece uma solução pronta para a segurança de imagens, gerando rótulos em três categorias de segurança.
Fazer o download do Kaggle
PaliGemma 2
NOVO
O PaliGemma 2 traz recursos de visão facilmente ajustáveis aos modelos de linguagem Gemma 2, permitindo uma ampla gama de aplicativos que combinam a compreensão de texto e imagem.
Fazer o download do Kaggle
DataGemma
Os DataGemma são os primeiros modelos abertos projetados para conectar LLMs a dados reais extraídos do Data Commons do Google.
Fazer o download do Kaggle
Escopo do Gemma
O Gemma Scope oferece aos pesquisadores uma transparência sem precedentes nos processos de tomada de decisão dos nossos modelos do Gemma 2.
Fazer o download do Hugging Face
Slide atual: 1
Slide atual: 2
Slide atual: 3
Slide atual: 4
Slide atual: 5
Visualizar comparativos de mercado do Gemma 3
MMLU-Pro
LiveCodeBench
Bird-SQL
GPQA Diamond
SimpleQA
Embasamento de FATOS
MATH
HiddenMath
MMMU
100%
75%
50%
25%
0%
Gemma 2
2b
15,6
9b
46,8
27b
56,9
Gemma 3
1b
14.7
4b
43,6
12b
60,6
27b
67,5
*Consulte o relatório técnico para saber mais sobre a performance com outras metodologias. Leia o relatório técnico
Conheça o Gemmaverse
Escolher o destino da implantação
Dispositivo móvel
Implantar no dispositivo com a IA de borda do Google
Implante diretamente nos dispositivos para funcionalidade off-line com baixa latência. Ideal para aplicativos que exigem privacidade e capacidade de resposta em tempo real, como apps para dispositivos móveis, dispositivos de IoT e sistemas embarcados.
Implantar o app para dispositivos móveis
Web
Integração perfeita a aplicativos da Web
Melhore seus sites e serviços da Web com recursos avançados de IA, como recursos interativos, conteúdo personalizado e automação inteligente.
Implantar a Web
Cloud
Escalone sem esforço com a infraestrutura em nuvem
Aproveite a escalabilidade e a flexibilidade da nuvem para lidar com implantações em grande escala, cargas de trabalho exigentes e aplicativos complexos de IA.
Deploy Cloud
Como acelerar a pesquisa acadêmica com créditos do Google Cloud
Termos de Serviço
Privacidade
Português – Brasil

Modelos
/
Documentos
Visão geral
Começar
Lançamentos
Modelos
Gemma 3
CodeGemma
PaliGemma 2
ShieldGemma 2
Executar o Gemma
Visão geral
Ollama
Biblioteca do Gemma
Keras
PyTorch
Gemma.cpp
Gemini API
Comandos e instruções do sistema
Configuração do Gemma
Recursos
Chamadas de função
Solicitação com dados visuais
Guias de ajuste
Visão geral
Ajustar usando LoRA e Keras
Ajustar usando a biblioteca Gemma
Ajustar usando o Hugging Face Transformers e o QLoRA
Ajustar a visão usando Transformers do Hugging Face e QLoRA
Ajuste distribuído usando o Keras
Guias de inscrição
Assistente pessoal de programação
Assistente de e-mail comercial
Tarefas de idioma falado
Chatbot usando Python
Gerador de memes
Guias de implantação
Web
Dispositivos móveis
Google Cloud
LangChain
Pesquisa e ferramentas
RecurrentGemma
DataGemma
Telescópio Gemma
Gemma-APS
Comunidade
Gemmaverse
Discord
Jurídico
Termos de Uso
Uso proibido
Confira o repositório do Gemma Cookbook para ver exemplos de geração e ajuste. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemma
Documentos
Isso foi útil?
Envie comentários
Visão geral dos modelos Gemma
Nesta página
Modelos pré-treinados e ajustados por instrução
Próximas etapas
O Gemma é uma família de modelos abertos, leves e de última geração criados a partir da mesma pesquisa e tecnologia usadas para criar modelos do Gemini. Desenvolvido pelo Google DeepMind e outras equipes do Google, o Gemma recebe o nome de a palavra latina gemma, que significa "pedra preciosa". Os pesos do modelo Gemma são com ferramentas de desenvolvimento que promovem a inovação, a colaboração e a uso responsável da inteligência artificial (IA).
Os modelos Gemma estão disponíveis para execução aplicativos e no hardware, dispositivos móveis ou serviços hospedados. Você também pode personalizar esses modelos usando técnicas de ajuste para que se sobressaiam realizar tarefas específicas que importam para você e seus usuários. Desenho de modelos Gemma inspiração e linhagem tecnológica da família de modelos Gemini e são para a comunidade de desenvolvimento de IA ampliar e ir mais além.
Pronto para começar? Comece a usar os modelos do Gemma.
Modelos pré-treinados e ajustados por instrução
É possível modificar o comportamento dos modelos Gemma com treinamento adicional para que o modelo tenha um desempenho melhor em tarefas específicas. Esse processo é chamado de modelo ajuste e, embora essa técnica melhore a capacidade de um modelo de realizar para tarefas direcionadas, isso também pode piorar o modelo em outras tarefas. Para Por isso, os modelos Gemma estão disponíveis tanto nos modelos ajustados por instrução versões pré-treinadas:
Ajuste por instruções (TI): essas versões do modelo são treinadas com interações de linguagem humana e podem responder a entradas de conversa, semelhantes a um chatbot.
Pré-treinado (PT): essas versões do modelo não são treinadas tarefas ou instruções específicas além do conjunto de treinamento de dados principais do Gemma. Você não devem implantar esses modelos em aplicativos sem realizar sintonização.
Próximas etapas
Comece sua jornada na criação de aplicativos com o Gemma com o Guia para começar a usar o Gemma.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2024-08-05 UTC.
Termos de Serviço
Privacidade
Português – Brasil

Modelos
/
Documentos
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Este é o Gemmaverse
Conheça os modelos Gemma criados pela comunidade
Estudos de caso em destaque
ROBOFLOW e PaliGemma 2
O objetivo da Roboflow é melhorar a visão computacional para uso do consumidor e da empresa com os fluxos de trabalho de IA, totalmente integrados à PaliGemma.
Saiba mais
INSAIT: BgGPT
O LLM líder na Bulgária com o Gemma 2
Saiba mais
NEXA AI: OmniAudio
Um modelo de linguagem de áudio para aplicativos de borda
Saiba mais
AI Singapore: SEA-LION
Tornando a IA mais inclusiva para os idiomas do Sudeste Asiático com o Gemma 2
Saiba mais
Como aproveitar a comunicação global
Conheça as variantes do Gemma criadas pela comunidade
Saiba mais sobre o Hugging Face
PRINCETON-NLP/GEMMA-2-9B-IT-SIMPO
Um derivado do Gemma 2 9B otimizado para o aprendizado de preferências pelo SimPO.
UNSLOTH/GEMMA-2-9B-IT-BNB-4BIT
O Unsloth aumenta a capacidade do Gemma 2 com quantização de 4 bits, oferecendo ajustes mais rápidos e uso reduzido de memória.
UCLA-AGI/GEMMA-2-9B-IT-SPPO-ITER3
Um modelo do Gemma 2 desenvolvido usando a otimização de preferência de autojogo.
AIDC-AI/OVIS1.6-GEMMA2-9B
Um modelo de linguagem grande multimodal de 10,2 bilhões de parâmetros para processamento e geração de imagens e textos.
RTZR/KO-GEMMA-2-9B-IT
Um modelo Gemma 2 em coreano ajustado para conversa e feedback humano.
LEMON07R/GEMMA-2-ATARAXY-9B
Mesclagem do Gemma 2, o texto criativo mais bem classificado, que combina o SimPO e o Gutenberg.
ALPHA-VLLM/LUMINA-IMAGE-2.0
Um modelo generativo de imagem eficiente criado com o codificador de texto do Gemma 2 e um VAE.
TELUGU-LLM-LABS/INDIC-GEMMA-2B-FINETUNED-SFT-NAVARASA-2.0
Um modelo Gemma ajustado para seguir instruções em vários idiomas índicos.
Participe da nossa comunidade Gemma
Converse, compartilhe ideias e faça conexões instantâneas no nosso canal #gemma do Google Developer Discord.
Chat agora
Acesse a ficha do modelo, confira notebooks interativos e participe das discussões da comunidade.
Participar do Kaggle
Termos de Serviço
Privacidade
Português – Brasil

Soluções
/
Português – Brasil
Fazer login
Borda de IA do Google
MediaPipe
LiteRT
Simulador de modelos
Mais
Conheça o LiteRT: o ambiente de execução de alto desempenho do Google para IA no dispositivo, antes conhecido como TensorFlow Lite.
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Implantar a IA em aplicativos para dispositivos móveis, Web e incorporados
Ferramentas e frameworks que alimentam os apps do Google
Conheça toda a pilha de IA de ponta, com produtos em todos os níveis, de APIs de pouco código a bibliotecas de aceleração específicas de hardware.
IA generativa
Integre modelos de imagem e linguagem generativa diretamente aos seus apps com APIs prontas para uso.
Vision
Conheça uma grande variedade de tarefas de visão que abrangem segmentação, classificação, detecção, reconhecimento e pontos de referência do corpo.
Texto e áudio
Classifique texto e áudio em várias categorias, incluindo idioma, sentimento e suas próprias categorias personalizadas.
PRIMEIROS PASSOS
Documentação do app Tarefas
Encontre todas as tarefas do MediaPipe com pouco código prontas para uso com documentação e exemplos de código.
Tarefas de IA generativa
Execute LLMs e modelos de difusão na borda com nossas tarefas de IA generativa do MediaPipe.
Testar demonstrações
Conheça nossa biblioteca de tarefas do MediaPipe e teste-as.
Documentação do Model Maker
Personalize os modelos nas nossas tarefas do MediaPipe com seus próprios dados.
Começar
Vários frameworks
Converta modelos do JAX, Keras, PyTorch e TensorFlow para execução na borda.
Multiplataforma
Execute o mesmo modelo em Android, iOS, Web e microcontroladores com SDKs nativos.
Leve e rápido
O ambiente de execução eficiente do LiteRT ocupa apenas alguns megabytes e permite a aceleração do modelo em CPUs, GPUs e NPUs.
PRIMEIROS PASSOS
Escolher um modelo
Escolha um modelo novo, treine novamente um modelo existente ou use o seu.
Converter
Converta seu modelo JAX, Keras, PyTorch ou Tensorflow em um modelo otimizado do LiteRT.
Implantar
Execute um modelo do LiteRT no Android, iOS, Web e microcontroladores.
Quantizar
Compacte seu modelo para reduzir a latência, o tamanho e a memória máxima.
Começar
Um tutorial para soluções de IA generativa no dispositivo Android
1º DE OUTUBRO DE 2024
Como levar seu modelo de IA para dispositivos Android
2 DE OUTUBRO DE 2024
O Gemini Nano já está disponível no Android com acesso experimental
1º DE OUTUBRO DE 2024
O TensorFlow Lite agora é o LiteRT
4 DE SETEMBRO DE 2024
Termos de Serviço
Privacidade
Português – Brasil

Soluções
/
Português – Brasil
Fazer login
Kit de ferramentas de IA generativa responsável
Documentos
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Toolkit para IA generativa responsável
Ferramentas e orientações para projetar, desenvolver e avaliar modelos abertos de IA com responsabilidade.
Design responsável de aplicativos
Defina regras para o comportamento do modelo, crie um aplicativo seguro e responsável e mantenha uma comunicação transparente com os usuários.
Alinhamento de segurança
Descubra técnicas de depuração imediata e orientações para ajustes e RLHF para alinhar modelos de IA às políticas de segurança.
Avaliação do modelo
Encontre orientações e dados para realizar uma avaliação robusta do modelo de segurança, imparcialidade e precisão com o Comparador de LLM.
de saída
Implante classificadores de segurança usando soluções prontas para uso ou crie as suas próprias com tutoriais passo a passo.
Projetar uma abordagem responsável
PRIMEIROS PASSOS
Definir políticas no nível do sistema
Determine que tipo de conteúdo seu aplicativo deve e não deve gerar.
Definir políticas
Confira exemplos
Design com foco na segurança
Defina sua abordagem geral para implementar técnicas de redução de riscos, considerando as compensações técnicas e comerciais.
Saiba mais
Seja transparente
Comunique sua abordagem com artefatos como cards de modelo.
Consulte "Modelos"
Sistemas de IA seguros
Considere os riscos de segurança específicos da IA e os métodos de correção destacados no framework de IA segura (SAIF, na sigla em inglês).
Framework de IA segura do Google
Documentação
Alinhar o modelo
PRIMEIROS PASSOS
Crie avisos mais seguros e robustos
Use o poder dos LLMs para criar modelos de comando mais seguros com a biblioteca de alinhamento de modelos.
Testar agora
Alinhamento do modelo
Ajustar modelos para segurança
Controle o comportamento do modelo ajustando-o para que ele se alinhe às suas políticas de segurança e conteúdo.
Saiba mais sobre os ajustes
Saiba mais sobre o ajuste do SFT
Saiba mais sobre o ajuste de RLHF
Investigar comandos de modelo
Crie instruções seguras e úteis com melhorias iterativas usando a Ferramenta de interpretabilidade de aprendizado (LIT, na sigla em inglês).
Testar agora
Ferramenta de interpretabilidade de aprendizado
Avalie o modelo
PRIMEIROS PASSOS
Comparador de LLM
Realize avaliações lado a lado com o Comparador de LLM para avaliar qualitativamente as diferenças nas respostas entre modelos, comandos diferentes para o mesmo modelo ou até mesmo diferentes ajustes de um modelo.
Teste a demonstração
Saiba mais sobre o comparador de LLM
Diretrizes de avaliação de modelos
Saiba mais sobre as práticas recomendadas de red team e avalie seu modelo com base em comparativos acadêmicos para avaliar os danos relacionados à segurança, à imparcialidade e à veracidade.
Saiba mais
Conferir comparativos de mercado
Confira as práticas recomendadas para equipes vermelhas
Proteger com proteções
PRIMEIROS PASSOS
Texto do SynthID
Uma ferramenta para adicionar marca d'água e detectar texto gerado pelo modelo.
Marca-d'água de texto do SynthID
ShieldGemma
Uma série de classificadores de segurança de conteúdo criados com o Gemma 2, disponíveis em três tamanhos: 2B, 9B e 27B.
Classificadores de segurança de conteúdo do ShieldGemma
Classificadores ágeis
Criar classificadores de segurança para suas políticas específicas usando o ajuste eficiente de parâmetros (PET, na sigla em inglês) com dados de treinamento relativamente pequenos
Criar classificadores de segurança
Verifica a segurança da IA
Garanta a conformidade da IA com suas políticas de conteúdo usando APIs e painéis de monitoramento.
Verifica a segurança da IA
Serviço de moderação de texto
Detecte uma lista de atributos de segurança, incluindo várias categorias e tópicos potencialmente nocivos que podem ser considerados sensíveis com essa API Google Cloud Natural Language disponível sem custo financeiro abaixo de um determinado limite de uso.
API Cloud Natural Language
Preços da API Cloud Natural Language
API Perspective
Identifique comentários "tóxicos" com esta API sem custo financeiro do Google Jigsaw para reduzir a toxicidade on-line e garantir um diálogo saudável.
API Perspective
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_9.txt ---

URL: https://ai.google.dev/showcase?hl=pt-br

Mais
/
Português – Brasil
Fazer login
Confira os vencedores da competição para desenvolvedores da API Gemini. Ver
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Gemini Showcase
Conheça apps reais que aproveitam os recursos multimodais mais recentes e as janelas de contexto longas.
Apps criados com a API Gemini
Vite Vere
Confira como o app para dispositivos móveis usa o Gemini para ajudar pessoas com deficiências cognitivas a terem mais autonomia.
MODELO
Gemini 1.5 Flash
Mais histórias
Vôlei
O Volley cria um protótipo de jogo com foco em áudio com o Gemini 2.0 Flash e a API Multimodal Live
Tldraw
Prototipagem de uma nova experiência de computação de linguagem natural em uma tela infinita com o Gemini 2.0
Salas
Desbloqueie interações mais ricas com os recursos de texto e áudio do Gemini 2.0
Toonsutra
Aproveitar as capacidades de tradução multilíngue contextual do Gemini 2.0 para tornar os quadrinhos e webtoons acessíveis ao público da Índia em idiomas regionais.
Viggle
Experimentar o Gemini 2.0 para criar personagens virtuais e narração de áudio para uma plataforma de vídeo com tecnologia de IA
Subcamada
Saiba como a estrutura de agente de IA baseada em Ruby ajuda as equipes de desenvolvimento a aumentar a produtividade com o poder dos modelos Gemini.
Sourcegraph
Saiba como a Cody AI teve grandes ganhos de qualidade usando a janela de contexto enorme do Gemini.
AgentOps
Saiba como o AgentOps oferece uma observabilidade de agentes com LLM econômica e eficiente para empresas que usam a API Gemini.
Comece a criar com a API Gemini
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_10.txt ---

URL: https://ai.google.dev/competition?hl=pt-br

Mais
/
Português – Brasil
Fazer login
Esta página foi traduzida pela API Cloud Translation.
Switch to English
API Gemini
Competição para desenvolvedores
Menções honrosas
Essas inscrições incríveis mostraram criatividade e inovação excepcionais, merecendo reconhecimento por suas contribuições junto com os vencedores.
Alarmi
O Alarmi usa IA para garantir que você realmente acorde.
Visualizar
Omni
O Omni é um app de IA integrado ao sistema operacional.
Visualizar
Ally
Assistente pessoal para usuários cegos
Visualizar
AI Shift
O AI Shift é um app da Web que automatiza e otimiza a programação de turnos.
Visualizar
Janus
O melhor app de histórias interativas
Visualizar
Studioberry
Plataforma com tecnologia de IA que usa o Gemini para transformar a produção de filmes
Visualizar
EAGLE AI
Seu monitor de segurança com tecnologia de IA
Visualizar
Menu Buddy
O Menu Buddy ajuda pessoas com problemas de fala a fazer pedidos em restaurantes.
Visualizar
Family Farms Forever
A nova maneira de comprar em feiras de produtores. . .e que seja fácil de usar para os agricultores.
Visualizar
Jana AI
Transforme seu dia em histórias interessantes
Visualizar
ITMZ
App de inventário pessoal personalizado para rastrear, pesquisar e compartilhar todos os seus itens.
Visualizar
LoreHunter
Passeios a pé fictícios personalizados
Visualizar
BeeFair - Promptlab
Seu assistente de compras inteligente.
Visualizar
Livros didáticos são tudo o que você precisa
Conheça a TAAYN-chan, uma IA que dá vida aos seus livros didáticos.
Visualizar
Digitalização de fotos
Recordações preciosas preservadas com o poder da IA
Visualizar
Reflexão
Mantenha um diário para ter mais clareza. Reflita para crescer.
Visualizar
1PUL
O primeiro lugar que você vai procurar seus itens
Visualizar
Pixtale
De fotos de viagens a vídeos narrados em minutos com a magia da IA Gemini.
Visualizar
StarryTrader
Um app Bloomberg justo, que democratiza os insights de notícias financeiras
Visualizar
AlphaFit
App de fitness para iniciantes que combina treinos personalizados com jogos mentais
Visualizar
EcoTrack
EcoTrack: a revolução das compras ecológicas com tecnologia de IA
Visualizar
Criar com a Gemini
Gerar uma chave de API no AI Studio
CONHEÇA OS VENCEDORES
Christopher Lloyd não ganhou.
Então, quem são os vencedores?
Português – Brasil

--- Content from: page_11.txt ---

URL: https://ai.google.dev/gemini-api/docs/gemini-for-research?hl=pt-br

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Acelere a descoberta com o Gemini for Research
Gerar uma chave da API Gemini
Os modelos do Gemini podem ser usados para avançar na pesquisa de base em várias disciplinas. Confira algumas maneiras de usar o Gemini para pesquisar:
Ajuste de detalhes: é possível ajustar os modelos do Gemini para várias modalidades e avançar na pesquisa. Saiba mais.
Analisar e controlar as saídas do modelo: para uma análise mais detalhada, é possível examinar um candidato de resposta gerado pelo modelo usando ferramentas como Logprobs e CitationMetadata. Também é possível configurar opções para geração de modelos e saídas, como responseSchema, topP e topK. Saiba mais.
Entradas multimodais: o Gemini pode processar imagens, áudio e vídeos, permitindo uma multiplicidade de direções de pesquisa interessantes. Saiba mais.
Capacidades de contexto longo: o Gemini 1.5 Flash vem com uma janela de contexto de um milhão de tokens, e o Gemini 1.5 Pro vem com uma janela de contexto de dois milhões de tokens. Saiba mais.
Cresça com o Google: acesse rapidamente os modelos do Gemini pela API para casos de uso de produção. Se você está procurando uma plataforma baseada no Google Cloud, a Vertex AI pode oferecer mais infraestrutura de suporte.
Para apoiar a pesquisa acadêmica e impulsionar pesquisas de ponta, o Google oferece acesso a créditos da API Gemini para cientistas e pesquisadores acadêmicos pelo Programa Acadêmico Gemini.
Comece a usar o Gemini
A API Gemini e o Google AI Studio ajudam você a começar a trabalhar com os modelos mais recentes do Google e transformar suas ideias em aplicativos que podem ser escalonados.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="How large is the universe?",
)

print(response.text)
Acadêmicos em destaque
"Nossa pesquisa investiga o Gemini como um modelo de linguagem visual (VLM, na sigla em inglês) e os comportamentos de agentes em diversos ambientes, considerando a robustez e a segurança. Até agora, avaliamos a robustez do Gemini em relação a distrações, como janelas pop-up quando os agentes de VLM realizam tarefas de computador, e aproveitamos o Gemini para analisar interação social, eventos temporais e fatores de risco com base no vídeo."
"O Gemini Pro e o Flash, com sua janela de contexto longa, têm nos ajudado no OK-Robot, nosso projeto de manipulação móvel de vocabulário aberto. O Gemini permite consultas e comandos complexos em linguagem natural na "memória" do robô: neste caso, observações anteriores feitas pelo robô durante uma operação de longa duração. Mahi Shafiullah e eu também estamos usando o Gemini para decompor tarefas em código que o robô pode executar no mundo real."
Programa acadêmico do Gemini
Pesquisadores acadêmicos qualificados (como professores, funcionários e estudantes de doutorado) nos países com suporte podem se inscrever para receber créditos da API Gemini e limites de taxa mais altos para projetos de pesquisa. Esse suporte permite uma maior taxa de transferência para experimentos científicos e pesquisas avançadas.
Estamos particularmente interessados nas áreas de pesquisa da seção a seguir, mas aceitamos inscrições de diversas disciplinas científicas:
Avaliações e comparativos: métodos de avaliação aprovados pela comunidade que podem fornecer um indicador de desempenho forte em áreas como factualidade, segurança, cumprimento de instruções, raciocínio e planejamento.
Acelerar a descoberta científica para beneficiar a humanidade: possíveis aplicações da IA em pesquisas científicas interdisciplinares, incluindo áreas como doenças raras e negligenciadas, biologia experimental, ciência de materiais e sustentabilidade.
Incorporação e interações: uso de modelos de linguagem grandes para investigar novas interações nos campos da IA incorporada, interações ambientais, robótica e interação humano-computador.
Recursos emergentes: conhecer novos recursos de agentes necessários para melhorar o raciocínio e o planejamento e como os recursos podem ser expandidos durante a inferência (por exemplo, usando o Gemini Flash).
Interação e compreensão multimodais: identificar lacunas e oportunidades para modelos de base multimodais para análise, raciocínio e planejamento em várias tarefas.
Elegibilidade: somente indivíduos (professores, pesquisadores ou equivalentes) afiliados a uma instituição acadêmica válida ou a uma organização de pesquisa acadêmica podem se inscrever. O acesso e os créditos da API serão concedidos e removidos a critério do Google. Analisamos as inscrições mensalmente.
Começar a pesquisar com a API Gemini
Faça sua inscrição agora
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-01 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_12.txt ---

URL: https://ai.google.dev/

Mais
/
Português – Brasil
Fazer login
NEW Start building with Gemini 2.0 Flash and Flash-Lite
AI for every
developer
Unlock AI models to build innovative apps and transform development workflows with tools across platforms.
Explore models in Google AI Studio
Terms
Privacy
Português – Brasil

--- Content from: page_13.txt ---

URL: https://ai.google.dev/gemini-api/docs

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
API Gemini Developer
Gerar uma chave da API Gemini
Receba uma chave da API Gemini e faça sua primeira solicitação de API em minutos.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Conheça os modelos
Usar o Gemini no Google AI Studio
2.5 Pro experiment
Nosso modelo de pensamento mais poderoso, com recursos para raciocínio complexo e muito mais
2.0 Flash spark
Nosso modelo multimodal mais recente, com recursos de última geração e recursos aprimorados
2.0 Flash-Lite bolt
Nosso modelo multimodal mais rápido e econômico com ótimo desempenho para tarefas de alta frequência
Explore a API
Geração de imagens nativas
Gere e edite imagens altamente contextuais de forma nativa com o Gemini 2.0 Flash.
Explorar o contexto longo
Insira milhões de tokens nos modelos do Gemini e extraia insights de imagens, vídeos e documentos não estruturados.
Gerar saídas estruturadas
Limite o Gemini para responder com JSON, um formato de dados estruturado adequado para processamento automatizado.
Comece a criar com a API Gemini
Primeiros passos
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_14.txt ---

URL: https://ai.google.dev/api

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Versões da API
Recursos
Modelos
Geração de conteúdo
Tokens
Arquivos
Armazenamento em cache
Embeddings
Ajuste
Recuperação semântica
Todos os métodos
Descontinuado
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Referência da API
Isso foi útil?
Envie comentários
Gemini API reference
Nesta página
Instalar a biblioteca da API Gemini
Faça sua primeira solicitação
A seguir
A API Gemini permite acessar os modelos generativos mais recentes do Google. Esta referência de API fornece informações detalhadas sobre as classes e os métodos disponíveis nos SDKs da API Gemini. Escolha um idioma e siga as etapas de configuração para começar a criar.
Python
JavaScript
Go
Instalar a biblioteca da API Gemini
Observação: estamos lançando um novo conjunto de bibliotecas da API Gemini, o SDK do Google Gen AI.
Usando o Python 3.9+, instale o pacote google-genai usando o seguinte comando pip:
pip install -q -U google-genai
Faça sua primeira solicitação
Use o método generateContent para enviar uma solicitação à API Gemini.
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash", contents="Explain how AI works in a few words"
)
print(response.text)
A seguir
Se você está começando a usar a API, confira os guias a seguir, que vão ajudar a entender o modelo de programação da API Gemini:
Guia de início rápido da API Gemini
Guia de modelos do Gemini
Design de comandos
Você também pode consultar os guias de recursos, que apresentam diferentes recursos da API Gemini e fornecem exemplos de código:
Geração de texto
Cache de contexto
Embeddings
Ajuste
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_15.txt ---

URL: https://ai.google.dev/gemini-api/docs/quickstart

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Guia de início rápido da API Gemini
Nesta página
Instalar a biblioteca da API Gemini
Faça sua primeira solicitação
A seguir
Este guia de início rápido mostra como instalar o SDK escolhido e fazer sua primeira solicitação da API Gemini.
Python
JavaScript
REST
Go
Instalar a biblioteca da API Gemini
Observação: estamos lançando um novo conjunto de bibliotecas da API Gemini, o SDK do Google Gen AI.
Usando o Python 3.9+, instale o pacote google-genai usando o seguinte comando pip:
pip install -q -U google-genai
Faça sua primeira solicitação
Conseguir uma chave da API Gemini no Google AI Studio
Use o método generateContent para enviar uma solicitação à API Gemini.
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash", contents="Explain how AI works in a few words"
)
print(response.text)
A seguir
Agora que você fez sua primeira solicitação de API, confira estes guias que mostram o Gemini em ação:
Geração de texto
Vision
Contexto longo
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_16.txt ---

URL: https://ai.google.dev/gemini-api/docs/api-key

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Gerar uma chave de API Gemini
Nesta página
Configurar a chave de API
Enviar sua primeira solicitação da API Gemini
Proteger a chave de API
Para usar a API Gemini, você precisa de uma chave de API. É possível criar uma chave com apenas alguns cliques no Google AI Studio.
Conseguir uma chave da API Gemini no Google AI Studio
Configurar a chave de API
Para o teste inicial, você pode codificar uma chave de API, mas isso deve ser temporário, já que não é seguro. O restante desta seção explica como configurar a chave de API localmente como uma variável de ambiente com diferentes sistemas operacionais.
Linux/macOS: Bash
macOS: Zsh
Windows
O Bash é uma configuração comum de terminal do Linux e do macOS. Para verificar se você tem um arquivo de configuração, execute o seguinte comando:
~/.bashrc
Se a resposta for "No such file or directory", você vai precisar criar esse arquivo e abri-lo executando os comandos a seguir ou usando zsh:
touch ~/.bashrc
open ~/.bashrc
Em seguida, defina a chave de API adicionando o seguinte comando de exportação:
export GEMINI_API_KEY=<YOUR_API_KEY_HERE>
Depois de salvar o arquivo, aplique as mudanças executando:
source ~/.bashrc
Enviar sua primeira solicitação da API Gemini
Use um comando curl para verificar a configuração:
  curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}" \
    -H 'Content-Type: application/json' \
    -X POST \
    -d '{
      "contents": [{
        "parts":[{"text": "Write a story about a magic backpack."}]
        }]
       }'
Proteger a chave de API
É importante manter a chave da API Gemini segura. Confira alguns pontos a serem considerados ao usar sua chave da API Gemini:
A API Gemini da IA do Google usa chaves de API para autorização. Se outras pessoas tiverem acesso à sua chave de API Gemini, elas poderão fazer chamadas usando a cota do seu projeto, o que pode resultar na perda da cota ou em cobranças adicionais para projetos faturados, além de acessar modelos e arquivos ajustados.
Adicionar restrições de chave de API pode ajudar a limitar a área utilizável em cada chave de API.
Você é responsável por manter a chave da API Gemini segura.
NÃO registre as chaves da API Gemini no controle da origem.
Os aplicativos do lado do cliente (Android, Swift, Web e Dart/Flutter) correm o risco de expor as chaves de API. Não recomendamos usar os SDKs de cliente da IA do Google em apps de produção para chamar a API Gemini da IA do Google diretamente dos seus apps para dispositivos móveis e da Web.
Para conferir algumas práticas recomendadas gerais, consulte este artigo de suporte.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-01-21 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_17.txt ---

URL: https://ai.google.dev/gemini-api/docs/libraries

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Instalar
Migrar para o SDK de IA generativa
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Bibliotecas da API Gemini
Nesta página
Python
JavaScript e TypeScript (pré-lançamento)
Go (pré-lançamento)
SDKs anteriores
Esta página fornece informações sobre como fazer o download ou instalar as bibliotecas para acessar a API Gemini. Se você não conhece a API Gemini, teste o guia de início rápido da API.
Python
Fornecemos um SDK do Python que pode ser instalado executando:
pip install google-genai
JavaScript e TypeScript (pré-lançamento)
Fornecemos um SDK do JavaScript e do TypeScript que pode ser instalado executando:
npm install @google/genai
Go (pré-lançamento)
Fornecemos um SDK do Go que pode ser instalado executando:
go get github.com/google/generative-ai-go
SDKs anteriores
Confira a seguir um conjunto de SDKs anteriores que não estão mais sendo desenvolvidos ativamente:
SDKs anteriores do Dart e do Flutter
SDK anterior do Swift
SDK anterior do Android
SDK anterior do Python
SDK anterior para Node.js
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-01 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_18.txt ---

URL: https://ai.google.dev/gemini-api/docs/migrate

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Instalar
Migrar para o SDK de IA generativa
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Fazer upgrade do SDK do Google GenAI para Python
Nesta página
Instalar o SDK
Autenticar
Geração de conteúdo
Streaming
Argumentos opcionais
Lançamos um novo SDK (google-genai, v1.0) com a versão do Gemini 2. O SDK atualizado é totalmente compatível com todos os modelos e recursos da API Gemini, incluindo adições recentes, como a API multimídia ao vivo (streaming de áudio e vídeo), uso aprimorado de ferramentas (execução de código, chamada de função e integração da busca no Google) e geração de mídia (Imagen). Esse SDK permite conectar-se à API Gemini pelo Google AI Studio ou pela Vertex AI.
O pacote google-generativeai continuará compatível com os modelos originais do Gemini. Ele pode ser usado com modelos Gemini 2, mas com um conjunto limitado de recursos. Todos os novos recursos serão desenvolvidos no novo SDK do Google GenAI.
Teste o novo SDK no Google Colab
Instalar o SDK
Antes
pip install -U -q "google-generativeai"
Depois
pip install -U -q "google-genai"
Autenticar
Autenticar usando uma chave de API. Você pode criar sua chave de API no Google AI Studio.
O SDK antigo processava o objeto de cliente da API de forma implícita. No novo SDK, você cria o cliente da API e o usa para chamar a API.
Em ambos os casos, o SDK vai buscar a chave de API na variável de ambiente GOOGLE_API_KEY se você não transmitir uma para configure/Client.
export GOOGLE_API_KEY=...
Antes
import google.generativeai as genai

genai.configure(api_key=...)
Depois
from google import genai

client = genai.Client(api_key=...)
Geração de conteúdo
O novo SDK oferece acesso a todos os métodos da API pelo objeto Client. Exceto alguns casos especiais com estado (chat e sessions de API ao vivo), essas são todas funções sem estado. Para utilidade e uniformidade, os objetos retornados são classes pydantic.
Antes
import google.generativeai as genai

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content(
    'Tell me a story in 300 words'
)
print(response.text)
Depois
from google import genai
client = genai.Client()

response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='Tell me a story in 300 words.'
)
print(response.text)

print(response.model_dump_json(
    exclude_none=True, indent=4))
Muitos dos mesmos recursos de conveniência existem no novo SDK. Por exemplo, os objetos PIL.Image são convertidos automaticamente:
Antes
import google.generativeai as genai

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content([
    'Tell me a story based on this image',
    Image.open(image_path)
])
print(response.text)
Depois
from google import genai
from PIL import Image

client = genai.Client()

response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents=[
        'Tell me a story based on this image',
        Image.open(image_path)
    ]
)
print(response.text)
Streaming
Os métodos de streaming são funções separadas com o sufixo _stream.
Antes
import google.generativeai as genai

response = model.generate_content(
    "Write a cute story about cats.",
    stream=True)
for chunk in response:
    print(chunk.text)
Depois
from google import genai

client = genai.Client()

for chunk in client.models.generate_content_stream(
  model='gemini-2.0-flash',
  contents='Tell me a story in 300 words.'
):
    print(chunk.text)
Argumentos opcionais
Para todos os métodos no novo SDK, os argumentos obrigatórios são fornecidos como argumentos de palavra-chave. Todas as entradas opcionais são fornecidas no argumento config.
Os argumentos de configuração podem ser especificados como dicionários Python ou classes Config no namespace google.genai.types. Para utilidade e uniformidade, todas as definições no módulo types são classes pydantic.
Antes
import google.generativeai as genai

model = genai.GenerativeModel(
   'gemini-1.5-flash',
    system_instruction='you are a story teller for kids under 5 years old',
    generation_config=genai.GenerationConfig(
       max_output_tokens=400,
       top_k=2,
       top_p=0.5,
       temperature=0.5,
       response_mime_type='application/json',
       stop_sequences=['\n'],
    )
)
response = model.generate_content('tell me a story in 100 words')
Depois
from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents='Tell me a story in 100 words.',
  config=types.GenerateContentConfig(
      system_instruction='you are a story teller for kids under 5 years old',
      max_output_tokens= 400,
      top_k= 2,
      top_p= 0.5,
      temperature= 0.5,
      response_mime_type= 'application/json',
      stop_sequences= ['\n'],
      seed=42,
   ),
)
Exemplo: configurações de segurança
Gerar resposta com as configurações de segurança:
Antes
import google.generativeai as genai

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content(
    'say something bad',
    safety_settings={
        'HATE': 'BLOCK_ONLY_HIGH',
        'HARASSMENT': 'BLOCK_ONLY_HIGH',
   }
)
Depois
from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents='say something bad',
  config=types.GenerateContentConfig(
      safety_settings= [
          types.SafetySetting(
              category='HARM_CATEGORY_HATE_SPEECH',
              threshold='BLOCK_ONLY_HIGH'
          ),
      ]
  ),
)
Assíncrona
Para usar o novo SDK com asyncio, há uma implementação async separada de cada método em client.aio.
Antes
import google.generativeai as genai

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content_async(
    'tell me a story in 100 words'
)
Depois
from google import genai

client = genai.Client()

response = await client.aio.models.generate_content(
    model='gemini-2.0-flash', 
    contents='Tell me a story in 300 words.'
)
Chat
Inicia um chat e envia uma mensagem para o modelo:
Antes
import google.generativeai as genai

model = genai.GenerativeModel('gemini-1.5-flash')
chat = model.start_chat()

response = chat.send_message(
    "Tell me a story in 100 words")
response = chat.send_message(
    "What happened after that?")
Depois
from google import genai

client = genai.Client()

chat = client.chats.create(model='gemini-2.0-flash')

response = chat.send_message(
    message='Tell me a story in 100 words')
response = chat.send_message(
    message='What happened after that?')
Chamadas de função
No novo SDK, a chamada de função automática é o padrão. Aqui, você desativa.
Antes
import google.generativeai as genai
from enum import Enum 

def get_current_weather(location: str) -> str:
    """Get the current whether in a given location.

    Args:
        location: required, The city and state, e.g. San Franciso, CA
        unit: celsius or fahrenheit
    """
    print(f'Called with: {location=}')
    return "23C"

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    tools=[get_current_weather]
)

response = model.generate_content("What is the weather in San Francisco?")
function_call = response.candidates[0].parts[0].function_call
Depois
from google import genai
from google.genai import types

client = genai.Client()

def get_current_weather(location: str) -> str:
    """Get the current whether in a given location.

    Args:
        location: required, The city and state, e.g. San Franciso, CA
        unit: celsius or fahrenheit
    """
    print(f'Called with: {location=}')
    return "23C"

response = client.models.generate_content(
   model='gemini-2.0-flash',
   contents="What is the weather like in Boston?",
   config=types.GenerateContentConfig(
       tools=[get_current_weather],
       automatic_function_calling={'disable': True},
   ),
)

function_call = response.candidates[0].content.parts[0].function_call
Chamadas de função automáticas
O SDK antigo só oferece suporte à chamada de função automática no chat. No novo SDK, esse é o comportamento padrão em generate_content.
Antes
import google.generativeai as genai

def get_current_weather(city: str) -> str:
    return "23C"

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    tools=[get_current_weather]
)

chat = model.start_chat(
    enable_automatic_function_calling=True)
result = chat.send_message("What is the weather in San Francisco?")
Depois
from google import genai
from google.genai import types
client = genai.Client()

def get_current_weather(city: str) -> str:
    return "23C"

response = client.models.generate_content(
   model='gemini-2.0-flash',
   contents="What is the weather like in Boston?",
   config=types.GenerateContentConfig(
       tools=[get_current_weather] 
   ),
)
Execução do código
A execução de código é uma ferramenta que permite que o modelo gere, execute e retorne o resultado do código Python.
Antes
import google.generativeai as genai

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    tools="code_execution"
)

result = model.generate_content(
  "What is the sum of the first 50 prime numbers? Generate and run code for "
  "the calculation, and make sure you get all 50.")
Depois
from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='What is the sum of the first 50 prime numbers? Generate and run '
             'code for the calculation, and make sure you get all 50.',
    config=types.GenerateContentConfig(
        tools=[types.Tool(code_execution=types.ToolCodeExecution)],
    ),
)
Busca de aterramento
GoogleSearch (Gemini>=2.0) e GoogleSearchRetrieval (Gemini < 2.0) são ferramentas que permitem que o modelo recupere dados da Web pública para embasamento, com tecnologia do Google.
Antes
import google.generativeai as genai

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content(
    contents="what is the Google stock price?",
    tools='google_search_retrieval'
)
Depois
from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='What is the Google stock price?',
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                google_search=types.GoogleSearch()
            )
        ]
    )
)
Resposta JSON
Gerar respostas no formato JSON.
Ao especificar um response_schema e definir response_mime_type="application/json", os usuários podem restringir o modelo para produzir uma resposta JSON seguindo uma determinada estrutura. O novo SDK usa classes pydantic para fornecer o esquema, embora seja possível transmitir um genai.types.Schema ou um dict equivalente. Quando possível, o SDK analisa o JSON retornado e retorna o resultado em response.parsed. Se você forneceu uma classe pydantic como o esquema, o SDK vai converter essa JSON em uma instância da classe.
Antes
import google.generativeai as genai
import typing_extensions as typing

class CountryInfo(typing.TypedDict):
    name: str
    population: int
    capital: str
    continent: str
    major_cities: list[str]
    gdp: int
    official_language: str
    total_area_sq_mi: int

model = genai.GenerativeModel(model_name="gemini-1.5-flash")
result = model.generate_content(
    "Give me information of the United States",
     generation_config=genai.GenerationConfig(
         response_mime_type="application/json",
         response_schema = CountryInfo
     ),
)
Depois
from google import genai
from pydantic import BaseModel

client = genai.Client()

class CountryInfo(BaseModel):
    name: str
    population: int
    capital: str
    continent: str
    major_cities: list[str]
    gdp: int
    official_language: str
    total_area_sq_mi: int

response = client.models.generate_content( 
    model='gemini-2.0-flash', 
    contents='Give me information of the United States.', 
    config={ 
        'response_mime_type': 'application/json',
        'response_schema': CountryInfo, 
    }, 
 )

response.parsed
Arquivos
Fazer upload
Faça upload de um arquivo:
Antes
import requests
import pathlib
import google.generativeai as genai

# Download file
response = requests.get(
    'https://storage.googleapis.com/generativeai-downloads/data/a11.txt')
pathlib.Path('a11.txt').write_text(response.text)

file = genai.upload_file(path='a11.txt')

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content([
    'Can you summarize this file:', 
    my_file
])
print(response.text)
Depois
import requests
import pathlib
from google import genai

client = genai.Client()

# Download file
response = requests.get(
    'https://storage.googleapis.com/generativeai-downloads/data/a11.txt')
pathlib.Path('a11.txt').write_text(response.text)

my_file = client.files.upload(file='a11.txt')

response = client.models.generate_content(
    model='gemini-2.0-flash', 
    contents=[
        'Can you summarize this file:', 
        my_file
    ]
)
print(response.text)
Listar e receber
Listar arquivos enviados e receber um arquivo enviado com um nome:
Antes
import google.generativeai as genai

for file in genai.list_files():
  print(file.name)

file = genai.get_file(name=file.name)
Depois
from google import genai
client = genai.Client()

for file in client.files.list():
    print(file.name)

file = client.files.get(name=file.name)
Excluir
Excluir um arquivo:
Antes
import pathlib
import google.generativeai as genai

pathlib.Path('dummy.txt').write_text(dummy)
dummy_file = genai.upload_file(path='dummy.txt')

file = genai.delete_file(name=dummy_file.name)
Depois
import pathlib
from google import genai

client = genai.Client()

pathlib.Path('dummy.txt').write_text(dummy)
dummy_file = client.files.upload(file='dummy.txt')

response = client.files.delete(name=dummy_file.name)
O armazenamento em cache de contexto
O armazenamento em cache de contexto permite que o usuário transmita o conteúdo ao modelo uma vez, armazene em cache os tokens de entrada e, em seguida, consulte os tokens em cache em chamadas subsequentes para reduzir o custo.
Antes
import requests
import pathlib
import google.generativeai as genai
from google.generativeai import caching

# Download file
response = requests.get(
    'https://storage.googleapis.com/generativeai-downloads/data/a11.txt')
pathlib.Path('a11.txt').write_text(response.text)


# Upload file
document = genai.upload_file(path="a11.txt")

# Create cache
apollo_cache = caching.CachedContent.create(
    model="gemini-1.5-flash-001",
    system_instruction="You are an expert at analyzing transcripts.",
    contents=[document],
)

# Generate response
apollo_model = genai.GenerativeModel.from_cached_content(
    cached_content=apollo_cache
)
response = apollo_model.generate_content("Find a lighthearted moment from this transcript")
Depois
import requests
import pathlib
from google import genai
from google.genai import types

client = genai.Client()

# Check which models support caching.
for m in client.models.list():
  for action in m.supported_actions:
    if action == "createCachedContent":
      print(m.name) 
      break

# Download file
response = requests.get(
    'https://storage.googleapis.com/generativeai-downloads/data/a11.txt')
pathlib.Path('a11.txt').write_text(response.text)


# Upload file
document = client.files.upload(file='a11.txt')

# Create cache
model='gemini-1.5-flash-001'
apollo_cache = client.caches.create(
      model=model,
      config={
          'contents': [document],
          'system_instruction': 'You are an expert at analyzing transcripts.',
      },
  )

# Generate response
response = client.models.generate_content(
    model=model,
    contents='Find a lighthearted moment from this transcript',
    config=types.GenerateContentConfig(
        cached_content=apollo_cache.name,
    )
)
Contar Tokens
Conte o número de tokens em uma solicitação.
Antes
import google.generativeai as genai

model = genai.GenerativeModel('gemini-1.5-flash')
response = model.count_tokens(
    'The quick brown fox jumps over the lazy dog.')
Depois
from google import genai

client = genai.Client()

response = client.models.count_tokens(
    model='gemini-2.0-flash',
    contents='The quick brown fox jumps over the lazy dog.',
)
Gerar imagens
Gerar imagens:
Antes
#pip install https://github.com/google-gemini/generative-ai-python@imagen
import google.generativeai as genai

imagen = genai.ImageGenerationModel(
    "imagen-3.0-generate-001")
gen_images = imagen.generate_images(
    prompt="Robot holding a red skateboard",
    number_of_images=1,
    safety_filter_level="block_low_and_above",
    person_generation="allow_adult",
    aspect_ratio="3:4",
)
Depois
from google import genai

client = genai.Client()

gen_images = client.models.generate_images(
    model='imagen-3.0-generate-001',
    prompt='Robot holding a red skateboard',
    config=types.GenerateImagesConfig(
        number_of_images= 1,
        safety_filter_level= "BLOCK_LOW_AND_ABOVE",
        person_generation= "ALLOW_ADULT",
        aspect_ratio= "3:4",
    )
)

for n, image in enumerate(gen_images.generated_images):
    pathlib.Path(f'{n}.png').write_bytes(
        image.image.image_bytes)
Incorporar conteúdo
Gerar embeddings de conteúdo.
Antes
import google.generativeai as genai

response = genai.embed_content(
   model='models/text-embedding-004',
   content='Hello world'
)
Depois
from google import genai

client = genai.Client()

response = client.models.embed_content(
   model='text-embedding-004',
   contents='Hello world',
)
Ajustar um modelo
Crie e use um modelo ajustado.
O novo SDK simplifica o ajuste com client.tunings.tune, que inicia o job de ajuste e faz pesquisas até que ele seja concluído.
Antes
import google.generativeai as genai
import random

# create tuning model
train_data = {} 
for i in range(1, 6): 
   key = f'input {i}' 
   value = f'output {i}' 
   train_data[key] = value

name = f'generate-num-{random.randint(0,10000)}'
operation = genai.create_tuned_model(
    source_model='models/gemini-1.5-flash-001-tuning',
    training_data=train_data,
    id = name,
    epoch_count = 5,
    batch_size=4,
    learning_rate=0.001,
)
# wait for tuning complete
tuningProgress = operation.result()

# generate content with the tuned model
model = genai.GenerativeModel(model_name=f'tunedModels/{name}')
response = model.generate_content('55')
Depois
from google import genai
from google.genai import types

client = genai.Client()

# Check which models are available for tuning.
for m in client.models.list():
  for action in m.supported_actions:
    if action == "createTunedModel":
      print(m.name) 
      break

# create tuning model
training_dataset=types.TuningDataset(
        examples=[
            types.TuningExample(
                text_input=f'input {i}',
                output=f'output {i}',
            )
            for i in range(5)
        ],
    )
tuning_job = client.tunings.tune(
    base_model='models/gemini-1.5-flash-001-tuning',
    training_dataset=training_dataset,
    config=types.CreateTuningJobConfig(
        epoch_count= 5,
        batch_size=4,
        learning_rate=0.001,
        tuned_model_display_name="test tuned model"
    )
)

# generate content with the tuned model
response = client.models.generate_content(
    model=tuning_job.tuned_model.model,
    contents='55', 
)
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-27 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_19.txt ---

URL: https://ai.google.dev/gemini-api/docs/changelog

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Notas da versão
Nesta página
4 de abril de 2025
25 de março de 2025
12 de março de 2025
11 de março de 2025
7 de março de 2025
Esta página documenta as atualizações da API Gemini.
4 de abril de 2025
Lançamos o gemini-2.5-pro-preview-03-25, uma versão de pré-lançamento público do Gemini 2.5 Pro com faturamento ativado. Você pode continuar usando o gemini-2.5-pro-exp-03-25 no nível sem custo financeiro.
25 de março de 2025
Lançamos o gemini-2.5-pro-exp-03-25, um modelo experimental público do Gemini com o modo de pensamento sempre ativado por padrão. Para saber mais, consulte Gemini 2.5 Pro Experimental.
12 de março de 2025
Atualizações de modelos:
Lançamos um modelo experimental do Gemini 2.0 Flash capaz de gerar e editar imagens.
Lançamento do gemma-3-27b-it, disponível no AI Studio e pela API Gemini, como parte do lançamento do Gemma 3.
Atualizações da API:
Adição de suporte a URLs do YouTube como uma fonte de mídia.
Foi adicionado suporte para a inclusão de um vídeo inline de menos de 20 MB.
11 de março de 2025
Atualizações do SDK:
Lançamos o SDK da IA generativa do Google para TypeScript e JavaScript na prévia pública.
7 de março de 2025
Atualizações de modelos:
Lançamos o gemini-embedding-exp-03-07, um modelo de embeddings experimental baseado no Gemini em pré-lançamento público.
28 de fevereiro de 2025
Atualizações da API:
Suporte para a Pesquisa como ferramenta adicionado a gemini-2.0-pro-exp-02-05, um modelo experimental baseado no Gemini 2.0 Pro.
25 de fevereiro de 2025
Atualizações de modelos:
Lançamos o gemini-2.0-flash-lite, uma versão de disponibilidade geral (GA) do Gemini 2.0 Flash-Lite, otimizado para velocidade, escala e eficiência de custo.
18 de fevereiro de 2025
Atualizações de modelos:
O Gemini 1.0 Pro não é mais compatível. Para conferir a lista de modelos compatíveis, consulte Modelos do Gemini.
19 de fevereiro de 2025
Atualizações do AI Studio:
Suporte para outras regiões (Kosovo, Groenlândia e Ilhas Faroé).
Atualizações da API:
Suporte para outras regiões (Kosovo, Groenlândia e Ilhas Faroé).
11 de fevereiro de 2025
Atualizações da API:
Atualizações sobre a compatibilidade com as bibliotecas da OpenAI.
6 de fevereiro de 2025
Atualizações de modelos:
Lançamos a imagen-3.0-generate-002, uma versão de disponibilidade geral (GA, na sigla em inglês) do Imagen 3 na API Gemini.
Atualizações do SDK:
Lançamos o SDK da IA generativa do Google para Java para pré-lançamento público.
5 de fevereiro de 2025
Atualizações de modelos:
Lançou o gemini-2.0-flash-001, uma versão de disponibilidade geral (GA) do Gemini 2.0 Flash que oferece suporte a saída somente de texto.
Lançou o gemini-2.0-pro-exp-02-05, uma versão de pré-lançamento pública do Gemini 2.0 Pro.
Lançamos o gemini-2.0-flash-lite-preview-02-05, um modelo de visualização pública experimental otimizado para eficiência de custos.
Atualizações da API:
Adicionamos suporte a entrada de arquivo e saída de gráfico à execução do código.
Atualizações do SDK:
Lançamos o SDK da IA generativa do Google para Python para disponibilidade geral (GA).
21 de janeiro de 2025
Atualizações de modelos:
Lançamos o gemini-2.0-flash-thinking-exp-01-21, a versão de pré-lançamento mais recente do modelo por trás do modelo de pensamento rápido do Gemini 2.0.
December 19, 2024
Atualizações de modelos:
Lançamos o modo Flash Thinking do Gemini 2.0 para pré-lançamento público. O modo de pensamento é um modelo de computação no momento do teste que permite ver o processo de pensamento do modelo enquanto ele gera uma resposta e produz respostas com recursos de raciocínio mais fortes.
Leia mais sobre o modo Flash Thinking do Gemini 2.0 na nossa página de visão geral.
11 de dezembro de 2024
Atualizações de modelos:
Lançamos o Gemini 2.0 Flash Experimental para pré-lançamento público. A lista parcial de recursos do Gemini 2.0 Flash Experimental inclui:
Duas vezes mais rápido que o Gemini 1.5 Pro
Streaming bidirecional com nossa API Live
Geração de respostas multimodais em forma de texto, imagens e fala
Uso de ferramentas integradas com raciocínio de vários turnos para usar recursos como execução de código, pesquisa, chamada de função e muito mais
Leia mais sobre o Gemini 2.0 Flash na nossa página de informações gerais.
21 de novembro de 2024
Atualizações de modelos:
Lançamos o gemini-exp-1121, um modelo experimental da API Gemini ainda mais poderoso.
Atualizações de modelos:
Atualizamos os aliases de modelo gemini-1.5-flash-latest e gemini-1.5-flash para usar gemini-1.5-flash-002.
Mudança para o parâmetro top_k: o modelo gemini-1.5-flash-002 aceita valores de top_k entre 1 e 41 (exclusivos). Valores maiores que 40 serão alterados para 40.
14 de novembro de 2024
Atualizações de modelos:
Lançamos o gemini-exp-1114, um modelo experimental avançado da API Gemini.
8 de novembro de 2024
Atualizações da API:
Adicionamos suporte ao Gemini nas bibliotecas da OpenAI / API REST.
31 de outubro de 2024
Atualizações da API:
Adicionamos suporte ao Embasamento com a Pesquisa Google.
3 de outubro de 2024
Atualizações de modelos:
Lançamos o gemini-1.5-flash-8b-001, uma versão estável do nosso modelo de API Gemini mais compacto.
24 de setembro de 2024
Atualizações de modelos:
Lançamos gemini-1.5-pro-002 e gemini-1.5-flash-002, duas novas versões estáveis do Gemini 1.5 Pro e 1.5 Flash, para disponibilidade geral.
Atualizamos o código do modelo gemini-1.5-pro-latest para usar gemini-1.5-pro-002 e o código do modelo gemini-1.5-flash-latest para usar gemini-1.5-flash-002.
gemini-1.5-flash-8b-exp-0924 foi lançado para substituir gemini-1.5-flash-8b-exp-0827.
Lançamos o filtro de segurança de integridade cívica para a API Gemini e o AI Studio.
Foi lançado o suporte a dois novos parâmetros para o Gemini 1.5 Pro e 1.5 Flash no Python e NodeJS: frequencyPenalty e presencePenalty.
19 de setembro de 2024
Atualizações do AI Studio:
Foram adicionados botões "Gostei" e "Não gostei" às respostas do modelo para que os usuários possam dar feedback sobre a qualidade de uma resposta.
Atualizações da API:
Adicionamos suporte a créditos do Google Cloud, que agora podem ser usados para uso da API Gemini.
17 de setembro de 2024
Atualizações do AI Studio:
Adicionamos um botão Open in Colab que exporta uma solicitação e o código para executá-la em um notebook do Colab. O recurso ainda não oferece suporte a solicitações com ferramentas (modo JSON, chamada de função ou execução de código).
13 de setembro de 2024
Atualizações do AI Studio:
Adição de suporte ao modo de comparação, que permite comparar respostas entre modelos e comandos para encontrar o melhor ajuste para seu caso de uso.
30 de agosto de 2024
Atualizações de modelos:
O Gemini 1.5 Flash oferece suporte ao fornecimento de esquema JSON pela configuração do modelo.
27 de agosto de 2024
Atualizações de modelos:
Lançamos os seguintes modelos experimentais:
gemini-1.5-pro-exp-0827
gemini-1.5-flash-exp-0827
gemini-1.5-flash-8b-exp-0827
9 de agosto de 2024
Atualizações da API:
Inclusão de suporte para processamento de PDF.
5 de agosto de 2024
Atualizações de modelos:
O suporte a ajustes finos foi lançado para o Gemini 1.5 Flash.
1º de agosto de 2024
Atualizações de modelos:
Lançamos o gemini-1.5-pro-exp-0801, uma nova versão experimental do Gemini 1.5 Pro.
12 de julho de 2024
Atualizações de modelos:
O suporte ao Gemini 1.0 Pro Vision foi removido dos serviços e ferramentas de IA do Google.
27 de junho de 2024
Atualizações de modelos:
Versão de disponibilidade geral para a janela de contexto de 2 milhões do Gemini 1.5 Pro.
Atualizações da API:
Foi adicionada compatibilidade com a execução de código.
18 de junho de 2024
Atualizações da API:
Adição de suporte para armazenamento em cache de contexto.
12 de junho de 2024
Atualizações de modelos:
O Gemini 1.0 Pro Vision foi descontinuado.
23 de maio de 2024
Atualizações de modelos:
O Gemini 1.5 Pro (gemini-1.5-pro-001) está disponível em geral (GA).
O Gemini 1.5 Flash (gemini-1.5-flash-001) está disponível em geral (GA).
14 de maio de 2024
Atualizações da API:
Introdução de uma janela de contexto de 2 milhões para o Gemini 1.5 Pro (lista de espera).
Introdução do faturamento de pagamento por uso para o Gemini 1.0 Pro, com o faturamento do Gemini 1.5 Pro e do Gemini 1.5 Flash em breve.
Aumento dos limites de taxa para o próximo nível pago do Gemini 1.5 Pro.
Adicionamos suporte a vídeo integrado à API File.
Foi adicionado suporte a texto simples à API File.
Adição de suporte à chamada de função paralela, que retorna mais de uma chamada por vez.
10 de maio de 2024
Atualizações de modelos:
Lançamos o Gemini 1.5 Flash (gemini-1.5-flash-latest) em pré-lançamento.
9 de abril de 2024
Atualizações de modelos:
Lançamos o Gemini 1.5 Pro (gemini-1.5-pro-latest) em versão prévia.
Lançamos um novo modelo de embedding de texto, text-embeddings-004, que oferece suporte a tamanhos de embedding elástica menores que 768.
Atualizações da API:
Lançamos a API File para armazenar temporariamente arquivos de mídia para uso em solicitações.
Foi adicionado suporte a comandos com dados de texto, imagem e áudio, também conhecidos como comandos multimodais. Para saber mais, consulte Como usar mídia para dar instruções.
Lançamos a versão Beta das Instruções do sistema.
Foi adicionado o modo de chamada de função, que define o comportamento de execução da chamada de função.
Adicionado suporte à opção de configuração response_mime_type, que permite solicitar respostas no formato JSON.
19 de março de 2024
Atualizações de modelos:
Foi adicionado suporte para ajustar o Gemini 1.0 Pro no Google AI Studio ou com a API Gemini.
13 de dezembro de 2023
Atualizações de modelos:
gemini-pro: novo modelo de texto para uma ampla variedade de tarefas. Equilibra capacidade e eficiência.
gemini-pro-vision: novo modelo multimodal para uma ampla variedade de tarefas. Equilibra capacidade e eficiência.
embedding-001: novo modelo de embeddings.
AQA: um novo modelo ajustado especialmente que é treinado para responder a perguntas usando passagens de texto para fundamentar as respostas geradas.
Consulte Modelos do Gemini para mais detalhes.
Atualizações da versão da API:
v1: o canal de API estável.
v1beta: canal Beta. Este canal tem recursos que podem estar em desenvolvimento.
Consulte o tópico sobre versões da API para mais detalhes.
Atualizações da API:
GenerateContent é um único endpoint unificado para chat e texto.
Streaming disponível pelo método StreamGenerateContent.
Recurso multimodal: a imagem é um novo modo compatível
Novos recursos Beta:
Chamadas de função
Semantic Retriever (link em inglês)
Respostas a perguntas atribuídas (AQA)
Atualização da contagem de candidatos: os modelos Gemini só retornam um candidato.
Diferentes categorias de SafetyRating e Configurações de segurança. Consulte Configurações de segurança para mais detalhes.
Ajustar modelos ainda não é possível para modelos do Gemini (em desenvolvimento).
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_20.txt ---

URL: https://ai.google.dev/gemini-api/docs/openai

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Compatibilidade com o OpenAI
Nesta página
Listar modelos
Recuperar um modelo
Streaming
Chamadas de função
Compreensão de imagens
Os modelos do Gemini podem ser acessados usando as bibliotecas OpenAI (Python e TypeScript / Javascript) com a API REST, atualizando três linhas de código e usando sua chave da API Gemini. Se você ainda não usa as bibliotecas OpenAI, recomendamos chamar a API Gemini diretamente.
Python
JavaScript
REST
from openai import OpenAI

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

response = client.chat.completions.create(
    model="gemini-2.0-flash",
    n=1,
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {
            "role": "user",
            "content": "Explain to me how AI works"
        }
    ]
)

print(response.choices[0].message)
O que mudou? Apenas três linhas.
api_key="GEMINI_API_KEY": substitua "GEMINI_API_KEY" pela chave de API Gemini, que você pode encontrar no Google AI Studio.
base_url="https://generativelanguage.googleapis.com/v1beta/openai/":instrui a biblioteca OpenAI a enviar solicitações para o endpoint da API Gemini em vez do endpoint padrão da OpenAI.
model="gemini-2.0-flash": estamos especificando o modelo gemini-2.0-flash, que é poderoso e eficiente.
Listar modelos
Confira uma lista de modelos do Gemini disponíveis:
Python
JavaScript
REST
from openai import OpenAI

client = OpenAI(
  api_key="GEMINI_API_KEY",
  base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

models = client.models.list()
for model in models:
  print(model.id)
Recuperar um modelo
Extraia um modelo do Gemini:
Python
JavaScript
REST
from openai import OpenAI

client = OpenAI(
  api_key="GEMINI_API_KEY",
  base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

model = client.models.retrieve("gemini-2.0-flash")
print(model.id)
Streaming
A API Gemini oferece suporte a respostas de streaming.
Python
JavaScript
REST
from openai import OpenAI

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

response = client.chat.completions.create(
  model="gemini-2.0-flash",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
  ],
  stream=True
)

for chunk in response:
    print(chunk.choices[0].delta)
Chamadas de função
A chamada de função facilita a geração de saídas de dados estruturados de modelos generativos e é compatível com a API Gemini.
Python
JavaScript
REST
from openai import OpenAI

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

tools = [
  {
    "type": "function",
    "function": {
      "name": "get_weather",
      "description": "Get the weather in a given location",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {
            "type": "string",
            "description": "The city and state, e.g. Chicago, IL",
          },
          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
        },
        "required": ["location"],
      },
    }
  }
]

messages = [{"role": "user", "content": "What's the weather like in Chicago today?"}]
response = client.chat.completions.create(
  model="gemini-2.0-flash",
  messages=messages,
  tools=tools,
  tool_choice="auto"
)

print(response)
Compreensão de imagens
Os modelos Gemini são multimodais por natureza e oferecem a melhor performance da categoria em muitas tarefas de visão comuns.
Python
JavaScript
REST
import base64
from openai import OpenAI

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

# Function to encode the image
def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')

# Getting the base64 string
base64_image = encode_image("Path/to/agi/image.jpeg")

response = client.chat.completions.create(
  model="gemini-2.0-flash",
  messages=[
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "What is in this image?",
        },
        {
          "type": "image_url",
          "image_url": {
            "url":  f"data:image/jpeg;base64,{base64_image}"
          },
        },
      ],
    }
  ],
)

print(response.choices[0])
Gerar uma imagem
Observação: a geração de imagens está disponível apenas no nível pago.
Gerar uma imagem:
Python
JavaScript
REST
import base64
from openai import OpenAI
from PIL import Image
from io import BytesIO

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
)

response = client.images.generate(
    model="imagen-3.0-generate-002",
    prompt="a portrait of a sheepadoodle wearing a cape",
    response_format='b64_json',
    n=1,
)

for image_data in response.data:
  image = Image.open(BytesIO(base64.b64decode(image_data.b64_json)))
  image.show()
Compreensão de áudio
Analisar a entrada de áudio:
Python
JavaScript
REST
import base64
from openai import OpenAI

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

with open("/path/to/your/audio/file.wav", "rb") as audio_file:
  base64_audio = base64.b64encode(audio_file.read()).decode('utf-8')

response = client.chat.completions.create(
    model="gemini-2.0-flash",
    messages=[
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Transcribe this audio",
        },
        {
              "type": "input_audio",
              "input_audio": {
                "data": base64_audio,
                "format": "wav"
          }
        }
      ],
    }
  ],
)

print(response.choices[0].message.content)
Saída estruturada
Os modelos do Gemini podem gerar objetos JSON em qualquer estrutura definida.
Python
JavaScript
from pydantic import BaseModel
from openai import OpenAI

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

class CalendarEvent(BaseModel):
    name: str
    date: str
    participants: list[str]

completion = client.beta.chat.completions.parse(
    model="gemini-2.0-flash",
    messages=[
        {"role": "system", "content": "Extract the event information."},
        {"role": "user", "content": "John and Susan are going to an AI conference on Friday."},
    ],
    response_format=CalendarEvent,
)

print(completion.choices[0].message.parsed)
Embeddings
Os embeddings de texto medem a relação entre strings de texto e podem ser gerados usando a API Gemini.
Python
JavaScript
REST
from openai import OpenAI

client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

response = client.embeddings.create(
    input="Your text string goes here",
    model="text-embedding-004"
)

print(response.data[0].embedding)
Limitações atuais
O suporte para as bibliotecas do OpenAI ainda está na versão Beta enquanto ampliamos o suporte a recursos.
Se você tiver dúvidas sobre parâmetros compatíveis, recursos futuros ou problemas para começar a usar o Gemini, participe do nosso fórum para desenvolvedores.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-01 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_21.txt ---

URL: https://ai.google.dev/gemini-api/docs/models

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Modelos do Gemini
Nesta página
Variantes de modelo
Pré-lançamento do Gemini 2.5 Pro
Gemini 2.0 Flash
Gemini 2.0 Flash-Lite
Gemini 1.5 Flash
Gemini 1.5 Flash-8B
Gemini 1.5 Pro
Imagem 3
2.5 Pro experiment
Nosso modelo de pensamento mais poderoso, com precisão máxima de resposta e desempenho de ponta
Inserir áudio, imagens, vídeo e texto e receber respostas em texto
Resolva problemas difíceis, analise grandes bancos de dados e muito mais
Ideal para programação, raciocínio e compreensão multimodais complexos
2.0 Flash spark
Nosso modelo multimodal mais recente, com recursos de última geração e recursos aprimorados
Inserir áudio, imagens, vídeo e texto e receber respostas em texto
Gerar código e imagens, extrair dados, analisar arquivos, gerar gráficos e muito mais
Baixa latência, desempenho aprimorado e recursos desenvolvidos para oferecer experiências de agentes
2.0 Flash-Lite
Um modelo Gemini 2.0 Flash otimizado para eficiência de custo e baixa latência
Inserir áudio, imagens, vídeo e texto e receber respostas em texto
Supera o Flash 1.5 na maioria dos comparativos de mercado
Uma janela de contexto com 1 milhão de tokens e entrada multimodal, como o Flash 2.0
Variantes de modelo
A API Gemini oferece diferentes modelos otimizados para casos de uso específicos. Confira uma breve descrição das variantes disponíveis do Gemini:
Variante de modelo Entrada(s) Saída Otimizado para
Pré-lançamento do Gemini 2.5 Pro
gemini-2.5-pro-preview-03-25 Áudio, imagens, vídeos e texto Texto Pensamento e raciocínio aprimorados, compreensão multimodal, programação avançada e muito mais
Gemini 2.0 Flash
gemini-2.0-flash Áudio, imagens, vídeos e texto Texto, imagens (experimental) e áudio (em breve) Recursos, velocidade, pensamento, streaming em tempo real e geração multimodais de última geração
Gemini 2.0 Flash-Lite
gemini-2.0-flash-lite Áudio, imagens, vídeos e texto Texto Eficiência de custos e baixa latência
Gemini 1.5 Flash
gemini-1.5-flash Áudio, imagens, vídeos e texto Texto Desempenho rápido e versátil em várias tarefas
Gemini 1.5 Flash-8B
gemini-1.5-flash-8b Áudio, imagens, vídeos e texto Texto Tarefas de alto volume e menor inteligência
Gemini 1.5 Pro
gemini-1.5-pro Áudio, imagens, vídeos e texto Texto Tarefas de raciocínio complexas que exigem mais inteligência
Incorporação do Gemini
gemini-embedding-exp Texto Embeddings de textos Como medir a relação entre strings de texto
Imagen 3
imagen-3.0-generate-002 Texto Imagens Nosso modelo de geração de imagens mais avançado
Você pode conferir os limites de taxa de cada modelo na página de limites de taxa.
Pré-lançamento do Gemini 2.5 Pro
Gemini 2.0 Flash
Gemini 2.0 Flash-Lite
Gemini 1.5 Flash
Gemini 1.5 Flash-8B
Gemini 1.5 Pro
Imagem 3
Integração experimental do Gemini
Incorporação de texto e embedding
AQA
Consulte os exemplos para conhecer os recursos dessas variações de modelo.
[*] Um token equivale a cerca de quatro caracteres para modelos do Gemini. 100 tokens equivalem a cerca de 60 a 80 palavras em inglês.
Padrões de nome de versão do modelo
Os modelos do Gemini estão disponíveis nas versões de pré-lançamento ou estáveis. No seu código, use um dos formatos de nome de modelo a seguir para especificar qual modelo e versão você quer usar.
Mais recente:aponta para a versão mais recente do modelo para uma geração e variação especificadas. O modelo subjacente é atualizado regularmente e pode ser uma versão de visualização. Apenas apps de teste exploratório e protótipos devem usar esse alias.
Para especificar a versão mais recente, use o seguinte padrão: <model>-<generation>-<variation>-latest. Por exemplo, gemini-1.0-pro-latest.
Versão estável mais recente:aponta para a versão estável mais recente lançada para a geração e variação de modelo especificadas.
Para especificar a versão estável mais recente, use o seguinte padrão: <model>-<generation>-<variation>. Por exemplo, gemini-1.0-pro.
Estável:aponta para um modelo estável específico. Modelos estáveis geralmente não mudam. A maioria dos apps de produção precisa usar um modelo estável específico.
Para especificar uma versão estável, use o seguinte padrão: <model>-<generation>-<variation>-<version>. Por exemplo, gemini-1.0-pro-001.
Experimental:aponta para um modelo experimental que pode não ser adequado para uso em produção. Lançamos modelos experimentais para coletar feedback e disponibilizar as nossas atualizações mais recentes aos desenvolvedores rapidamente.
Para especificar uma versão experimental, use o seguinte padrão: <model>-<generation>-<variation>-<version>. Por exemplo, gemini-2.0-pro-exp-02-05.
Modelos experimentais
Além dos modelos prontos para produção, a API Gemini oferece modelos experimentais que podem não ser adequados para uso em produção.
Lançamos modelos experimentais para coletar feedback, disponibilizar as últimas atualizações aos desenvolvedores rapidamente e destacar o ritmo de inovação do Google. O que aprendemos com os lançamentos experimentais nos ajuda a definir como lançar modelos para um público maior. Um modelo experimental pode ser trocado por outro sem aviso prévio. Não garantimos que um modelo experimental se torne estável no futuro.
Modelos experimentais anteriores
À medida que novas versões ou versões estáveis ficam disponíveis, removemos e substituímos modelos experimentais. Você pode encontrar os modelos experimentais anteriores que lançamos na seção a seguir, junto com a versão de substituição:
Código do modelo Modelo base Versão substituta
gemini-2.0-pro-exp-02-05 Gemini 2.0 Pro Experimental gemini-2.5-pro-exp-03-25
gemini-2.0-flash-exp Gemini 2.0 Flash gemini-2.0-flash
gemini-exp-1206 Gemini 2.0 Pro gemini-2.0-pro-exp-02-05
gemini-2.0-flash-thinking-exp-1219 Gemini 2.0 Flash Thinking gemini-2.0-flash-thinking-exp-01-21
gemini-exp-1121 Gemini gemini-exp-1206
gemini-exp-1114 Gemini gemini-exp-1206
gemini-1.5-pro-exp-0827 Gemini 1.5 Pro gemini-exp-1206
gemini-1.5-pro-exp-0801 Gemini 1.5 Pro gemini-exp-1206
gemini-1.5-flash-8b-exp-0924 Gemini 1.5 Flash-8B gemini-1.5-flash-8b
gemini-1.5-flash-8b-exp-0827 Gemini 1.5 Flash-8B gemini-1.5-flash-8b
Idiomas aceitos
Os modelos do Gemini são treinados para funcionar com os seguintes idiomas:
Árabe (ar)
Bengalês (bn)
Búlgaro (bg)
Chinês (simplificado e tradicional) (zh)
Croata (hr)
República Tcheca (cs)
Coreano (da)
Holandês (nl)
Inglês (en)
Estoniano (et)
Finlandês (fi)
Francês (fr)
Alemão (de)
Grego (el)
Hebraico (iw)
Hindi (hi)
Húngaro (hu)
Indonésio (id)
Italiano (it)
Japonês (ja)
Coreano (ko)
Letão (lv)
Lituano (lt)
Norueguês (no)
Polonês (pl)
Português (pt)
Romeno (ro)
Russo (ru)
Sérvio (sr)
Eslovaco (sk)
Esloveno (sl)
Espanhol (es)
Suaíli (sw)
Sueco (sv)
Tailandês (th)
Turco (tr)
Ucraniano (uk)
Vietnamita (vi)
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_22.txt ---

URL: https://ai.google.dev/gemini-api/docs/pricing

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Preços da API Gemini Developer
Nesta página
Pré-lançamento do Gemini 2.5 Pro
Gemini 2.0 Flash
Gemini 2.0 Flash-Lite
Imagem 3
O Gemma 3
O "nível sem custo financeiro" da API Gemini é oferecido pelo serviço da API com limites de taxa mais baixos para fins de teste. O uso do Google AI Studio é totalmente sem custo financeiro em todos os países disponíveis. O "nível pago" da API Gemini tem limites de taxa mais altos, mais recursos e diferentes formas de processamento de dados.
Fazer upgrade para o nível pago
Pré-lançamento do Gemini 2.5 Pro
Testar no Google AI Studio
Nosso modelo multiuso de última geração, que se destaca em programação e tarefas de raciocínio complexas.
Os modelos de pré-lançamento podem mudar antes de se tornarem estáveis e disponíveis para todos.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo, use "gemini-2.5-pro-exp-03-25" US$ 1,25, comandos <= 200 mil tokens
US$2,50, comandos > 200 mil tokens
Preço de saída (incluindo tokens de pensamento) Sem custo, use "gemini-2.5-pro-exp-03-25" US$ 10,00, comandos <= 200 mil tokens
US$15,00, comandos > 200 mil
Preço do armazenamento em cache de contexto Indisponível Indisponível
Embasamento com a Pesquisa Google Sem custo financeiro, até 500 RPD 1.500 RPD (sem custo financeiro), depois US $35 / 1.000 solicitações
Usado para melhorar nossos produtos Sim Não
Gemini 2.0 Flash
Testar no Google AI Studio
Nosso modelo multimodal mais equilibrado com ótimo desempenho em todas as tarefas, com uma janela de contexto de 1 milhão de tokens e criado para a era dos agentes.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,10 (texto / imagem / vídeo)
US$0,70 (áudio)
Preço de saída Sem custo financeiro US$ 0,40
Preço do armazenamento em cache de contexto Sem custo financeiro US$ 0,025 / 1.000.000 tokens (texto/imagem/vídeo)
US$0,175 / 1.000.000 tokens (áudio)
Disponível em 15 de abril de 2025
Armazenamento em cache de contexto Sem custo financeiro, até 1.000.000 de tokens de armazenamento por hora
Disponível em 15 de abril de 2025 US$ 1,00 / 1.000.000 tokens por hora
Disponível em 15 de abril de 2025
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Sem custo financeiro, até 500 RPD 1.500 RPD (sem custo financeiro), depois US $35 / 1.000 solicitações
Usado para melhorar nossos produtos Sim Não
Gemini 2.0 Flash-Lite
Testar no Google AI Studio
Nosso modelo menor e mais econômico, criado para uso em grande escala.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,075
Preço de saída Sem custo financeiro US$ 0,30
Preço do armazenamento em cache de contexto Disponível em 15 de abril de 2025 Disponível em 15 de abril de 2025
Armazenamento em cache de contexto Disponível em 15 de abril de 2025 Disponível em 15 de abril de 2025
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível Indisponível
Usado para melhorar nossos produtos Sim Não
Imagem 3
Testar no ImageFX
Nosso modelo de geração de imagens de última geração, disponível para desenvolvedores no nível pago da API Gemini.
Nível gratuito Nível pago, por imagem em USD
Preço da imagem Indisponível US$ 0,03
Usado para melhorar nossos produtos Sim Não
O Gemma 3
Testar o Gemma 3
Nosso modelo aberto leve e de última geração, criado com a mesma tecnologia que alimenta nossos modelos Gemini.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro Indisponível
Preço de saída Sem custo financeiro Indisponível
Preço do armazenamento em cache de contexto Sem custo financeiro Indisponível
Armazenamento em cache de contexto Sem custo financeiro Indisponível
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível Indisponível
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Flash
Testar no Google AI Studio
Nosso modelo multimodal mais rápido, com ótimo desempenho para tarefas diversas e repetitivas e uma janela de contexto de 1 milhão de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,075, comandos <= 128 mil tokens
US$0,15, comandos > 128 mil tokens
Preço de saída Sem custo financeiro US$ 0,30, comandos <= 128 mil tokens
US$0,60, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Sem custo financeiro, até 1 milhão de tokens de armazenamento por hora US$ 0,01875, comandos <= 128 mil tokens
US$0,0375, comandos > 128 mil tokens
Armazenamento em cache de contexto Sem custo financeiro US$ 1,00 por hora
Preço de ajuste Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro. Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro.
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Flash-8B
Testar no Google AI Studio
Nosso modelo mais pequeno para casos de uso de inteligência mais simples, com uma janela de contexto de 1 milhão de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,0375, comandos <= 128 mil tokens
US$0,075, comandos > 128 mil tokens
Preço de saída Sem custo financeiro US$ 0,15, comandos <= 128 mil tokens
US$0,30, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Sem custo financeiro, até 1 milhão de tokens de armazenamento por hora US$ 0,01, solicitações <= 128 mil tokens
US$0,02, solicitações > 128 mil tokens
Armazenamento em cache de contexto Sem custo financeiro US$ 0,25 por hora
Preço de ajuste Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro. Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro.
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Pro
Testar no Google AI Studio
Nosso modelo de série Gemini 1.5 com a maior inteligência, com uma janela de contexto de 2 milhões de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 1,25, solicitações de até 128 mil tokens
US$2,50, solicitações de mais de 128 mil tokens
Preço de saída Sem custo financeiro US$ 5,00, comandos <= 128 mil tokens
US$10,00, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Indisponível US$ 0,3125, comandos <= 128 mil tokens
US$0,625, comandos > 128 mil tokens
Armazenamento em cache de contexto Indisponível US$ 4,50 por hora
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Text Embedding 004
Nosso modelo de embedding de texto de última geração.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro Indisponível
Preço de saída Sem custo financeiro Indisponível
Preço de ajuste Indisponível Indisponível
Usado para melhorar nossos produtos Sim Não
[*] O uso do Google AI Studio é sem custo financeiro em todas as regiões disponíveis. Consulte as Perguntas frequentes sobre faturamento para mais detalhes.
[**] Os preços podem ser diferentes dos listados aqui e dos oferecidos na Vertex AI. Para conferir os preços da Vertex, consulte a página de preços da Vertex AI.
[***] Se você estiver usando a recuperação dinâmica para otimizar custos, apenas as solicitações que contêm pelo menos um URL de suporte de embasamento da Web na resposta são cobradas pela integração com a Pesquisa Google. Os custos do Gemini sempre se aplicam. Os limites de taxa estão sujeitos a alterações.
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_23.txt ---

URL: https://ai.google.dev/gemini-api/docs/rate-limits

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Limites de taxas
Nesta página
Como funcionam os limites de taxa
Níveis de uso
Limites de taxa atuais
Como fazer upgrade para o próximo nível
Solicitar um aumento no limite de taxa
Os limites de taxa regulam o número de solicitações que você pode fazer para a API Gemini em um determinado período. Esses limites ajudam a garantir o uso justo, protegem contra abusos e ajudam a manter o desempenho do sistema para todos os usuários.
Como funcionam os limites de taxa
Os limites de taxa são medidos em três dimensões:
Solicitações por minuto (RPM)
Solicitações por dia (RPD)
Tokens por minuto (TPM)
Seu uso é avaliado em relação a cada limite, e o excesso de qualquer um deles aciona um erro de limite de taxa. Por exemplo, se o limite de RPM for 20, fazer 21 solicitações em um minuto resultará em um erro, mesmo que você não tenha excedido o TPM ou outros limites.
Os limites de taxa são aplicados por projeto, não por chave de API.
Os limites variam de acordo com o modelo específico usado, e alguns limites se aplicam apenas a modelos específicos. Por exemplo, as imagens por minuto (IPM, na sigla em inglês) são calculadas apenas para modelos capazes de gerar imagens (Imagem 3), mas são conceitualmente semelhantes à TPM.
Níveis de uso
Os limites de taxa estão vinculados ao nível de uso dos projetos, que será lançado em breve. À medida que o uso e os gastos com a API aumentam, você tem a opção de fazer upgrade para um nível mais alto com limites de taxa maiores.
Nível Requisitos
Grátis Usuários em países qualificados
Nível 1 Conta de faturamento vinculada ao projeto
Nível 2 Gasto total: US$ 250 + pelo menos 30 dias desde o pagamento
Nível 3 Gasto total: US$ 1.000 e pelo menos 30 dias desde o pagamento
Quando você solicita um upgrade, nosso sistema automatizado de proteção contra abuso realiza outras verificações. Embora o atendimento aos critérios de qualificação declarados seja geralmente suficiente para a aprovação, em casos raros, uma solicitação de upgrade pode ser negada com base em outros fatores identificados durante o processo de análise.
Esse sistema ajuda a garantir a segurança e a integridade da plataforma da API Gemini para todos os usuários.
Limites de taxa atuais
Nível gratuito
Nível 1
Nível 2
Nível 3
Modelo RPM TPM RPD
Gemini 2.5 Pro Experimental 5 1.000.000 25
Pré-lançamento do Gemini 2.5 Pro -- -- --
Gemini 2.0 Flash 15 1.000.000 1.500
Gemini 2.0 Flash Experimental (incluindo a geração de imagens) 10 1.000.000 1.500
Gemini 2.0 Flash-Lite 30 1.000.000 1.500
Gemini 2.0 Flash Thinking Experimental 01-21 10 4.000.000 1.500
Gemini 1.5 Flash 15 1.000.000 1.500
Gemini 1.5 Flash-8B 15 1.000.000 1.500
Gemini 1.5 Pro 2 32.000 50
Imagem 3 -- -- --
O Gemma 3 30 15.000 14.400
Gemini Embedding Experimental 03-07 5 -- 100
Os limites de taxa especificados não são garantidos, e a capacidade real pode variar.
Como fazer upgrade para o próximo nível
A API Gemini usa o Cloud Billing para todos os serviços de faturamento. Para fazer a transição do nível sem custo financeiro para o pago, primeiro ative o Cloud Billing no seu projeto do Google Cloud.
Quando seu projeto atende aos critérios especificados, ele se qualifica para um upgrade para o próximo nível. Para solicitar um upgrade, siga estas etapas:
Acesse a página Chaves de API no AI Studio.
Localize o projeto que você quer atualizar e clique em "Fazer upgrade". A opção "Upgrade" só vai aparecer para projetos que atendem às qualificações do próximo nível.
Após uma validação rápida, o projeto será atualizado para o próximo nível.
Solicitar um aumento no limite de taxa
Cada variação de modelo tem um limite de taxa associado (solicitações por minuto, RPM). Para mais detalhes sobre esses limites de taxa, consulte Modelos do Gemini.
Solicitar um aumento no limite de taxa da categoria paga
Não oferecemos garantias sobre o aumento do limite de taxa, mas vamos fazer o possível para analisar seu pedido e entrar em contato com você se for possível atender às suas necessidades de capacidade.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_24.txt ---

URL: https://ai.google.dev/gemini-api/docs/billing

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Faturamento
Nesta página
Sobre o faturamento
Por que usar o nível pago?
Cloud Billing
Ativar faturamento
Monitorar o uso
Perguntas frequentes
Por que estou recebendo uma cobrança?
Onde posso conferir minha cota?
Este guia apresenta uma visão geral das diferentes opções de faturamento da API Gemini, explica como ativar o faturamento e monitorar o uso e oferece respostas a perguntas frequentes sobre o faturamento.
Fazer upgrade para o nível pago da API Gemini
Sobre o faturamento
O faturamento da API Gemini é baseado em dois níveis de preço: sem custo financeiro (ou free) e pagamento por uso (ou paid). Os preços e os limites de taxa são diferentes entre esses níveis e também variam de acordo com o modelo. Confira as páginas limites de taxa e preços para mais informações. Para um detalhamento dos recursos de cada modelo, consulte a página Modelos do Gemini.
Como solicitar um upgrade
A API Gemini usa o Cloud Billing para todos os serviços de faturamento. Para fazer a transição do nível sem custo financeiro para o pago, primeiro é necessário ativar o faturamento do Cloud no seu projeto do Google Cloud.
Quando seu projeto atende aos critérios especificados, ele se qualifica para um upgrade para o próximo nível. Para solicitar um upgrade, siga estas etapas:
Acesse a página Chaves de API do AI Studio.
Encontre o projeto que você quer atualizar e clique em Fazer upgrade.
O sistema vai verificar automaticamente a qualificação do seu projeto. Esse processo leva alguns segundos.
Se o projeto atender a todos os requisitos, ele será atualizado instantaneamente para o próximo nível.
Por que usar o nível pago?
Quando você ativa o faturamento e usa o nível pago, tem limites de taxa mais altos, e seus comandos e respostas não são usados para melhorar os produtos do Google. Para mais informações sobre o uso de dados para serviços pagos, consulte os termos de serviço.
Cloud Billing
A API Gemini usa o Cloud Billing para serviços de faturamento. Para usar o nível pago, configure o faturamento do Cloud no seu projeto. Depois de ativar o Cloud Billing, você pode usar as ferramentas do Cloud Billing para acompanhar os gastos, entender os custos, fazer pagamentos e acessar o suporte do Cloud Billing.
Ativar faturamento
É possível ativar o faturamento do Cloud a partir do Google AI Studio:
Abra o Google AI Studio.
Na parte de baixo da barra lateral esquerda, selecione Configurações > Informações do plano.
Clique em Configurar faturamento para o projeto escolhido e ative o Cloud Billing.
Monitorar o uso
Depois de ativar o Cloud Billing, você pode monitorar o uso da API Gemini no console do Google Cloud. O nome do serviço da API é generativelanguage.googleapis.com, e no console, a API Gemini também é chamada de API Linguagem Generativa.
Para saber mais, consulte a documentação do Google Cloud sobre como monitorar o uso da API.
Perguntas frequentes
Esta seção contém respostas para perguntas frequentes.
Por que estou recebendo uma cobrança?
O preço da API Gemini é baseado no seguinte:
Contagem de tokens de entrada
Contagem de tokens de saída
Contagem de tokens em cache
Duração do armazenamento de tokens em cache
Para mais informações sobre preços, consulte a página de preços.
Onde posso conferir minha cota?
É possível conferir a cota e os limites do sistema no console do Google Cloud.
Como solicitar mais cota?
Para solicitar mais cota, siga as instruções em Como solicitar um upgrade.
Posso usar a API Gemini sem custo financeiro no EEE (incluindo a UE), no Reino Unido e na Suíça?
Sim, disponibilizamos o nível sem custo financeiro e o pago em várias regiões.
Se eu configurar o faturamento com a API Gemini, vou receber uma cobrança pelo uso do Google AI Studio?
Não, o uso do Google AI Studio continua sem custo financeiro, mesmo que você configure o faturamento em todas as regiões com suporte.
Posso usar 1 milhão de tokens no nível sem custo financeiro?
O nível sem custo financeiro da API Gemini varia de acordo com o modelo selecionado. Por enquanto, é possível testar a janela de contexto com 1 milhão de tokens das seguintes maneiras:
No Google AI Studio
Com planos de pagamento por uso
Com planos sem cobrança para alguns modelos
Consulte os limites de taxa sem custo por modelo na página de limites de taxa.
Como posso calcular o número de tokens que estou usando?
Use o método GenerativeModel.count_tokens para contar o número de tokens. Consulte o guia de tokens para saber mais sobre o assunto.
Posso usar meus créditos do Google Cloud com a API Gemini?
Sim, os créditos do Google Cloud podem ser usados para o uso da API Gemini.
Como o faturamento é processado?
O faturamento da API Gemini é processado pelo sistema do Cloud Billing.
Vou receber cobranças por solicitações com falha?
Se a solicitação falhar com um erro 400 ou 500, não haverá cobrança pelos tokens usados. No entanto, a solicitação ainda vai contar para sua cota.
Há cobrança pelo ajuste dos modelos?
O ajuste de modelo é sem custo financeiro, mas a inferência em modelos ajustados é cobrada na mesma taxa dos modelos básicos.
O GetTokens é cobrado?
As solicitações à API GetTokens não são faturadas e não são contabilizadas na cota de inferência.
Como meus dados do Google AI Studio são processados se eu tiver uma conta de API paga?
Consulte os termos para saber como os dados são processados quando o faturamento do Cloud está ativado. Consulte "Como o Google usa seus dados" em "Serviços pagos". Os comandos do Google AI Studio são tratados sob os mesmos termos de "Serviços pagos", desde que pelo menos um projeto de API tenha o faturamento ativado. Você pode validar isso na página da chave da API Gemini se houver projetos marcados como "Pago" em "Plano".
Onde posso receber ajuda com o faturamento?
Para receber ajuda com o faturamento, consulte Receber suporte do Cloud Billing.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_25.txt ---

URL: https://ai.google.dev/gemini-api/docs/text-generation

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Geração de texto
Nesta página
Entrada de texto
Entrada de imagem
Saída de streaming
Conversas com vários turnos
Parâmetros de configuração
A API Gemini pode gerar saída de texto em resposta a várias entradas, incluindo texto, imagens, vídeo e áudio. Este guia mostra como gerar texto usando entradas de texto e imagem. Ele também abrange streaming, chat e instruções do sistema.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Entrada de texto
A maneira mais simples de gerar texto usando a API Gemini é fornecer ao modelo uma única entrada de texto, conforme mostrado neste exemplo:
Python
JavaScript
Go
REST
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=["How does AI work?"]
)
print(response.text)
Entrada de imagem
A API Gemini oferece suporte a entradas multimodais que combinam arquivos de texto e mídia. O exemplo a seguir mostra como gerar texto com base em texto e imagem:
Python
JavaScript
Go
REST
from PIL import Image
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

image = Image.open("/path/to/organ.png")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[image, "Tell me about this instrument"]
)
print(response.text)
Saída de streaming
Por padrão, o modelo retorna uma resposta após concluir todo o processo de geração de texto. Você pode ter interações mais rápidas usando o streaming para retornar instâncias de GenerateContentResponse conforme são geradas.
Python
JavaScript
Go
REST
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

response = client.models.generate_content_stream(
    model="gemini-2.0-flash",
    contents=["Explain how AI works"]
)
for chunk in response:
    print(chunk.text, end="")
Conversas com vários turnos
O SDK do Gemini permite coletar várias rodadas de perguntas e respostas em uma conversa. O formato de chat permite que os usuários avancem gradualmente para encontrar respostas e receber ajuda com problemas de várias partes. Essa implementação do SDK do chat fornece uma interface para acompanhar o histórico de conversas, mas, nos bastidores, ela usa o mesmo método generateContent para criar a resposta.
O exemplo de código a seguir mostra uma implementação básica de chat:
Python
JavaScript
Go
REST
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")
chat = client.chats.create(model="gemini-2.0-flash")

response = chat.send_message("I have 2 dogs in my house.")
print(response.text)

response = chat.send_message("How many paws are in my house?")
print(response.text)

for message in chat.get_history():
    print(f'role - {message.role}',end=": ")
    print(message.parts[0].text)
Também é possível usar o streaming com chat, conforme mostrado no exemplo a seguir:
Python
JavaScript
Go
REST
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")
chat = client.chats.create(model="gemini-2.0-flash")

response = chat.send_message_stream("I have 2 dogs in my house.")
for chunk in response:
    print(chunk.text, end="")

response = chat.send_message_stream("How many paws are in my house?")
for chunk in response:
    print(chunk.text, end="")

for message in chat.get_history():
    print(f'role - {message.role}', end=": ")
    print(message.parts[0].text)
Parâmetros de configuração
Cada comando enviado ao modelo inclui parâmetros que controlam como o modelo gera respostas. É possível configurar esses parâmetros ou permitir que o modelo use as opções padrão.
O exemplo a seguir mostra como configurar os parâmetros do modelo:
Python
JavaScript
Go
REST
from google import genai
from google.genai import types

client = genai.Client(api_key="GEMINI_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=["Explain how AI works"],
    config=types.GenerateContentConfig(
        max_output_tokens=500,
        temperature=0.1
    )
)
print(response.text)
Confira alguns dos parâmetros de modelo que você pode configurar. As convenções de nomenclatura variam de acordo com a linguagem de programação.
stopSequences: especifica o conjunto de sequências de caracteres (até 5) que interromperá a geração de saída. Se especificado, a API vai parar na primeira aparição de um stop_sequence. A sequência de paradas não será incluída como parte da resposta.
temperature: controla a aleatoriedade da saída. Use valores mais altos para respostas mais criativas e valores mais baixos para respostas mais deterministas. Os valores podem variar de [0,0 a 2,0].
maxOutputTokens: define o número máximo de tokens a serem incluídos em um candidato.
topP: muda a forma como o modelo seleciona tokens para saída. Os tokens são selecionados do mais para o menos provável até que a soma das probabilidades seja igual ao valor topP. O valor padrão de topP é 0,95.
topK: muda a forma como o modelo seleciona tokens para saída. Um topK de 1 significa que o token selecionado é o mais provável entre todos os tokens no vocabulário do modelo, enquanto um topK de 3 significa que o próximo token é selecionado entre os três mais prováveis usando a temperatura. Os tokens são filtrados com base em topP, com o token final selecionado usando a amostragem de temperatura.
Instruções do sistema
As instruções do sistema permitem orientar o comportamento de um modelo com base no seu caso de uso específico. Ao fornecer instruções do sistema, você proporciona ao modelo mais contexto para ajudar a entender a tarefa e gerar respostas mais personalizadas. O modelo precisa aderir às instruções do sistema durante toda a interação com o usuário, permitindo que você especifique o comportamento no nível do produto separado dos comandos fornecidos pelos usuários finais.
É possível definir instruções do sistema ao inicializar o modelo:
Python
JavaScript
Go
REST
from google import genai
from google.genai import types

client = genai.Client(api_key="GEMINI_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    config=types.GenerateContentConfig(
        system_instruction="You are a cat. Your name is Neko."),
    contents="Hello there"
)

print(response.text)
Em seguida, é possível enviar solicitações ao modelo normalmente.
Modelos compatíveis
Toda a família de modelos Gemini oferece suporte à geração de texto. Para saber mais sobre os modelos e os recursos deles, consulte Modelos.
Dicas de comandos
Para casos de uso básicos de geração de texto, talvez não seja necessário incluir exemplos de saída, instruções do sistema ou informações de formatação. Essa é uma abordagem zero-shot. Para alguns casos de uso, uma solicitação one-shot ou few-shot pode produzir uma saída mais alinhada às expectativas do usuário. Em alguns casos, também é possível fornecer instruções do sistema para ajudar o modelo a entender a tarefa ou seguir diretrizes específicas.
A seguir
Teste o Guia de início da API Gemini no Colab.
Aprenda a usar a compreensão visual do Gemini para processar imagens e vídeos.
Aprenda a usar o entendimento de áudio do Gemini para processar arquivos de áudio.
Saiba mais sobre as estratégias de comando de arquivos multimodais.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_26.txt ---

URL: https://ai.google.dev/gemini-api/docs/image-generation

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Gerar imagens
Nesta página
Gerar imagens usando o Gemini
Edição de imagens com o Gemini
Limitações
Escolher um modelo
Gerar imagens usando o Imagen 3
Parâmetros do modelo do Imagen
A seguir
A API Gemini oferece suporte à geração de imagens usando o Gemini 2.0 Flash Experimental e o Imagen 3. Este guia ajuda você a começar a usar os dois modelos.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Gerar imagens usando o Gemini
O Gemini 2.0 Flash Experimental oferece suporte à capacidade de gerar texto e imagens inline. Isso permite que você use o Gemini para editar imagens em uma conversa ou gerar saídas com texto entrelaçado (por exemplo, gerar uma postagem de blog com texto e imagens em uma única vez). Todas as imagens geradas incluem uma marca-d'água SynthID, e as imagens no Google AI Studio também incluem uma marca-d'água visível.
Observação: inclua responseModalities: ["Text", "Image"] na configuração de geração para saída de texto e imagem com gemini-2.0-flash-exp-image-generation. Imagens únicas não são permitidas.
O exemplo a seguir mostra como usar o Gemini 2.0 para gerar saída de texto e imagem:
Python
JavaScript
REST
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO
import base64

client = genai.Client()

contents = ('Hi, can you create a 3d rendered image of a pig '
            'with wings and a top hat flying over a happy '
            'futuristic scifi city with lots of greenery?')

response = client.models.generate_content(
    model="gemini-2.0-flash-exp-image-generation",
    contents=contents,
    config=types.GenerateContentConfig(
      response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
  if part.text is not None:
    print(part.text)
  elif part.inline_data is not None:
    image = Image.open(BytesIO((part.inline_data.data)))
    image.save('gemini-native-image.png')
    image.show()
Imagem gerada por IA de um porco voador fantástico
Dependendo do comando e do contexto, o Gemini vai gerar conteúdo em diferentes modos (texto para imagem, texto para imagem e texto, etc.). Veja alguns exemplos:
Texto para imagem
Exemplo de comando: "Gere uma imagem da Torre Eiffel com fogos de artifício em segundo plano".
Texto para imagens e texto (intercalado)
Exemplo de comando: "Gerencie uma receita ilustrada de paella."
Imagens e texto para imagens e texto (intercalados)
Exemplo de comando: (com uma imagem de um cômodo mobiliado) "Que outras cores de sofás funcionariam no meu espaço? Você pode atualizar a imagem?"
Edição de imagens (texto e imagem para imagem)
Exemplo de instrução: "Edite esta imagem para que ela pareça um desenho animado"
Exemplo de comando: [imagem de um gato] + [imagem de um travesseiro] + "Crie um ponto cruz do meu gato neste travesseiro".
Edição de imagens com vários turnos (chat)
Exemplos de comandos: [faça upload de uma imagem de um carro azul.] "Transforme este carro em um conversível." "Agora mude a cor para amarelo."
Edição de imagens com o Gemini
Para fazer a edição de imagens, adicione uma imagem como entrada. O exemplo a seguir demonstra o envio de imagens codificadas em base64. Para várias imagens e payloads maiores, consulte a seção Entrada de imagem.
Python
JavaScript
REST
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO

import PIL.Image

image = PIL.Image.open('/path/to/image.png')

client = genai.Client()

text_input = ('Hi, This is a picture of me.'
            'Can you add a llama next to me?',)

response = client.models.generate_content(
    model="gemini-2.0-flash-exp-image-generation",
    contents=[text_input, image],
    config=types.GenerateContentConfig(
      response_modalities=['Text', 'Image']
    )
)

for part in response.candidates[0].content.parts:
  if part.text is not None:
    print(part.text)
  elif part.inline_data is not None:
    image = Image.open(BytesIO(part.inline_data.data))
    image.show()
Limitações
Para ter o melhor desempenho, use os seguintes idiomas: EN, es-MX, ja-JP, zh-CN, hi-IN.
A geração de imagens não tem suporte para entradas de áudio ou vídeo.
A geração de imagens nem sempre aciona:
O modelo pode gerar apenas texto. Tente pedir as saídas de imagem explicitamente (por exemplo, "gerar uma imagem", "fornecer imagens conforme você avança", "atualizar a imagem").
O modelo pode parar de gerar no meio do processo. Tente de novo ou use outro comando.
Ao gerar texto para uma imagem, o Gemini funciona melhor se você gerar primeiro o texto e depois pedir uma imagem com o texto.
Escolher um modelo
Qual modelo você deve usar para gerar imagens? Depende do seu caso de uso.
O Gemini 2.0 é o melhor para produzir imagens relevantes do ponto de vista contextual, combinando texto e imagens, incorporando conhecimento geral e raciocinando sobre imagens. Você pode usá-lo para criar recursos visuais precisos e relevantes para o contexto incorporados em longas sequências de texto. Você também pode editar imagens de forma conversacional, usando linguagem natural, mantendo o contexto durante a conversa.
Se a qualidade da imagem for sua prioridade, o Imagen 3 é a melhor escolha. O Imagen 3 se destaca em fotorrealismo, detalhes artísticos e estilos artísticos específicos, como impressionismo ou anime. O Imagen 3 também é uma boa escolha para tarefas especializadas de edição de imagens, como atualizar planos de fundo de produtos, aumentar o tamanho de imagens e infundir branding e estilo nos recursos visuais. Você pode usar o Imagen 3 para criar logotipos ou outros designs de produtos de marca.
Gerar imagens usando o Imagen 3
A API Gemini oferece acesso ao Imagen 3, o modelo de conversão de texto em imagem de maior qualidade do Google, com vários recursos novos e aprimorados. O Imagen 3 pode fazer o seguinte:
Gerar imagens com mais detalhes, iluminação mais rica e menos artefatos distrativos do que os modelos anteriores
Entender comandos escritos em linguagem natural
Gerar imagens em vários formatos e estilos
Renderizar texto de maneira mais eficaz do que os modelos anteriores
Observação: o Imagen 3 está disponível apenas no nível pago e sempre inclui uma marca d'água SynthID.
Python
JavaScript
REST
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO

client = genai.Client(api_key='GEMINI_API_KEY')

response = client.models.generate_images(
    model='imagen-3.0-generate-002',
    prompt='Robot holding a red skateboard',
    config=types.GenerateImagesConfig(
        number_of_images= 4,
    )
)
for generated_image in response.generated_images:
  image = Image.open(BytesIO(generated_image.image.image_bytes))
  image.show()
Imagem gerada por IA de dois coelhos fofos na cozinha
No momento, o Imagen só oferece suporte a comandos em inglês e aos seguintes parâmetros:
Parâmetros do modelo do Imagen
(As convenções de nomenclatura variam de acordo com a linguagem de programação.)
numberOfImages: o número de imagens a serem geradas, de 1 a 4. O padrão é 4.
aspectRatio: muda a proporção da imagem gerada. Os valores aceitos são "1:1", "3:4", "4:3", "9:16" e "16:9". O padrão é "1:1".
personGeneration: permite que o modelo gere imagens de pessoas. Os seguintes valores são aceitos:
"DONT_ALLOW": bloqueia a geração de imagens de pessoas.
"ALLOW_ADULT": gera imagens de adultos, mas não de crianças. Esse é o padrão.
A seguir
Para saber mais sobre como escrever solicitações para o Imagen, consulte o guia de solicitações do Imagen.
Para saber mais sobre os modelos do Gemini 2.0, consulte Modelos do Gemini e Modelos experimentais.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_27.txt ---

URL: https://ai.google.dev/gemini-api/docs/vision

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Explore as capacidades visuais com a API Gemini
Nesta página
Entrada de imagem
Como trabalhar com imagens locais
Imagens codificadas em Base64
Várias imagens
Payloads de imagens grandes
Compatibilidade com o OpenAI
Como usar imagens
Detalhes técnicos (imagens)
Python
Node.js
Go
REST
Testar um notebook do Colab
Acessar o notebook no GitHub
Os modelos Gemini são capazes de processar imagens e vídeos, permitindo muitos casos de uso de desenvolvedores de fronteira que historicamente exigiriam modelos específicos de domínio. Alguns dos recursos de visão do Gemini incluem a capacidade de:
Adicionar legendas e responder a perguntas sobre imagens
Transcrever e analisar PDFs, incluindo até 2 milhões de tokens
Descrever, segmentar e extrair informações de vídeos com até 90 minutos de duração
Detectar objetos em uma imagem e retornar as coordenadas da caixa delimitadora
O Gemini foi criado para ser multimodais desde o início, e continuamos avançando os limites do que é possível.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Entrada de imagem
Para tamanhos de payload de imagem total de menos de 20 MB, recomendamos fazer o upload de imagens codificadas em base64 ou diretamente de arquivos de imagem armazenados localmente.
Como trabalhar com imagens locais
Se você estiver usando a biblioteca de imagens do Python (Pillow), também poderá usar objetos de imagem PIL.
from google import genai
from google.genai import types

import PIL.Image

image = PIL.Image.open('/path/to/image.png')

client = genai.Client(api_key="
GEMINI_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=["What is this image?", image])

print(response.text)
Imagens codificadas em Base64
Você pode fazer upload de URLs de imagens públicas codificando-os como payloads Base64. O exemplo de código abaixo mostra como fazer isso usando apenas ferramentas de biblioteca padrão:
from google import genai
from google.genai import types

import requests

image_path = "https://goo.gle/instrument-img"
image = requests.get(image_path)

client = genai.Client(api_key="
GEMINI_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=["What is this image?",
              types.Part.from_bytes(data=image.content, mime_type="image/jpeg")])

print(response.text)
Várias imagens
Para solicitar com várias imagens, forneça várias imagens na chamada para generate_content. Eles podem estar em qualquer formato compatível, incluindo base64 ou PIL.
from google import genai
from google.genai import types

import pathlib
import PIL.Image

image_path_1 = "path/to/your/image1.jpeg"  # Replace with the actual path to your first image
image_path_2 = "path/to/your/image2.jpeg" # Replace with the actual path to your second image

image_url_1 = "https://goo.gle/instrument-img" # Replace with the actual URL to your third image

pil_image = PIL.Image.open(image_path_1)

b64_image = types.Part.from_bytes(
    data=pathlib.Path(image_path_2).read_bytes(),
    mime_type="image/jpeg"
)

downloaded_image = requests.get(image_url_1)

client = genai.Client(api_key="
GEMINI_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=["What do these images have in common?",
              pil_image, b64_image, downloaded_image])

print(response.text)
Essas chamadas de dados inline não incluem muitos dos recursos disponíveis na API File, como a extração de metadados de arquivos, listagem ou exclusão de arquivos.
Payloads de imagens grandes
Quando a combinação de arquivos e instruções do sistema que você pretende enviar tiver um tamanho maior que 20 MB, use a API File para fazer upload deles.
Use o método media.upload da API File para fazer upload de uma imagem de qualquer tamanho.
Observação: a API File permite armazenar até 20 GB de arquivos por projeto, com um tamanho máximo de 2 GB por arquivo. Os arquivos são armazenados por 48 horas. Eles podem ser acessados nesse período com sua chave de API, mas não podem ser transferidos por download da API. Ele está disponível sem custo financeiro em todas as regiões onde a API Gemini está disponível.
Depois de fazer o upload do arquivo, é possível fazer solicitações GenerateContent que fazem referência ao URI da API File. Selecione o modelo generativo e forneça um comando de texto e a imagem enviada.
from google import genai

client = genai.Client(api_key="
GEMINI_API_KEY")

img_path = "/path/to/Cajun_instruments.jpg"
file_ref = client.files.upload(file=img_path)
print(f'{file_ref=}')

client = genai.Client(api_key="
GEMINI_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=["What can you tell me about these instruments?",
              file_ref])

print(response.text)
Compatibilidade com o OpenAI
É possível acessar os recursos de compreensão de imagem do Gemini usando as bibliotecas da OpenAI. Isso permite integrar o Gemini aos fluxos de trabalho atuais da OpenAI atualizando três linhas de código e usando a chave da API Gemini. Consulte o exemplo de compreensão de imagem para ver o código que demonstra como enviar imagens codificadas como payloads Base64.
Como usar imagens
Neste tutorial, você vai fazer upload de imagens usando a API File ou como dados inline e gerar conteúdo com base nessas imagens.
Detalhes técnicos (imagens)
O Gemini 2.0 Flash, 1.5 Pro e 1.5 Flash oferecem suporte a um máximo de 3.600 arquivos de imagem.
As imagens precisam estar em um dos seguintes tipos MIME de dados de imagem:
PNG - image/png
JPEG - image/jpeg
WEBP - image/webp
HEIC - image/heic
HEIF - image/heif
Tokens
Veja como os tokens são calculados para imagens:
Gemini 1.0 Pro Vision: cada imagem representa 258 tokens.
Gemini 1.5 Flash e Gemini 1.5 Pro: se as duas dimensões de uma imagem forem menores ou iguais a 384 pixels, então 258 tokens serão usados. Se uma dimensão de uma imagem for maior que 384 pixels, ela será cortada em blocos. O padrão de cada tamanho de bloco é a menor dimensão (largura ou altura) dividida por 1,5. Se necessário, cada bloco é ajustado para não ser menor que 256 pixels nem maior que 768 pixels. Cada bloco é redimensionado para 768 x 768 e usa 258 tokens.
Gemini 2.0 Flash: as entradas de imagem com as duas dimensões <=384 pixels são contabilizadas como 258 tokens. As imagens maiores em uma ou ambas as dimensões são cortadas e redimensionadas conforme necessário em blocos de 768 x 768 pixels, cada um contado como 258 tokens.
Para ter os melhores resultados
Gire as imagens para a orientação correta antes de fazer o upload.
Evite imagens desfocadas.
Se estiver usando uma única imagem, coloque o comando de texto depois dela.
Recursos
Esta seção descreve os recursos de visão específicos do modelo do Gemini, incluindo a detecção de objetos e as coordenadas da caixa delimitadora.
Extrair uma caixa delimitadora para um objeto
Os modelos do Gemini são treinados para retornar as coordenadas da caixa delimitadora como larguras ou alturas relativas no intervalo [0, 1]. Esses valores são dimensionados por 1.000 e convertidos em números inteiros. Na prática, as coordenadas representam a caixa delimitadora em uma versão de 1.000 x 1.000 pixels da imagem. Portanto, você precisará converter essas coordenadas de volta às dimensões da imagem original para mapear as caixas delimitadoras com precisão.
from google import genai

client = genai.Client(api_key="
GEMINI_API_KEY")

prompt = (
  "Return a bounding box for each of the objects in this image "
  "in [ymin, xmin, ymax, xmax] format.")

response = client.models.generate_content(
  model="gemini-1.5-pro",
  contents=[sample_file_1, prompt])

print(response.text)
É possível usar caixas delimitadoras para a detecção e a localização de objetos em imagens e vídeos. Ao identificar e delimitar objetos com caixas limitadoras, você pode desbloquear uma ampla gama de aplicativos e melhorar a inteligência dos seus projetos.
Principais vantagens
Simples:integre recursos de detecção de objetos aos seus aplicativos com facilidade, independentemente da sua experiência em visão computacional.
Personalizável:produz caixas delimitadoras com base em instruções personalizadas (por exemplo, "Quero ver caixas delimitadoras de todos os objetos verdes nesta imagem") sem precisar treinar um modelo personalizado.
Detalhes técnicos
Entrada:seu comando e as imagens ou frames de vídeo associados.
Saída:caixas delimitadoras no formato [y_min, x_min, y_max, x_max]. O canto superior esquerdo é a origem. Os eixos x e y vão horizontalmente e verticalmente, respectivamente. Os valores de coordenadas são normalizados de 0 a 1.000 para cada imagem.
Visualização:os usuários do AI Studio vão ver as caixas de limite plotadas na interface.
Para desenvolvedores Python, teste o notebook de compreensão espacial 2D ou o notebook experimental de ponteiro 3D.
Normalizar coordenadas
O modelo retorna coordenadas da caixa delimitadora no formato [y_min, x_min, y_max, x_max]. Para converter essas coordenadas normalizadas nas coordenadas de pixel da imagem original, siga estas etapas:
Divida cada coordenada de saída por 1.000.
Multiplique as coordenadas x pela largura da imagem original.
Multiplique as coordenadas y pela altura da imagem original.
Para conferir exemplos mais detalhados de como gerar coordenadas de caixa delimitadora e visualizá-las em imagens, consulte nosso exemplo de manual de detecção de objetos.
Segmentação de imagens
A partir da geração 2.5, os modelos do Gemini são treinados para não apenas detectar itens, mas também segmentá-los e fornecer uma máscara do contorno deles.
O modelo prevê uma lista JSON, em que cada item representa uma máscara de segmentação. Cada item tem uma caixa delimitadora ("box_2d") no formato [y0, x0, y1, x1] com coordenadas normalizadas entre 0 e 1000, um rótulo ("label") que identifica o objeto e, por fim, a máscara de segmentação dentro da caixa delimitadora, como png codificado em base64, que é um mapa de probabilidade com valores entre 0 e 255. A máscara precisa ser redimensionada para corresponder às dimensões da caixa delimitadora e, em seguida, binarizada no limite de confiança (127 para o ponto médio).
from google import genai

client = genai.Client(api_key="
GEMINI_API_KEY")

prompt = """
  Give the segmentation masks for the wooden and glass items.
  Output a JSON list of segmentation masks where each entry contains the 2D
  bounding box in the key "box_2d", the segmentation mask in key "mask", and
  the text label in the key "label". Use descriptive labels.
"""

response = client.models.generate_content(
  model="gemini-2.5-pro-exp-03-25",
  contents=[sample_file_1, prompt])

print(response.text)
Máscara dos objetos de madeira e vidro encontrados na imagem
Confira o exemplo de segmentação no guia do livro de receitas para conferir um exemplo mais detalhado.
Como usar vídeos para dar comandos
Neste tutorial, você vai fazer o upload de um vídeo usando a API File e gerar conteúdo com base nessas imagens.
Detalhes técnicos (vídeo)
O Gemini 1.5 Pro e o Flash oferecem suporte a aproximadamente uma hora de dados de vídeo.
O vídeo precisa estar em um dos seguintes tipos MIME de formato de vídeo:
video/mp4
video/mpeg
video/mov
video/avi
video/x-flv
video/mpg
video/webm
video/wmv
video/3gpp
O serviço da API File extrai frames de imagens de vídeos a 1 frame por segundo (FPS) e áudio a 1 Kbps, canal único, adicionando carimbos de data/hora a cada segundo. Essas taxas estão sujeitas a mudanças no futuro para melhorias na inferência.
Observação: os detalhes de sequências de ação rápidas podem ser perdidos na taxa de amostragem de frames de 1 QPS. Considere desacelerar clipes de alta velocidade para melhorar a qualidade da inferência.
Os frames individuais são 258 tokens, e o áudio é 32 tokens por segundo. Com metadados, cada segundo de vídeo se torna cerca de 300 tokens, o que significa que uma janela de contexto de 1 milhão pode caber em pouco menos de uma hora de vídeo. Como resultado, o Gemini Pro, que tem uma janela de contexto de 2 milhões, pode processar vídeos com até 2 horas de duração, e o Gemini Flash, que tem uma janela de contexto de 1 milhão, pode processar vídeos com até 1 hora de duração.
Para fazer perguntas sobre locais com carimbo de data/hora, use o formato MM:SS, em que os dois primeiros dígitos representam minutos e os dois últimos dígitos representam segundos.
Para os melhores resultados:
Use um vídeo por comando.
Se você estiver usando um único vídeo, coloque o comando de texto depois dele.
Fazer upload de um arquivo de vídeo usando a API File
Observação: a API File permite armazenar até 20 GB de arquivos por projeto, com um tamanho máximo de 2 GB por arquivo. Os arquivos são armazenados por 48 horas. Eles podem ser acessados nesse período com sua chave de API, mas não podem ser transferidos por download usando nenhuma API. Ele está disponível sem custo em todas as regiões em que a API Gemini está disponível.
A API File aceita formatos de arquivo de vídeo diretamente. Este exemplo usa o curto-metragem da NASA "Jupiter's Great Red Spot Shrinks and Grows". Crédito: Centro de Voos Espaciais Goddard (GSFC)/David Ladd (2018).
"Jupiter's Great Red Spot Shrinks and Grows" está no domínio público e não mostra pessoas identificáveis. (Diretrizes de uso de imagens e mídia da NASA.)
Comece recuperando o vídeo curto:
wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4
Faça upload do vídeo usando a API File e imprima o URI.
from google import genai

client = genai.Client(api_key="
GEMINI_API_KEY")

print("Uploading file...")
video_file = client.files.upload(file="GreatRedSpot.mp4")
print(f"Completed upload: {video_file.uri}")
Verificar o upload de arquivos e o estado de verificação
Verifique se a API recebeu os arquivos chamando o método files.get.
Observação: os arquivos de vídeo têm um campo State na API File. Quando um vídeo é enviado, ele fica no estado PROCESSING até que esteja pronto para inferência. Somente arquivos ACTIVE podem ser usados para inferência de modelo.
import time

# Check whether the file is ready to be used.
while video_file.state.name == "PROCESSING":
    print('.', end='')
    time.sleep(1)
    video_file = client.files.get(name=video_file.name)

if video_file.state.name == "FAILED":
  raise ValueError(video_file.state.name)

print('Done')
Com um vídeo e texto
Quando o vídeo enviado estiver no estado ACTIVE, será possível fazer solicitações GenerateContent que especifiquem o URI da API File para esse vídeo. Selecione o modelo generativo e forneça o vídeo enviado e um comando de texto.
from IPython.display import Markdown

# Pass the video file reference like any other media part.
response = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[
        video_file,
        "Summarize this video. Then create a quiz with answer key "
        "based on the information in the video."])

# Print the response, rendering any Markdown
Markdown(response.text)
Fazer upload de um vídeo inline
Se o vídeo tiver menos de 20 MB, você poderá incluí-lo inline com a solicitação como um Part de dados.
Confira um exemplo de upload de um vídeo inline:
# Only for videos of size <20Mb
video_file_name = "/path/to/your/video.mp4"
video_bytes = open(video_file_name, 'rb').read()

response = client.models.generate_content(
    model='models/gemini-2.0-flash',
    contents=types.Content(
        parts=[
            types.Part(text='Can you summarize this video?'),
            types.Part(
                inline_data=types.Blob(data=video_bytes, mime_type='video/mp4')
            )
        ]
    )
)
Incluir um URL do YouTube
Pré-lançamento :o recurso de URL do YouTube está em fase de pré-lançamento e não tem custo financeiro. Os preços e os limites de taxa podem mudar.
A API Gemini e o AI Studio oferecem suporte a URLs do YouTube como Part de dados de arquivo. É possível incluir um URL do YouTube com um comando que pede ao modelo para resumir, traduzir ou interagir com o conteúdo do vídeo.
Limitações:
Não é possível enviar mais de oito horas de vídeo do YouTube por dia.
Você só pode enviar um vídeo por solicitação.
Só é possível enviar vídeos públicos, não privados ou não listados.
Observação: o Gemini Pro, que tem uma janela de contexto de 2 milhões, pode processar vídeos de até 2 horas. Já o Gemini Flash, que tem uma janela de contexto de 1 milhão, pode processar vídeos de até 1 hora.
O exemplo a seguir mostra como incluir um URL do YouTube com uma solicitação:
response = client.models.generate_content(
    model='models/gemini-2.0-flash',
    contents=types.Content(
        parts=[
            types.Part(text='Can you summarize this video?'),
            types.Part(
                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=9hE5-98ZeCg')
            )
        ]
    )
)
Consulte as marcações de tempo no conteúdo
Você pode usar carimbos de data/hora no formato MM:SS para se referir a momentos específicos no vídeo.
prompt = "What are the examples given at 01:05 and 01:19 supposed to show us?"

response = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[video_file, prompt])

print(response.text)
Transcrever vídeos e fornecer descrições visuais
Os modelos Gemini podem transcrever e fornecer descrições visuais do conteúdo do vídeo processando a faixa de áudio e os frames visuais. Para descrições visuais, o modelo faz a amostragem do vídeo a uma taxa de 1 frame por segundo. Essa taxa de amostragem pode afetar o nível de detalhes nas descrições, principalmente em vídeos com mudanças visuais rápidas.
prompt = (
    "Transcribe the audio from this video, giving timestamps for "
    "salient events in the video. Also provide visual descriptions.")

response = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[video_file, prompt])

print(response.text)
Listar arquivos
É possível listar todos os arquivos enviados usando a API File e os URIs deles usando files.list.
from google import genai

client = genai.Client(api_key="
GEMINI_API_KEY")

print('My files:')
for f in client.files.list():
  print(" ", f'{f.name}: {f.uri}')
Excluir arquivos
Os arquivos enviados usando a API File são excluídos automaticamente após dois dias. Também é possível excluí-las manualmente usando files.delete.
from google import genai

client = genai.Client(api_key="
GEMINI_API_KEY")

# Upload a file
poem_file = client.files.upload(file="poem.txt")

# Files will auto-delete after a period.
print(poem_file.expiration_time)

# Or they can be deleted explicitly.
dr = client.files.delete(name=poem_file.name)

try:
  client.models.generate_content(
      model="gemini-2.0-flash-exp",
      contents=['Finish this poem:', poem_file])
except genai.errors.ClientError as e:
  print(e.code)  # 403
  print(e.status)  # PERMISSION_DENIED
  print(e.message)  # You do not have permission to access the File .. or it may not exist.
A seguir
Este guia mostra como fazer upload de arquivos de imagem e vídeo usando a API File e, em seguida, gerar saídas de texto de entradas de imagem e vídeo. Para saber mais, confira estes recursos:
Estratégias de solicitação de arquivo: a API Gemini oferece suporte a solicitações com dados de texto, imagem, áudio e vídeo, também conhecidas como solicitações multimodais.
Instruções do sistema: as instruções do sistema permitem orientar o comportamento do modelo com base nas suas necessidades e casos de uso específicos.
Orientações de segurança: às vezes, os modelos de IA generativa produzem resultados inesperados, como respostas imprecisas, parciais ou ofensivas. O pós-processamento e a avaliação humana são essenciais para limitar o risco de danos causados por essas saídas.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_28.txt ---

URL: https://ai.google.dev/gemini-api/docs/audio

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Conheça recursos de áudio com a API Gemini
Nesta página
Formatos de áudio compatíveis
Detalhes técnicos sobre áudio
Disponibilizar um arquivo de áudio para o Gemini
Fazer upload de um arquivo de áudio e gerar conteúdo
Receber metadados de um arquivo
Python
JavaScript
Go
REST
O Gemini pode responder a comandos sobre áudio. Por exemplo, o Gemini pode:
Descrever, resumir ou responder a perguntas sobre conteúdo de áudio.
Forneça uma transcrição do áudio.
Forneça respostas ou uma transcrição sobre um segmento específico do áudio.
Observação: não é possível gerar output de áudio com a API Gemini.
Este guia demonstra diferentes maneiras de interagir com arquivos de áudio e conteúdo de áudio usando a API Gemini.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Formatos de áudio compatíveis
O Gemini oferece suporte aos seguintes tipos MIME de formato de áudio:
WAV - audio/wav
MP3 - audio/mp3
AIFF - audio/aiff
AAC - audio/aac
OGG Vorbis - audio/ogg
FLAC - audio/flac
Detalhes técnicos sobre áudio
O Gemini impõe as seguintes regras para áudio:
O Gemini representa cada segundo de áudio como 32 tokens. Por exemplo, um minuto de áudio é representado como 1.920 tokens.
O Gemini só pode inferir respostas a falas em inglês.
O Gemini pode "entender" componentes não de fala, como o canto de pássaros ou sirenes.
A duração máxima de dados de áudio em uma única instrução é de 9,5 horas. O Gemini não limita o número de arquivos de áudio em uma única instrução.No entanto, a duração total combinada de todos os arquivos de áudio em uma única instrução não pode exceder 9,5 horas.
O Gemini reduz os arquivos de áudio para uma resolução de dados de 16 Kbps.
Se a fonte de áudio tiver vários canais, o Gemini vai combiná-los em um único canal.
Disponibilizar um arquivo de áudio para o Gemini
É possível disponibilizar um arquivo de áudio para o Gemini de duas maneiras:
Faça upload do arquivo de áudio antes de fazer a solicitação de comando.
Forneça o arquivo de áudio como dados inline para a solicitação de comando.
Fazer upload de um arquivo de áudio e gerar conteúdo
Você pode usar a API File para fazer upload de um arquivo de áudio de qualquer tamanho. Sempre use a API File quando o tamanho total da solicitação (incluindo arquivos, comando de texto, instruções do sistema etc.) for maior que 20 MB.
Observação: a API File permite armazenar até 20 GB de arquivos por projeto, com um tamanho máximo de 2 GB por arquivo. Os arquivos são armazenados por 48 horas. Eles podem ser acessados nesse período com sua chave de API, mas não podem ser transferidos por download da API. A API File está disponível sem custo financeiro em todas as regiões onde a API Gemini está disponível.
Chame media.upload para fazer upload de um arquivo usando a API File. O código abaixo faz upload de um arquivo de áudio e o usa em uma chamada para models.generateContent.
from google import genai

client = genai.Client()

myfile = client.files.upload(file='media/sample.mp3')

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents=['Describe this audio clip', myfile]
)

print(response.text)
Receber metadados de um arquivo
É possível verificar se a API armazenou o arquivo enviado e acessar os metadados dele chamando files.get.
myfile = client.files.upload(file='media/sample.mp3')
file_name = myfile.name
myfile = client.files.get(name=file_name)
print(myfile)
Listar arquivos enviados
Você pode fazer upload de vários arquivos de áudio (e outros tipos de arquivos). O código abaixo gera uma lista de todos os arquivos enviados:
print('My files:')
for f in client.files.list():
    print(' ', f.name)
Excluir arquivos enviados
Os arquivos são excluídos automaticamente após 48 horas. Você também pode excluir manualmente um arquivo enviado. Exemplo:
myfile = client.files.upload(file='media/sample.mp3')
client.files.delete(name=myfile.name)
Fornecer o arquivo de áudio como dados inline na solicitação
Em vez de fazer upload de um arquivo de áudio, transmita dados de áudio na mesma chamada que contém o comando.
Em seguida, transmita esse pequeno arquivo de áudio baixado com o comando para o Gemini:
from google.genai import types

with open('media/small-sample.mp3', 'rb') as f:
    audio_bytes = f.read()

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents=[
    'Describe this audio clip',
    types.Part.from_bytes(
      data=audio_bytes,
      mime_type='audio/mp3',
    )
  ]
)

print(response.text)
Observe o seguinte sobre o envio de áudio como dados inline:
O tamanho máximo da solicitação é de 20 MB, incluindo comandos de texto, instruções do sistema e arquivos fornecidos inline. Se o tamanho do arquivo ultrapassar 20 MB, o tamanho total da solicitação será maior que esse valor. Nesse caso, use a API File para fazer upload de arquivos para uso em solicitações.
Se você estiver usando um sample de áudio várias vezes, será mais eficiente usar a API File.
Mais formas de trabalhar com áudio
Esta seção apresenta algumas outras maneiras de aproveitar melhor o áudio.
Receber uma transcrição do arquivo de áudio
Para receber uma transcrição, basta pedir no comando. Exemplo:
myfile = client.files.upload(file='media/sample.mp3')
prompt = 'Generate a transcript of the speech.'

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents=[prompt, myfile]
)

print(response.text)
Consultar carimbos de data/hora no arquivo de áudio
Um comando pode especificar carimbos de data/hora do formulário MM:SS para se referir a seções específicas em um arquivo de áudio. Por exemplo, o comando a seguir solicita uma transcrição que:
Começa 2 minutos e 30 segundos após o início do arquivo.
Termina em 3 minutos e 29 segundos do início do arquivo.
# Create a prompt containing timestamps.
prompt = "Provide a transcript of the speech from 02:30 to 03:29."
Contar Tokens
Chame o método countTokens para conferir a contagem de tokens no arquivo de áudio. Exemplo:
response = client.models.count_tokens(
  model='gemini-2.0-flash',
  contents=[myfile]
)

print(response)
A seguir
Este guia mostra como fazer upload de arquivos de áudio usando a API File e gerar saídas de texto de entradas de áudio. Para saber mais, consulte os seguintes recursos:
Estratégias de solicitação de arquivo: a API Gemini oferece suporte a solicitações com dados de texto, imagem, áudio e vídeo, também conhecidas como solicitações multimodais.
Instruções do sistema: as instruções do sistema permitem orientar o comportamento do modelo com base nas suas necessidades e casos de uso específicos.
Orientações de segurança: às vezes, os modelos de IA generativa produzem resultados inesperados, como respostas imprecisas, parciais ou ofensivas. O pós-processamento e a avaliação humana são essenciais para limitar o risco de danos causados por essas saídas.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-08 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_29.txt ---

URL: https://ai.google.dev/gemini-api/docs/long-context

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Contexto longo
Nesta página
O que é uma janela de contexto?
Introdução ao contexto longo
Casos de uso de contexto longo
Texto longo
Vídeo mais longo
Áudio de longa duração
Otimizações de contexto longo
Limitações de contexto longo
O Gemini 2.0 Flash e o Gemini 1.5 Flash vêm com uma janela de contexto de um milhão de tokens, e o Gemini 1.5 Pro vem com uma janela de contexto de dois milhões de tokens. Historicamente, os modelos de linguagem grandes (LLMs) estavam significativamente limitados pela quantidade de texto (ou tokens) que podia ser transmitida ao modelo de uma só vez. A janela de contexto longo do Gemini 1.5, com recuperação quase perfeita (>99%), libera muitos novos casos de uso e paradigmas de desenvolvedor.
O código que você já usa para casos como geração de texto ou entradas multimodais vai funcionar imediatamente com contexto longo.
Neste guia, você vai conhecer os conceitos básicos da janela de contexto, como os desenvolvedores devem pensar sobre o contexto longo, vários casos de uso reais para contexto longo e maneiras de otimizar o uso do contexto longo.
O que é uma janela de contexto?
A maneira básica de usar os modelos do Gemini é transmitindo informações (contexto) ao modelo, que vai gerar uma resposta. Uma analogia com a janela de contexto é a memória de curto prazo. Há uma quantidade limitada de informações que podem ser armazenadas na memória de curto prazo, e o mesmo vale para modelos generativos.
Leia mais sobre como os modelos funcionam no nosso guia de modelos generativos.
Introdução ao contexto longo
A maioria dos modelos generativos criados nos últimos anos só foi capaz de processar 8.000 tokens de uma vez. Os modelos mais recentes avançaram ainda mais, aceitando 32.000 tokens ou 128.000 tokens. O Gemini 1.5 é o primeiro modelo capaz de aceitar 1 milhão de tokens e agora 2 milhões de tokens com o Gemini 1.5 Pro.
Na prática, 1 milhão de tokens seria:
50.000 linhas de código (com o padrão de 80 caracteres por linha)
Todas as mensagens de texto que você enviou nos últimos cinco anos
8 romances ingleses de tamanho médio
Transcrição de mais de 200 episódios de podcast de duração média
Os modelos podem ter cada vez mais contexto, muito da sabedoria convencional sobre o uso de modelos de linguagem grandes assume essa limitação no modelo, que, a partir de 2024, não ocorrerá mais.
Algumas estratégias comuns para lidar com a limitação de pequenas janelas de contexto incluindo o seguinte:
Mensagens / textos antigos são descartados arbitrariamente da janela de contexto quando um novo texto é recebido
Resume o conteúdo anterior e o substitui pelo resumo quando a janela de contexto estiver quase cheia
Usa o RAG com pesquisa semântica para mover dados para fora da janela de contexto e em um banco de dados de vetores
Usar filtros determinísticos ou generativos para remover determinados textos / caracteres dos comandos para salvar tokens
Embora muitos deles ainda sejam relevantes em certos casos, o local padrão para começar é colocando todos os tokens na janela de contexto. Como os modelos Gemini foram criados especificamente com uma janela de contexto longa, eles são muito mais capazes de aprender com base em contexto. Por exemplo, com apenas materiais instrucionais (uma gramática de referência de 500 páginas, um dicionário e cerca de 400 frases paralelas extras) fornecidos no contexto, o Gemini 1.5 Pro e o Gemini 1.5 Flash são capazes de aprender a traduzir do inglês para o Kalamang, um idioma papuano com menos de 200 falantes e, portanto, quase nenhuma presença on-line, com qualidade semelhante a uma pessoa que aprendeu com os mesmos materiais.
Este exemplo destaca como você pode começar a pensar no que é possível com o contexto longo e os recursos de aprendizado no contexto dos modelos do Gemini.
Casos de uso de contexto longo
Embora o caso de uso padrão para a maioria dos modelos generativos ainda seja a entrada de texto, a família de modelos Gemini 1.5 possibilita um novo paradigma de casos de uso multimodais. Eles podem entender textos, vídeos, áudios e imagens de maneira nativa. São acompanhados pela API Gemini, que aceita tipos de arquivos multimodais por conveniência.
Texto longo
O texto provou ser a camada de inteligência que sustenta grande parte do impulso em torno dos LLMs. Como mencionado anteriormente, grande parte da limitação prática dos LLMs se deve à falta de uma janela de contexto grande o suficiente para realizar determinadas tarefas. Isso levou à rápida adoção da geração aumentada de recuperação (RAG, na sigla em inglês) e outras técnicas que fornecem dinamicamente ao modelo informações contextuais. Agora, com janelas de contexto cada vez maiores (atualmente até 2 milhões no Gemini 1.5 Pro), novas técnicas são disponibilizadas, o que possibilita novos casos de uso.
Alguns casos de uso emergentes e padrão para contexto longo baseado em texto incluem o seguinte:
Resumir grandes corpus de texto
As opções de resumo anteriores com modelos de contexto menores exigiam uma janela deslizante ou outra técnica para manter o estado das seções anteriores à medida que novos tokens eram transmitidos para o modelo.
Perguntas e respostas
Historicamente, isso só era possível com o RAG, devido à quantidade limitada de contexto e à baixa recuperação de fatos dos modelos.
Fluxos de trabalho agente
O texto é a base de como os agentes mantêm o estado do que fizeram e o que eles precisam fazer. Não ter informações suficientes sobre o mundo e o objetivo do agente é uma limitação na confiabilidade dos agentes
A aprendizagem em contexto com muitas tentativas é um dos recursos mais exclusivos liberados pelos modelos de contexto longo. As pesquisas mostram que usar o exemplo de paradigma de "tentativa única" comum ou "muitas tentativas", em que o modelo é apresentado com um ou alguns exemplos de uma tarefa e escalonando-o até centenas, milhares ou mesmo centenas de milhares de exemplos, pode levar a novos recursos do modelo. Essa abordagem de várias fotos também apresentou um desempenho semelhante ao de modelos ajustados para uma tarefa específica. Para casos de uso em que a performance de um modelo do Gemini ainda não é suficiente para um lançamento em produção, tente a abordagem de várias tentativas. Como você pode explorar mais tarde na seção de otimização de contexto longo, o armazenamento em cache de contexto torna esse tipo de alta carga de trabalho de token de entrada muito mais viável e com latência ainda menor em alguns casos.
Vídeo mais longo
A utilidade do conteúdo de vídeo é, há muito tempo, limitada pela falta de acessibilidade da própria mídia. Era difícil ler o conteúdo, as transcrições muitas vezes não conseguiam capturar as nuances de um vídeo e a maioria das ferramentas não processava imagem, texto e áudio juntos. Com o Gemini 1.5, os recursos de texto de contexto longo se traduzem na capacidade de raciocinar e responder a perguntas sobre entradas multimodais com desempenho sustentável. Gemini 1.5 Flash, quando testado na agulha em um problema de palheiro em vídeo com 1 milhão de tokens, obteve um recall >99,8% do vídeo na janela de contexto, e o 1.5 Pro alcançou um desempenho de última geração no comparativo de mercado de vídeo/MME.
Alguns casos de uso emergentes e padrão para contexto de vídeo longo incluem:
Perguntas e respostas sobre vídeos
Memória de vídeo, como mostrado com o Project Astra do Google
Legendas em vídeos
Sistemas de recomendação de vídeo, enriquecendo os metadados com nova compreensão multimodal
Personalização de vídeo, analisando um conjunto de dados e metadados de vídeos associados e, em seguida, removendo partes dos vídeos que não são relevantes para o leitor
Moderação de conteúdo em vídeo
Processamento de vídeo em tempo real
Ao trabalhar com vídeos, é importante considerar como os vídeos são processados em tokens, o que afeta os limites de faturamento e uso. Saiba mais sobre comandos com arquivos de vídeo no Guia de comandos.
Áudio de longa duração
O Gemini 1.5 foi os primeiros modelos de linguagem grandes multimodais nativos que pudesse entender áudio. Historicamente, o fluxo de trabalho típico de um desenvolvedor envolve unir vários modelos específicos de domínio, como um modelo de conversão de voz em texto e de conversão de texto em texto para processar o áudio. Isso levou a uma latência adicional necessária ao realizar várias solicitações de ida e volta e reduziu o desempenho, geralmente atribuído a arquiteturas desconexas da configuração de vários modelos.
Em avaliações padrão de palheiro de áudio, o Gemini 1.5 Pro encontra o áudio oculto em 100% dos testes, e o Gemini 1.5 Flash consegue encontrá-lo em 98,7% dos testes. O Gemini 1.5 Flash aceita até 9,5 horas de áudio em uma única solicitação, e o Gemini 1.5 Pro aceita até 19 horas de áudio usando a janela de contexto de 2 milhões de tokens. Além disso, em um conjunto de teste de 15 minutos de áudio, o Gemini 1.5 Pro arquiva uma taxa de erro de palavras (WER, na sigla em inglês) de cerca de 5,5%, muito menor do que modelos de conversão de voz em texto especializados, sem a complexidade adicional de segmentação de entrada extra e pré-processamento.
Alguns casos de uso emergentes e padrão para contexto de áudio incluem o seguinte:
Transcrição e tradução em tempo real
Perguntas e respostas sobre podcasts / vídeos
Transcrição e resumo de reuniões
Assistentes por voz
Saiba mais sobre comandos com arquivos de áudio em Guia de comandos.
Otimizações de contexto longo
A otimização principal ao trabalhar com contexto longo e os modelos do Gemini 1.5 é usar o armazenamento em cache de contexto. Além da impossibilidade anterior de processar muitos tokens em uma única solicitação, a outra restrição principal era o custo. Se você tiver um app de "conversa com seus dados" em que um usuário carrega 10 PDFs, um vídeo e alguns documentos de trabalho, historicamente, você teria que trabalhar com uma ferramenta / framework de geração aumentada de recuperação (RAG) mais complexa para processar essas solicitações e pagar um valor significativo por tokens que foram movidos para a janela de contexto. Agora, é possível armazenar em cache os arquivos que o usuário envia e pagar para armazená-los por hora. O custo de entrada / saída por solicitação com o Gemini 1.5 Flash, por exemplo, é cerca de quatro vezes menor do que o custo de entrada / saída padrão. Portanto, se o usuário conversar bastante com os dados, isso vai gerar uma grande economia de custos para você como desenvolvedor.
Limitações de contexto longo
Em várias seções deste guia, falamos sobre como os modelos do Gemini 1.5 alcançam alta performance em várias avaliações de recuperação de agulha no palheiro. Esses testes consideram a configuração mais básica, em que há apenas uma agulha que você está procurando. Nos casos em que você pode ter várias "agulhas" ou partes específicas de informações que está procurando, o modelo não tem o mesmo desempenho. A performance pode variar bastante dependendo do contexto. É importante considerar isso, pois há uma compensação inerente entre obter a recuperação de informações e custos corretos. Você pode receber cerca de 99% em uma única consulta, mas precisa pagar o custo do token de entrada sempre que enviar essa consulta. Portanto, para que 100 pedaços de informações sejam recuperadas, se você precisar de 99% de performance, provavelmente terá que enviar 100 solicitações. Este é um bom exemplo de quando o armazenamento em cache do contexto pode reduzir significativamente o custo associado ao uso de modelos do Gemini mantendo o alto desempenho.
Perguntas frequentes
A performance do modelo é afetada quando adiciono mais tokens a uma consulta?
Em geral, se você não precisar que os tokens sejam transmitidos ao modelo, é melhor evitar a transmissão deles. No entanto, se você tiver um grande número de tokens com algumas informações e quiser fazer perguntas sobre elas, o modelo será capaz de extrair essas informações (até 99% de precisão em muitos casos).
Como o Gemini 1.5 Pro se sai no teste padrão de agulha no palheiro?
O Gemini 1.5 Pro alcança um recall de 100% em até 530 mil tokens e de >99,7% em até 1 milhão de tokens.
Como posso reduzir meu custo com consultas de contexto longo?
Se você tiver um conjunto semelhante de tokens / contexto que quer reutilizar várias vezes, o armazenamento em cache de contexto pode ajudar a reduzir os custos associados a perguntas sobre essas informações.
Como posso acessar a janela de contexto com 2 milhões de tokens?
Todos os desenvolvedores agora têm acesso à janela de contexto de 2 milhões de tokens com o Gemini 1.5 Pro.
O comprimento do contexto afeta a latência do modelo?
Há uma quantidade fixa de latência em qualquer solicitação, independentemente do tamanho, mas geralmente as consultas mais longas têm latência mais alta (tempo até o primeiro token).
Os recursos de contexto longo são diferentes entre o Gemini 1.5 Flash e o Gemini 1.5 Pro?
Sim, alguns números foram mencionados em diferentes seções deste guia, mas, geralmente, o Gemini 1.5 Pro tem melhor desempenho na maioria dos casos de uso de contexto longo.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-24 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_30.txt ---

URL: https://ai.google.dev/gemini-api/docs/code-execution

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Execução do código
Nesta página
Começar a usar a execução de código
Ativar a execução de código no modelo
Usar a execução de código no chat
Entrada/saída (E/S)
Preços de E/S
Detalhes de E/S
Faturamento
Limitações
Python
JavaScript
Go
REST
O recurso de execução de código da API Gemini permite que o modelo gere e execute código Python e aprenda de forma iterativa com os resultados até chegar a uma saída final. É possível usar esse recurso de execução de código para criar aplicativos que se beneficiam do raciocínio baseado em código e que produzem saída de texto. Por exemplo, você pode usar a execução de código em um aplicativo que resolve equações ou processa texto.
Observação: o Gemini só pode executar códigos em Python. Ainda é possível pedir ao Gemini para gerar código em outro idioma, mas o modelo não pode usar a ferramenta de execução de código para executá-lo.
A execução do código está disponível no AI Studio e na API Gemini. No AI Studio, é possível ativar a execução de código no painel à direita em Ferramentas. A API Gemini oferece a execução de código como uma ferramenta, semelhante à chamada de função. Depois de adicionar a execução de código como uma ferramenta, o modelo decide quando usá-la.
O ambiente de execução do código inclui as seguintes bibliotecas: altair, chess, cv2, matplotlib, mpmath, numpy, pandas, pdfminer, reportlab, seaborn, sklearn, statsmodels, striprtf, sympy e tabulate. Não é possível instalar suas próprias bibliotecas.
Observação: apenas matplotlib é compatível com a renderização de gráficos usando a execução de código.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Começar a usar a execução de código
Você também pode testar o tutorial de execução de código em um notebook:
Testar um notebook do Colab
Acessar o notebook no GitHub
Ativar a execução de código no modelo
É possível ativar a execução de código no modelo, conforme mostrado aqui:
from google import genai
from google.genai import types

client = genai.Client(api_key="
GEMINI_API_KEY")

response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents='What is the sum of the first 50 prime numbers? '
           'Generate and run code for the calculation, and make sure you get all 50.',
  config=types.GenerateContentConfig(
    tools=[types.Tool(
      code_execution=types.ToolCodeExecution
    )]
  )
)
Em um notebook, você pode mostrar tudo no formato Markdown com esta função auxiliar:
def display_code_execution_result(response):
  for part in response.candidates[0].content.parts:
    if part.text is not None:
      display(Markdown(part.text))
    if part.executable_code is not None:
      code_html = f'<pre style="background-color: #BBBBEE;">{part.executable_code.code}</pre>' # Change code color
      display(HTML(code_html))
    if part.code_execution_result is not None:
      display(Markdown(part.code_execution_result.output))
    if part.inline_data is not None:
      display(Image(data=part.inline_data.data, format="png"))
    display(Markdown("---"))

display_code_execution_result(response)
A saída pode ser semelhante a esta:
Preciso calcular a soma dos primeiros 50 números primos. Vou usar um script Python para gerar os primeiros 50 números primos e somá-los.
```python
def is_prime(n):
  """Checks if a number is prime."""
  if n <= 1:
    return False
  for i in range(2, int(n**0.5) + 1):
    if n % i == 0:
      return False
  return True

def sum_of_primes(n):
  """Calculates the sum of the first n prime numbers."""
  primes = []
  i = 2
  while len(primes) < n:
    if is_prime(i):
      primes.append(i)
    i += 1
  return sum(primes)

# Calculate the sum of the first 50 prime numbers
sum_of_first_50_primes = sum_of_primes(50)

print(f"The sum of the first 50 prime numbers is: {sum_of_first_50_primes}")
```

**Output:**

```
The sum of the first 50 prime numbers is: 5117
```
Usar a execução de código no chat
Também é possível usar a execução de código como parte de uma conversa.
from google import genai
from google.genai import types

client = genai.Client(api_key="
GEMINI_API_KEY")

chat = client.chats.create(
    model='gemini-2.0-flash',
    config=types.GenerateContentConfig(
      tools=[types.Tool(
        code_execution=types.ToolCodeExecution
      )]
    )
)

response = chat.send_message("Can you run some code to bogo-sort this list of numbers?: [2,34,1,65,4]")
display_code_execution_result(response)
A conversa pode continuar assim:
Entendo que você quer que eu classifique a lista [2, 34, 1, 65, 4] com a regra de Bogo. O Bogo-sort é um algoritmo de classificação notoriamente ineficiente. Ele funciona embaralhando a lista repetidamente até que ela seja classificada. Devido ao desempenho extremamente ruim, ele não é prático para listas de qualquer tamanho significativo.
No entanto, para fins de demonstração, posso executar uma versão simplificada para um número muito limitado de iterações, apenas para mostrar o processo. Posso concluir?
response = chat.send_message("Yes, please create the code.")
display_code_execution_result(response)
Ok,vou usar uma função que embaralha a lista e verifica se ela está classificada. Vou executar por um máximo de 10 iterações. …
Entrada/saída (E/S)
A partir do Gemini 2.0 Flash, a execução de código oferece suporte à entrada de arquivos e à saída de gráficos. Com esses novos recursos de entrada e saída, você pode fazer upload de arquivos CSV e de texto, fazer perguntas sobre os arquivos e gerar gráficos do Matplotlib como parte da resposta.
Preços de E/S
Ao usar a E/S de execução de código, você é cobrado por tokens de entrada e de saída:
Tokens de entrada:
Comando do usuário
Tokens de saída:
Código gerado pelo modelo
Saída da execução do código no ambiente de código
Resumo gerado pelo modelo
Detalhes de E/S
Ao trabalhar com E/S de execução de código, esteja ciente dos seguintes detalhes técnicos:
O tempo de execução máximo do ambiente de código é de 30 segundos.
Se o ambiente de código gerar um erro, o modelo poderá decidir regenerar a saída do código. Isso pode acontecer até cinco vezes.
O tamanho máximo de entrada de arquivo é limitado pela janela de token do modelo. No AI Studio, usando o Gemini Flash 2.0, o tamanho máximo do arquivo de entrada é de 1 milhão de tokens (cerca de 2 MB para arquivos de texto dos tipos de entrada aceitos). Se você enviar um arquivo muito grande, o AI Studio não vai permitir que ele seja enviado.
Interação única Bidirecional (API Multimodal Live)
Modelos com suporte Todos os modelos Gemini 2.0 Somente modelos experimentais do Flash
Tipos de entrada de arquivo aceitos .png, .jpeg, .csv, .xml, .cpp, .java, .py, .js, .ts .png, .jpeg, .csv, .xml, .cpp, .java, .py, .js, .ts
Bibliotecas de plotagem com suporte Matplotlib Matplotlib
Uso de várias ferramentas Não Sim
Faturamento
Não há cobrança extra para ativar a execução de código na API Gemini. A cobrança será feita com base na taxa atual de tokens de entrada e saída com base no modelo Gemini que você está usando.
Confira algumas outras informações sobre o faturamento para execução de código:
Você só vai receber cobrança uma vez pelos tokens de entrada transmitidos ao modelo e pelos tokens de saída finais retornados pelo modelo.
Os tokens que representam o código gerado são contados como tokens de saída. O código gerado pode incluir saídas de texto e multimodais, como imagens.
Os resultados da execução do código também são contados como tokens de saída.
O modelo de faturamento é mostrado no diagrama a seguir:
A cobrança é feita com base na taxa atual de tokens de entrada e saída com base no modelo Gemini que você está usando.
Se o Gemini usar a execução de código ao gerar a resposta, o comando original, o código gerado e o resultado do código executado serão rotulados como tokens intermediários e cobrados como tokens de entrada.
O Gemini gera um resumo e retorna o código gerado, o resultado do código executado e o resumo final. Eles são cobrados como tokens de saída.
A API Gemini inclui uma contagem de tokens intermediários na resposta da API para que você saiba por que está recebendo tokens de entrada adicionais além do comando inicial.
Limitações
O modelo só pode gerar e executar código. Ele não pode retornar outros artefatos, como arquivos de mídia.
Em alguns casos, a ativação da execução de código pode levar a regressões em outras áreas da saída do modelo (por exemplo, na escrita de uma história).
Há alguma variação na capacidade dos diferentes modelos de usar a execução do código com sucesso.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_31.txt ---

URL: https://ai.google.dev/gemini-api/docs/structured-output

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Gerar saída estruturada com a API Gemini
Nesta página
Gerar JSON
Fornecer um esquema como texto no comando
Fornecer um esquema pela configuração do modelo
Usar um tipo enumerado para restringir a saída
Mais informações sobre os esquemas JSON
Ordenação de propriedades
Python
JavaScript
Go
REST

O Gemini gera texto não estruturado por padrão, mas alguns aplicativos exigem texto estruturado. Para esses casos de uso, você pode restringir o Gemini para responder com JSON, um formato de dados estruturado adequado para processamento automatizado. Também é possível restringir o modelo para responder com uma das opções especificadas em um tipo enumerado.
Confira alguns casos de uso que podem exigir uma saída estruturada do modelo:
Crie um banco de dados de empresas extraindo informações de artigos de jornal.
Extrair informações padronizadas dos currículos.
Extrair ingredientes de receitas e mostrar um link para um site de compras para cada ingrediente.
No comando, você pode pedir que o Gemini produza uma saída formatada em JSON, mas não há garantia de que o modelo vai produzir JSON e nada além disso. Para uma resposta mais determinística, transmita um esquema JSON específico em um campo responseSchema para que o Gemini sempre responda com uma estrutura esperada. Para saber mais sobre como trabalhar com esquemas, consulte Mais informações sobre esquemas JSON.
Este guia mostra como gerar JSON usando o método generateContent pelo SDK de sua preferência ou diretamente pela API REST. Os exemplos mostram entradas somente em texto, mas o Gemini também pode produzir respostas JSON para solicitações multimodais que incluem imagens, vídeos e áudio.
Gerar JSON
Quando o modelo está configurado para gerar JSON, ele responde a qualquer comando com saída formatada em JSON.
É possível controlar a estrutura da resposta JSON fornecendo um esquema. Há duas maneiras de fornecer um esquema ao modelo:
Como texto no comando
Como um esquema estruturado fornecido pela configuração do modelo
Fornecer um esquema como texto no comando
O exemplo a seguir solicita que o modelo retorne receitas de biscoitos em um formato JSON específico.
Como o modelo recebe a especificação de formato do texto no comando, você pode ter alguma flexibilidade na representação da especificação. Qualquer formato razoável para representar um esquema JSON pode funcionar.
from google import genai

prompt = """List a few popular cookie recipes in JSON format.

Use this JSON schema:

Recipe = {'recipe_name': str, 'ingredients': list[str]}
Return: list[Recipe]"""

client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents=prompt,
)

# Use the response as a JSON string.
print(response.text)
A saída pode ser semelhante a esta:
[
  {
    "recipe_name": "Chocolate Chip Cookies",
    "ingredients": [
      "2 1/4 cups all-purpose flour",
      "1 teaspoon baking soda",
      "1 teaspoon salt",
      "1 cup (2 sticks) unsalted butter, softened",
      "3/4 cup granulated sugar",
      "3/4 cup packed brown sugar",
      "1 teaspoon vanilla extract",
      "2 large eggs",
      "2 cups chocolate chips"
    ]
  },
  ...
]
Fornecer um esquema pela configuração do modelo
O exemplo a seguir faz o seguinte:
Cria um modelo configurado por um esquema para responder com JSON.
Solicita ao modelo que retorne receitas de biscoitos.
Esse método mais formal de declaração do esquema JSON oferece um controle mais preciso do que depender apenas do texto no comando.
Importante: ao trabalhar com esquemas JSON na API Gemini, a ordem das propriedades é importante. Para mais informações, consulte Ordem das propriedades.
from google import genai
from pydantic import BaseModel


class Recipe(BaseModel):
  recipe_name: str
  ingredients: list[str]


client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='List a few popular cookie recipes. Be sure to include the amounts of ingredients.',
    config={
        'response_mime_type': 'application/json',
        'response_schema': list[Recipe],
    },
)
# Use the response as a JSON string.
print(response.text)

# Use instantiated objects.
my_recipes: list[Recipe] = response.parsed
A saída pode ser semelhante a esta:
[
  {
    "recipe_name": "Chocolate Chip Cookies",
    "ingredients": [
      "1 cup (2 sticks) unsalted butter, softened",
      "3/4 cup granulated sugar",
      "3/4 cup packed brown sugar",
      "1 teaspoon vanilla extract",
      "2 large eggs",
      "2 1/4 cups all-purpose flour",
      "1 teaspoon baking soda",
      "1 teaspoon salt",
      "2 cups chocolate chips"
    ]
  },
  ...
]
Observação: os validadores Pydantic ainda não têm suporte. Se uma pydantic.ValidationError ocorrer, ela será suprimida, e .parsed poderá estar vazio/nulo.
Sintaxe de definição de esquema
Especifique o esquema da resposta JSON na propriedade response_schema da configuração do modelo. O valor de response_schema precisa ser:
Um tipo, como você usaria em uma anotação de tipo. Consulte o módulo typing do Python.
Uma instância de genai.types.Schema.
O dict equivalente a genai.types.Schema.
Definir um esquema com um tipo
A maneira mais fácil de definir um esquema é com um tipo direto. Esta é a abordagem usada no exemplo anterior:
config={'response_mime_type': 'application/json',
        'response_schema': list[Recipe]}
A biblioteca de cliente Python da API Gemini oferece suporte a esquemas definidos com os seguintes tipos (em que AllowedType é qualquer tipo permitido):
int
float
bool
str
list[AllowedType]
Para tipos estruturados:
dict[str, AllowedType]. Essa anotação declara que todos os valores do dicionário são do mesmo tipo, mas não especifica quais chaves devem ser incluídas.
Modelos Pydantic definidos pelo usuário. Essa abordagem permite especificar os nomes das chaves e definir diferentes tipos para os valores associados a cada uma das chaves, incluindo estruturas aninhadas.
Usar um tipo enumerado para restringir a saída
Em alguns casos, talvez você queira que o modelo escolha uma única opção de uma lista de opções. Para implementar esse comportamento, transmita um tipo enumerado no esquema. É possível usar uma opção de tipo enumerado em qualquer lugar em que seja possível usar um str no response_schema, porque um tipo enumerado é uma lista de strings. Assim como um esquema JSON, um tipo enumerado permite restringir a saída do modelo para atender aos requisitos do aplicativo.
Por exemplo, suponha que você esteja desenvolvendo um aplicativo para classificar instrumentos musicais em uma das cinco categorias: "Percussion", "String", "Woodwind", "Brass" ou ""Keyboard"". Você pode criar um tipo enumerado para ajudar nesta tarefa.
No exemplo abaixo, você transmite a classe de enumeração Instrument como response_schema, e o modelo precisa escolher a opção de enumeração mais adequada.
from google import genai
import enum

class Instrument(enum.Enum):
  PERCUSSION = "Percussion"
  STRING = "String"
  WOODWIND = "Woodwind"
  BRASS = "Brass"
  KEYBOARD = "Keyboard"

client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='What type of instrument is an oboe?',
    config={
        'response_mime_type': 'text/x.enum',
        'response_schema': Instrument,
    },
)

print(response.text)
# Woodwind
O SDK do Python vai traduzir as declarações de tipo para a API. No entanto, a API aceita um subconjunto do esquema da OpenAPI 3.0 (Esquema). Também é possível transmitir o esquema como JSON:
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='What type of instrument is an oboe?',
    config={
        'response_mime_type': 'text/x.enum',
        'response_schema': {
            "type": "STRING",
            "enum": ["Percussion", "String", "Woodwind", "Brass", "Keyboard"],
        },
    },
)

print(response.text)
# Woodwind
Além de problemas básicos de múltipla escolha, você pode usar um tipo enumerado em qualquer lugar em um esquema para JSON ou chamada de função. Por exemplo, você pode pedir ao modelo uma lista de títulos de receitas e usar um tipo enumerado Grade para dar a cada título uma nota de popularidade:
from google import genai

import enum
from pydantic import BaseModel

class Grade(enum.Enum):
    A_PLUS = "a+"
    A = "a"
    B = "b"
    C = "c"
    D = "d"
    F = "f"

class Recipe(BaseModel):
  recipe_name: str
  rating: Grade

client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='List 10 home-baked cookies and give them grades based on tastiness.',
    config={
        'response_mime_type': 'application/json',
        'response_schema': list[Recipe],
    },
)

print(response.text)
# [{"rating": "a+", "recipe_name": "Classic Chocolate Chip Cookies"}, ...]
Mais informações sobre os esquemas JSON
Ao configurar o modelo para retornar uma resposta JSON, você pode usar um objeto Schema para definir a forma dos dados JSON. O Schema representa um subconjunto selecionado do objeto de esquema da OpenAPI 3.0.
Confira uma representação pseudo-JSON de todos os campos Schema:
{
  "type": enum (Type),
  "format": string,
  "description": string,
  "nullable": boolean,
  "enum": [
    string
  ],
  "maxItems": string,
  "minItems": string,
  "properties": {
    string: {
      object (Schema)
    },
    ...
  },
  "required": [
    string
  ],
  "propertyOrdering": [
    string
  ],
  "items": {
    object (Schema)
  }
}
O Type do esquema precisa ser um dos tipos de dados da OpenAPI. Apenas um subconjunto de campos é válido para cada Type. A lista a seguir mapeia cada Type para campos válidos para esse tipo:
string: -> tipo enumerado, formato
integer -> formato
number -> formato
boolean
array -> minItems, maxItems, items
object -> properties, required, propertyOrdering, nullable
Confira alguns exemplos de esquemas que mostram combinações válidas de tipo e campo:
{ "type": "string", "enum": ["a", "b", "c"] }

{ "type": "string", "format": "date-time" }

{ "type": "integer", "format": "int64" }

{ "type": "number", "format": "double" }

{ "type": "boolean" }

{ "type": "array", "minItems": 3, "maxItems": 3, "items": { "type": ... } }

{ "type": "object",
  "properties": {
    "a": { "type": ... },
    "b": { "type": ... },
    "c": { "type": ... }
  },
  "nullable": true,
  "required": ["c"],
  "propertyOrdering": ["c", "b", "a"]
}
Para conferir a documentação completa dos campos do esquema conforme eles são usados na API Gemini, consulte a Referência do esquema.
Ordenação de propriedades
Ao trabalhar com esquemas JSON na API Gemini, a ordem das propriedades é importante. Por padrão, a API ordena as propriedades em ordem alfabética e não preserva a ordem em que as propriedades são definidas, embora os SDKs do Google Gen AI possam preservar essa ordem. Se você estiver fornecendo exemplos ao modelo com um esquema configurado e a ordem das propriedades dos exemplos não for consistente com a ordem das propriedades do esquema, a saída poderá ser incoerente ou inesperada.
Para garantir uma ordenação consistente e previsível das propriedades, use o campo propertyOrdering[] opcional.
"propertyOrdering": ["recipe_name", "ingredients"]
propertyOrdering[], que não é um campo padrão na especificação da OpenAPI, é uma matriz de strings usada para determinar a ordem das propriedades na resposta. Ao especificar a ordem das propriedades e fornecer exemplos com propriedades nessa mesma ordem, você pode melhorar a qualidade dos resultados.
Importante: para melhorar os resultados ao usar um esquema JSON, defina propertyOrdering[] e forneça exemplos com uma ordem de propriedade correspondente.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_32.txt ---

URL: https://ai.google.dev/gemini-api/docs/thinking

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Use o pensamento Gemini
Nesta página
Usar modelos de pensamento
Enviar uma solicitação básica
Conversas de pensamento com vários turnos
Usar ferramentas com modelos mentais
Ferramenta de pesquisa
Execução do código
Saída estruturada
Técnicas de estímulo para modelos de pensamento
O Gemini 2.5 Pro Experimental e o Gemini 2.0 Flash Thinking Experimental são modelos que usam um "processo de pensamento" interno durante a geração de respostas. Esse processo contribui para melhorar as habilidades de raciocínio e permite que eles resolvam tarefas complexas. Este guia mostra como usar modelos do Gemini com recursos de pensamento.
Teste a prévia do Gemini 2.5 Pro no Google AI Studio
Observação: "gemini-2.5-pro-preview-03-25" é um modelo faturado. Você pode continuar usando "gemini-2.5-pro-exp-03-25" no nível sem custo financeiro.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Usar modelos de pensamento
Os modelos com recursos de pensamento estão disponíveis no Google AI Studio e na API Gemini. O processo de pensamento é visível no Google AI Studio, mas não é fornecido como parte da saída da API.
Enviar uma solicitação básica
Python
JavaScript
Go
REST
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")
prompt = "Explain the concept of Occam's Razor and provide a simple, everyday example."
response = client.models.generate_content(
    model="gemini-2.5-pro-exp-03-25",  # or gemini-2.0-flash-thinking-exp
    contents=prompt
)

print(response.text)
Conversas de pensamento com vários turnos
Para considerar o histórico de chat anterior, use conversas de vários turnos.
Com os SDKs, é possível criar uma sessão de chat para gerenciar o estado da conversa.
Python
JavaScript
from google import genai

client = genai.Client(api_key='GEMINI_API_KEY')

chat = client.aio.chats.create(
    model='gemini-2.5-pro-preview-03-25',  # or gemini-2.0-flash-thinking-exp
)
response = await chat.send_message('What is your name?')
print(response.text)
response = await chat.send_message('What did you just say before this?')
print(response.text)
Usar ferramentas com modelos mentais
Os modelos de pensamento podem usar ferramentas para realizar ações além de gerar texto. Isso permite que eles interajam com sistemas externos, executem códigos ou acessem informações em tempo real, incorporando os resultados ao raciocínio e à resposta final.
Ferramenta de pesquisa
A ferramenta de pesquisa permite que o modelo consulte mecanismos de pesquisa externos para encontrar informações atualizadas ou além dos dados de treinamento. Isso é útil para perguntas sobre eventos recentes ou tópicos muito específicos.
Para configurar a ferramenta de pesquisa, consulte Configurar a ferramenta de pesquisa.
Comando:
What were the major scientific breakthroughs announced last week?
Resposta (usando a ferramenta de pesquisa):
Based on recent search results, here are some highlights from the past week in science:

...
(gemini-2.5-pro-exp-03-25)
Execução do código
A ferramenta de execução de código permite que o modelo gere e execute código Python para realizar cálculos, manipular dados ou resolver problemas que são melhor tratados algoritmicamente. O modelo recebe a saída do código e pode usá-la na resposta.
Para configurar a execução de código, consulte Ativar a execução de código no modelo.
Comando:
What is the sum of the first 50 prime numbers?
Generate and run Python code for the calculation, and make sure you get all 50.
Provide the final sum clearly.
Resposta (usando a ferramenta de execução de código):
Okay, I can calculate that. I will generate Python code to find the first 50 prime numbers and sum them up.

```python
def is_prime(num):
    if num < 2:
        return False
    for i in range(2, int(num**0.5) + 1):
        if num % i == 0:
            return False
    return True

primes = []
num = 2
while len(primes) < 50:
    if is_prime(num):
        primes.append(num)
    num += 1

total_sum = sum(primes)
print(total_sum)
```

Running the code...

Code Execution Result:
Outcome: OK
Output:

5117
Use code with caution.
The sum of the first 50 prime numbers is 5117.
(gemini-2.5-pro-exp-03-25)
Saída estruturada
Com a saída estruturada, é possível restringir o Gemini para responder com JSON, um formato de saída estruturado adequado para processamento automatizado. Isso é útil principalmente para integrar a saída do modelo aos aplicativos.
É possível especificar o formato diretamente no comando ou fornecer um esquema pela configuração do modelo.
Comando:
Provide a list of 3 famous physicists and their key contributions
in JSON format.
Use this JSON schema:

Physicist = {'name': str, 'contribution': str, 'era': str}
Return: list[Physicist]
Resposta (instruída para JSON):
```json
[
{
"name": "Albert Einstein",
"contribution": "Theory of Relativity (Special and General)",
"era": "Early 20th Century"
},
{
"name": "Isaac Newton",
"contribution": "Laws of Motion and Universal Gravitation",
"era": "Late 17th / Early 18th Century"
},
{
"name": "Marie Curie",
"contribution": "Pioneering research on radioactivity",
"era": "Late 19th / Early 20th Century"
}
]
```
(gemini-2.5-pro-preview-03-25)
Técnicas de estímulo para modelos de pensamento
A solicitação eficaz é crucial para maximizar os benefícios dos modelos de pensamento do Gemini. Esta seção descreve algumas práticas de estímulo para modelos de pensamento.
Primeiros passos
Comece com instruções gerais que descrevam o resultado desejado. Comece com uma solicitação simples e observe as ideias iniciais do modelo sobre como enfrentar o desafio.
Comando:
Describe the most unusual or striking architectural feature you've ever seen in a building or structure.
Resposta:
<...>
The most unusual architectural feature that has truly stayed with me is the "floating roof" of the
 Heydar Aliyev Center in Baku, Azerbaijan, designed by Zaha Hadid Architects.

Visually, it's breathtaking. Imagine a vast, undulating landscape of pure white, seemingly draped
over the building. It's not just a roof in the traditional sense; it's an extension of the ground,
flowing seamlessly upwards and over the building's various spaces before curving back down to meet
the earth again. There are no sharp angles, no rigid lines. Instead, everything is fluid, organic,
and continuous. It resembles a giant, pristine white wave frozen in motion, or perhaps a sand dune
sculpted by an unseen wind.
<...>
(gemini-2.5-pro-exp-03-25)
Fornecer instruções detalhadas
Se a tentativa inicial não gerar o resultado desejado, refine o comando fornecendo instruções mais explícitas para guiar o Gemini pelo processo de solução de problemas e ter uma abordagem mais focada. Isso permite que você oriente a compreensão inicial do modelo da tarefa com sugestões e orientações explícitas.
Comando:
Now imagine that architectural feature is not just for looks, but has a specific function or
purpose related to the building's environment or the people who use it. Explain what that
function could be and how it enhances the building's overall design and usability.
Resposta:
<...>
Let's imagine that the "floating roof" of the Heydar Aliyev Center is not purely aesthetic but
serves a crucial environmental and user-centric function: it's designed as a sophisticated climate
moderator and natural ventilation system for the Baku environment.

Here's how this function would work and enhance the building:

Function: Passive Climate Control and Natural Ventilation System

Shading and Solar Heat Mitigation: The undulating curves of the white GFRC roof are strategically
shaped and oriented to provide optimal shading throughout the day, year-round. Baku experiences
intense sun, especially during the summer. The overhanging curves, acting like giant brise-soleils,
would block direct sunlight from hitting the building's glass facade, significantly reducing solar
heat gain. The varying heights and depths of the curves would create dynamic shade patterns, ensuring
that different parts of the building are shaded at different times of the day, optimizing comfort
and reducing the need for excessive air conditioning. The white color of the GFRC further enhances
this by reflecting a large portion of the solar radiation.
<...>
(gemini-2.5-pro-exp-03-25)
Comandos de multisaída com pensamento
A solicitação de várias fotos em conjunto com o pensamento pode melhorar ainda mais a compreensão do Gemini e a precisão das respostas. Dê vários exemplos de pares de entrada e saída, demonstrando o comportamento e o formato de saída desejados no comando.
Comando:
Example 1:
User: What is the tallest mountain in the world?
Assistant: Mount Everest

Example 2:
User: What is the largest ocean?
Assistant: Pacific Ocean

User: What is the longest river in the world?
Assistant:
Resposta:
Amazon River
(gemini-2.5-pro-exp-03-25)
Como definir saída e comportamento
Ao criar um aplicativo em que os usuários interagem diretamente com o modelo, é recomendável fornecer orientações sobre como a saída e as respostas do Gemini vão soar e ser formatadas.
Instruções do sistema
As instruções do sistema são um conjunto de instruções que o modelo processa antes de processar comandos. Elas são recuperadas sempre que o modelo é solicitado e informam como você quer que ele se comporte e responda. Por exemplo, você pode incluir itens como o papel ou perfil, informações contextuais e instruções de formatação.
Comando:
System Instruction: You are a helpful and concise coding tutor. Always provide code examples and explain them briefly.

User Prompt: Explain what is a closure in Javascript and give an example.
Resposta:
function outerFunction(outerVar) {
 function innerFunction(innerVar) {
 console.log(outerVar); // Accessing outerVar from outerFunction's scope
 console.log(innerVar);
 }
 return innerFunction;
 }

 const closureExample = outerFunction('I am from outer');
 closureExample('I am from inner');

Explanation:

A closure is created when a function (innerFunction in this example) is defined inside another function
(outerFunction) and the inner function remembers and has access to the variables from the outer
function's scope, even after the outer function has finished executing.

In the example:

outerFunction is called with 'I am from outer' and returns innerFunction.

closureExample now holds a reference to innerFunction.

When closureExample('I am from inner') is called, innerFunction executes.

Even though outerFunction has already finished, innerFunction can still access and use outerVar
(which is 'I am from outer') because of the closure.

In essence, the innerFunction "closes over" the variables of its outer function's scope, creating
a closure.
(gemini-2.5-pro-exp-03-25)
Verificação e reflexão
Inclua etapas de verificação específicas nas instruções do sistema ou nos seus comandos. Por exemplo, peça ao Gemini para verificar as fontes, revisar o raciocínio, identificar possíveis erros e verificar a resposta final.
Comando:
Verify the following statement and provide your sources: The capital of Brazil is Rio de Janeiro.
Resposta:
The statement "The capital of Brazil is Rio de Janeiro" is incorrect.

The current capital of Brazil is Brasília.

Rio de Janeiro was the capital of Brazil for a significant period, from 1763 to 1960. However, the
capital was moved to Brasília in 1960 as part of a plan to develop the country's interior and create
a more centrally located capital.

Verification and Sources:

You can easily verify this information from numerous reliable sources:

Encyclopedias:

Britannica: Searching for "Brazil" on Britannica will clearly state Brasília as the capital.

https://www.britannica.com/place/Brazil (Look for the "Capital" information in the introductory summary or "Geography" section)

Wikipedia: The Wikipedia article for "Brazil" also states Brasília as the capital.

https://en.wikipedia.org/wiki/Brazil (Look in the infobox or introductory section)

Government and Official Sources:

CIA World Factbook: This is a highly reliable source for country information. Searching for "Brazil"
will list Brasília as the capital.

https://www.cia.gov/the-world-factbook/countries/brazil/ (Look under "Government" > "Capital")

Official Website of the Brazilian Government (if accessible and in English): While navigating official
government websites can sometimes be complex, they would definitively list Brasília as the capital.

Geographic Resources:

National Geographic: Their website and publications will confirm Brasília as the capital of Brazil.

Atlases and Geography Textbooks: Any modern atlas or geography textbook will list Brasília as the capital.

Why the confusion?

The confusion might arise because:

Rio de Janeiro is a very famous Brazilian city: It's a major tourist destination, known for its
beaches, Carnival, and iconic landmarks like Christ the Redeemer. Its past status as capital adds
to its historical significance and public recognition.

Historical context: Rio de Janeiro was the capital for a long time. People who learned about Brazil
in the past might remember it as the capital.

In conclusion, the statement is false. The capital of Brazil is Brasília, not Rio de Janeiro. Rio
de Janeiro was the former capital but is no longer the current capital.

You can confidently use the sources listed above to verify this information.
(gemini-2.5-pro-exp-03-25)
Depuração e direção
O Google AI Studio oferece aos desenvolvedores acesso aos pensamentos do modelo na interface. Isso é útil para desenvolvedores que analisam o comando ao depurar:
Analisar o processo de pensamento
Analise cuidadosamente o processo de pensamento do Gemini para identificar as áreas em que ele pode ter se perdido. Essa análise pode fornecer dicas valiosas para refinar suas solicitações e receber a resposta esperada de forma consistente no seu aplicativo.
Exemplo de cenário: se o processo de pensamento do Gemini mostrar que ele entendeu mal uma etapa em uma instrução complexa, você pode refinar a instrução para esclarecer essa etapa específica.
Comando:
Step 1: Summarize the following article about quantum physics.
Step 2: Translate the summary into Spanish.
Step 3: Extract the key entities from the Spanish summary.

Article: ... [Article Text] ...
Análise do processo de pensamento do Gemini (exemplo)
The user wants me to process an article about Google's new quantum chip called Willow in three steps:
Step 1: Summarize the article.
Step 2: Translate the summary into Spanish.
Step 3: Extract the key entities from the Spanish summary.

Let's break down each step.

Step 1: Summarize the article.
I need to read the article and identify the main points. The article is about Google's new quantum
chip, Willow, and its achievements. The key achievements are:

Exponential error reduction as qubits scale up.

Outperforming supercomputers in a benchmark computation (RCS).

Willow is a step towards commercially relevant quantum computing.

It's the first system below threshold for quantum error correction.

It achieved a benchmark computation in under 5 minutes that would take a supercomputer 10 septillion years.

It was fabricated in a new facility.

It has state-of-the-art performance and high quality qubits.

Google is looking towards real-world applications with Willow.

Quantum computing will benefit AI.

I will synthesize these points into a concise summary.

Step 2: Translate the summary into Spanish.
Once I have the summary in English, I will translate it into Spanish. I need to ensure the translation
is accurate and natural-sounding in Spanish.

Step 3: Extract the key entities from the Spanish summary.
After translating the summary, I will identify and extract the key entities. Key entities are typically
nouns or noun phrases that represent important objects, concepts, or actors. In this context, they
will likely include:

Names of chips (Willow, Sycamore)

Companies/Organizations (Google Quantum AI, Google Research)

Technologies (quantum chip, quantum computer, qubits, quantum error correction, superconducting
quantum system, classical computers, supercomputers, AI)

Benchmarks (random circuit sampling, RCS)

People (Julian Kelly, Peter Shor, David Deutsch, Sergio Boixo, Hartmut Neven, John Preskill)

Concepts (exponential error reduction, below threshold, beyond breakeven, state-of-the-art performance,
commercially relevant applications, quantum mechanics, multiverse, T1 times, system benchmarks,
algorithmic benchmarks)

I will need to carefully review the Spanish summary to identify these entities and list them out.
Provide Corrective Feedback
If you observe errors or inconsistencies in Gemini's reasoning, provide corrective feedback in your prompt and/or System Instructions to anticipate where the model's response may deviate from your desired outcome.
Prompt:
You are an expert in botany. When asked to identify a plant, focus on leaf shape, flower structure, and stem characteristics.

Identify this plant based on these characteristics: ... [Plant Characteristics Description] ...

Previous incorrect response focused on habitat only. Please disregard habitat and focus on morphology.
Instrução refinada (se necessário com base no processo de pensamento):
Previous incorrect response focused on habitat only. Please disregard habitat and focus on morphology.
Resposta:
Tabebuia vellosoi
(gemini-2.5-pro-exp-03-25)
Como aproveitar ao máximo os formatos longos e o pensamento longo
O pensamento gera "pensamentos" como parte da saída de token que mostra o raciocínio detalhado do Gemini. Para aproveitar ao máximo essas saídas:
Analisar o raciocínio
Preste atenção ao processo de raciocínio do Gemini (disponível na interface do Google AI Studio), como ele dividiu a tarefa e as escolhas feitas para a saída. Isso pode ajudar você a entender como ele chegou à conclusão.
Orientação sobre o raciocínio
Se a saída desejada for particularmente longa, forneça mais orientações no comando para limitar a quantidade de pensamento necessária para realizar a tarefa apresentada no comando. Isso permite que você reserve mais da saída de token para sua resposta.
Exemplo: para um relatório detalhado, especifique seções e subseções no comando para orientar o pensamento do Gemini e estruturar o resultado de maneira eficiente.
Comando:
Generate a detailed report on the impact of climate change on coastal ecosystems.

Report Structure:

Introduction

Rising Sea Levels
2.1. Impact on Mangroves
2.2. Impact on Coral Reefs

Ocean Acidification
3.1. Impact on Shellfish
3.2. Impact on Plankton

Extreme Weather Events
4.1. Increased Storm Intensity
4.2. Coastal Erosion

Conclusion

Provide detailed analysis within each section.
Resposta:
<...>
Climate Change Impact on Coastal Ecosystems: A Detailed Report

1. Introduction

Coastal ecosystems, the dynamic interface between land and sea, are among the most productive and
biodiverse environments on Earth. They provide crucial ecosystem services, including coastal protection,
fisheries, carbon sequestration, and support for a vast array of species. However, these vital
ecosystems are increasingly threatened by the multifaceted impacts of climate change. Driven by
anthropogenic greenhouse gas emissions, climate change is manifesting in several interconnected ways
that are profoundly altering the physical and chemical conditions of coastal environments. This report
will delve into the key impacts of climate change on coastal ecosystems, focusing on rising sea levels,
ocean acidification, and extreme weather events, and their specific consequences for critical habitats
like mangroves and coral reefs, and key organisms like shellfish and plankton. Understanding these
impacts is crucial for developing effective conservation and management strategies to mitigate the
damage and enhance the resilience of these invaluable ecosystems.

2. Rising Sea Levels

Rising sea levels are a direct and significant consequence of global warming, driven by thermal
expansion of seawater and the melting of land ice (glaciers and ice sheets). This phenomenon poses a
direct threat to low-lying coastal ecosystems by inundating habitats, altering salinity regimes, and
increasing erosion rates. The rate of sea level rise is accelerating, and projections for the 21st
century indicate a continued upward trend, with potentially devastating consequences for coastal
environments.

2.1. Impact on Mangroves

Mangrove forests are unique coastal ecosystems found in tropical and subtropical intertidal zones.
They provide numerous benefits, including coastal protection against storms, nursery grounds for
fish and invertebrates, and significant carbon sequestration...
<...>
(gemini-2.5-pro-exp-03-25)
A seguir
Teste a prévia do Gemini 2.5 Pro no Google AI Studio.
Para mais informações sobre a prévia do Gemini 2.5 Pro e o Gemini Flash 2.0 Thinking, acesse a página do modelo.
Confira mais exemplos no manual de instruções do Thinking.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_33.txt ---

URL: https://ai.google.dev/gemini-api/docs/function-calling

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Chamada de função com a API Gemini
Nesta página
Como a chamada de função funciona
Etapa 1: definir a declaração de função
Etapa 2: chamar o modelo com declarações de função
Etapa 3: executar o código da função set_light_values
Etapa 4: criar uma resposta amigável ao usuário com o resultado da função e chamar o modelo novamente
A chamada de função permite conectar modelos a ferramentas e APIs externas. Em vez de gerar respostas de texto, o modelo entende quando chamar funções e fornece os parâmetros necessários para executar ações reais. Isso permite que o modelo funcione como uma ponte entre a linguagem natural e as ações e dados do mundo real. As chamadas de função têm três casos de uso principais:
Aumentar o conhecimento:acesse informações de fontes externas, como bancos de dados, APIs e bases de conhecimento.
Ampliar os recursos:use ferramentas externas para realizar cálculos e ampliar as limitações do modelo, como usar uma calculadora ou criar gráficos.
Realizar ações:interagir com sistemas externos usando APIs, como agendar compromissos, criar faturas, enviar e-mails ou controlar dispositivos de casa inteligente.
Receber informações sobre o clima
Agendar reunião
Criar gráfico
Python
JavaScript
REST
 from google import genai
 from google.genai import types

 # Define the function declaration for the model
 schedule_meeting_function = {
     "name": "schedule_meeting",
     "description": "Schedules a meeting with specified attendees at a given time and date.",
     "parameters": {
         "type": "object",
         "properties": {
             "attendees": {
                 "type": "array",
                 "items": {"type": "string"},
                 "description": "List of people attending the meeting.",
             },
             "date": {
                 "type": "string",
                 "description": "Date of the meeting (e.g., '2024-07-29')",
             },
             "time": {
                 "type": "string",
                 "description": "Time of the meeting (e.g., '15:00')",
             },
             "topic": {
                 "type": "string",
                 "description": "The subject or topic of the meeting.",
             },
         },
         "required": ["attendees", "date", "time", "topic"],
     },
 }

 # Configure the client and tools
 client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
 tools = types.Tool(function_declarations=[schedule_meeting_function])
 config = types.GenerateContentConfig(tools=[tools])

 # Send request with function declarations
 response = client.models.generate_content(
     model="gemini-2.0-flash",
     contents="Schedule a meeting with Bob and Alice for 03/14/2025 at 10:00 AM about the Q3 planning.",
     config=config,
 )

 # Check for a function call
 if response.candidates[0].content.parts[0].function_call:
     function_call = response.candidates[0].content.parts[0].function_call
     print(f"Function to call: {function_call.name}")
     print(f"Arguments: {function_call.args}")
     #  In a real app, you would call your function here:
     #  result = schedule_meeting(**function_call.args)
 else:
     print("No function call found in the response.")
     print(response.text)
Como a chamada de função funciona
A chamada de função envolve uma interação estruturada entre o aplicativo, o modelo e as funções externas. Confira os detalhes do processo:
Definir a declaração de função:defina a declaração de função no código do aplicativo. As declarações de função descrevem o nome, os parâmetros e a finalidade da função para o modelo.
Chamar o LLM com declarações de função:envie o comando do usuário com as declarações de função para o modelo. Ele analisa a solicitação e determina se uma chamada de função seria útil. Nesse caso, ele responde com um objeto JSON estruturado.
Executar o código da função (sua responsabilidade): o modelo não executa a função. É responsabilidade do seu aplicativo processar a resposta e verificar a chamada de função, se
Sim: extraia o nome e os argumentos da função e execute a função correspondente no seu aplicativo.
Não:o modelo forneceu uma resposta de texto direta ao comando. Esse fluxo é menos enfatizado no exemplo, mas é um resultado possível.
Criar uma resposta amigável ao usuário:se uma função foi executada, capture o resultado e o envie de volta ao modelo em uma próxima vez na conversa. Ele vai usar o resultado para gerar uma resposta final fácil de usar que incorpora as informações da chamada de função.
Esse processo pode ser repetido em várias rodadas, permitindo interações e fluxos de trabalho complexos. O modelo também oferece suporte à chamada de várias funções em uma única vez (chamada de função paralela) e em sequência (chamada de função composta).
Etapa 1: definir a declaração de função
Defina uma função e a declaração dela no código do aplicativo para permitir que os usuários definam valores de luz e façam uma solicitação de API. Essa função pode chamar serviços ou APIs externos.
Python
JavaScript
from google.genai import types

# Define a function that the model can call to control smart lights
set_light_values_declaration = {
    "name": "set_light_values",
    "description": "Sets the brightness and color temperature of a light.",
    "parameters": {
        "type": "object",
        "properties": {
            "brightness": {
                "type": "integer",
                "description": "Light level from 0 to 100. Zero is off and 100 is full brightness",
            },
            "color_temp": {
                "type": "string",
                "enum": ["daylight", "cool", "warm"],
                "description": "Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.",
            },
        },
        "required": ["brightness", "color_temp"],
    },
}

# This is the actual function that would be called based on the model's suggestion
def set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:
    """Set the brightness and color temperature of a room light. (mock API).

    Args:
        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness
        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.

    Returns:
        A dictionary containing the set brightness and color temperature.
    """
    return {"brightness": brightness, "colorTemperature": color_temp}
Etapa 2: chamar o modelo com declarações de função
Depois de definir as declarações de função, você pode solicitar que o modelo use a função. Ele analisa as declarações de comando e função e decide responder diretamente ou chamar uma função. Se uma função for chamada, o objeto de resposta vai conter uma sugestão de chamada de função.
Python
JavaScript
from google import genai

# Generation Config with Function Declaration
tools = types.Tool(function_declarations=[set_light_values_declaration])
config = types.GenerateContentConfig(tools=[tools])

# Configure the client
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# Define user prompt
contents = [
    types.Content(
        role="user", parts=[types.Part(text="Turn the lights down to a romantic level")]
    )
]

# Send request with function declarations
response = client.models.generate_content(
    model="gemini-2.0-flash", config=config, contents=contents
)

print(response.candidates[0].content.parts[0].function_call)
O modelo retorna um objeto functionCall em um esquema compatível com a OpenAPI, especificando como chamar uma ou mais das funções declaradas para responder à pergunta do usuário.
Python
JavaScript
id=None args={'color_temp': 'warm', 'brightness': 25} name='set_light_values'
Etapa 3: executar o código da função set_light_values
Extraia os detalhes da chamada de função da resposta do modelo, analise os argumentos e execute a função set_light_values no código.
Python
JavaScript
# Extract tool call details
tool_call = response.candidates[0].content.parts[0].function_call

if tool_call.name == "set_light_values":
    result = set_light_values(**tool_call.args)
    print(f"Function execution result: {result}")
Etapa 4: criar uma resposta amigável ao usuário com o resultado da função e chamar o modelo novamente
Por fim, envie o resultado da execução da função de volta ao modelo para que ele possa incorporar essas informações na resposta final ao usuário.
Python
JavaScript
# Create a function response part
function_response_part = types.Part.from_function_response(
    name=tool_call.name,
    response={"result": result},
)

# Append function call and result of the function execution to contents
contents.append(types.Content(role="model", parts=[types.Part(function_call=tool_call)])) # Append the model's function call message
contents.append(types.Content(role="user", parts=[function_response_part])) # Append the function response

final_response = client.models.generate_content(
    model="gemini-2.0-flash",
    config=config,
    contents=contents,
)

print(final_response.text)
Isso conclui o fluxo de chamada de função. O modelo usou a função set_light_values para realizar a ação de solicitação do usuário.
Declarações de função
Ao implementar a chamada de função em um comando, você cria um objeto tools, que contém um ou mais function declarations. Você define funções usando JSON, especificamente com um subconjunto selecionado do formato de esquema da OpenAPI. Uma única declaração de função pode incluir os seguintes parâmetros:
name (string): um nome exclusivo para a função (get_weather_forecast, send_email). Use nomes descritivos sem espaços ou caracteres especiais (use sublinhados ou letras em caixa alta e baixa).
description (string): uma explicação clara e detalhada do propósito e dos recursos da função. Isso é crucial para que o modelo entenda quando usar a função. Seja específico e dê exemplos se for útil ("Encontra cinemas com base na localização e, opcionalmente, no título do filme que está em cartaz no momento").
parameters (objeto): define os parâmetros de entrada esperados pela função.
type (string): especifica o tipo de dados geral, como object.
properties (objeto): lista parâmetros individuais, cada um com:
type (string): o tipo de dados do parâmetro, como string, integer, boolean, array.
description (string): uma descrição da finalidade e do formato do parâmetro. Dê exemplos e restrições ("A cidade e o estado, por exemplo, "São Paulo, SP" ou um CEP, por exemplo, '95616'.").
enum (matriz, opcional): se os valores do parâmetro forem de um conjunto fixo, use "enum" para listar os valores permitidos em vez de apenas descrevê-los na descrição. Isso melhora a precisão ("enum": ["daylight", "cool", "warm"]).
required (matriz): uma matriz de strings que lista os nomes dos parâmetros obrigatórios para a função funcionar.
Chamada de função paralela
Além de chamar uma função de turno único, você também pode chamar várias funções de uma só vez. A chamada de função paralela permite executar várias funções de uma vez e é usada quando as funções não dependem uma da outra. Isso é útil em cenários como a coleta de dados de várias fontes independentes, como a recuperação de detalhes do cliente de diferentes bancos de dados ou a verificação de níveis de inventário em vários armazéns ou a realização de várias ações, como a conversão de um apartamento em um disco.
Python
JavaScript
power_disco_ball = {
    "name": "power_disco_ball",
    "description": "Powers the spinning disco ball.",
    "parameters": {
        "type": "object",
        "properties": {
            "power": {
                "type": "boolean",
                "description": "Whether to turn the disco ball on or off.",
            }
        },
        "required": ["power"],
    },
}

start_music = {
    "name": "start_music",
    "description": "Play some music matching the specified parameters.",
    "parameters": {
        "type": "object",
        "properties": {
            "energetic": {
                "type": "boolean",
                "description": "Whether the music is energetic or not.",
            },
            "loud": {
                "type": "boolean",
                "description": "Whether the music is loud or not.",
            },
        },
        "required": ["energetic", "loud"],
    },
}

dim_lights = {
    "name": "dim_lights",
    "description": "Dim the lights.",
    "parameters": {
        "type": "object",
        "properties": {
            "brightness": {
                "type": "number",
                "description": "The brightness of the lights, 0.0 is off, 1.0 is full.",
            }
        },
        "required": ["brightness"],
    },
}
Chame o modelo com uma instrução que possa usar todas as ferramentas especificadas. Este exemplo usa uma tool_config. Para saber mais, leia sobre como configurar a chamada de função.
Python
JavaScript
from google import genai
from google.genai import types

# Set up function declarations
house_tools = [
    types.Tool(function_declarations=[power_disco_ball, start_music, dim_lights])
]

config = {
    "tools": house_tools,
    "automatic_function_calling": {"disable": True},
    # Force the model to call 'any' function, instead of chatting.
    "tool_config": {"function_calling_config": {"mode": "any"}},
}

# Configure the client
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

chat = client.chats.create(model="gemini-2.0-flash", config=config)
response = chat.send_message("Turn this place into a party!")

# Print out each of the function calls requested from this single call
print("Example 1: Forced function calling")
for fn in response.function_calls:
    args = ", ".join(f"{key}={val}" for key, val in fn.args.items())
    print(f"{fn.name}({args})")
Cada um dos resultados impressos reflete uma única chamada de função solicitada pelo modelo. Para enviar os resultados de volta, inclua as respostas na mesma ordem em que foram solicitadas.
O SDK do Python oferece suporte a um recurso chamado chamada de função automática, que converte a função Python em declarações, processa a execução da chamada de função e o ciclo de resposta para você. Confira abaixo um exemplo do nosso caso de uso do disco.
Observação: no momento, a chamada de função automática é um recurso exclusivo do SDK do Python.
Python
from google import genai
from google.genai import types

# Actual implementation functions
def power_disco_ball_impl(power: bool) -> dict:
    """Powers the spinning disco ball.

    Args:
        power: Whether to turn the disco ball on or off.

    Returns:
        A status dictionary indicating the current state.
    """
    return {"status": f"Disco ball powered {'on' if power else 'off'}"}

def start_music_impl(energetic: bool, loud: bool) -> dict:
    """Play some music matching the specified parameters.

    Args:
        energetic: Whether the music is energetic or not.
        loud: Whether the music is loud or not.

    Returns:
        A dictionary containing the music settings.
    """
    music_type = "energetic" if energetic else "chill"
    volume = "loud" if loud else "quiet"
    return {"music_type": music_type, "volume": volume}

def dim_lights_impl(brightness: float) -> dict:
    """Dim the lights.

    Args:
        brightness: The brightness of the lights, 0.0 is off, 1.0 is full.

    Returns:
        A dictionary containing the new brightness setting.
    """
    return {"brightness": brightness}

config = {
    "tools": [power_disco_ball_impl, start_music_impl, dim_lights_impl],
}

chat = client.chats.create(model="gemini-2.0-flash", config=config)
response = chat.send_message("Do everything you need to this place into party!")

print("\nExample 2: Automatic function calling")
print(response.text)
# I've turned on the disco ball, started playing loud and energetic music, and dimmed the lights to 50% brightness. Let's get this party started!
Chamada de função com composição
O Gemini 2.0 oferece suporte à chamada de função com composição, o que significa que o modelo pode encadear várias chamadas de função. Por exemplo, para responder "Pegar a temperatura no meu local atual", a API Gemini pode invocar uma função get_current_location() e uma função get_weather() que use o local como parâmetro.
Observação: no momento, a chamada de função com estrutura é um recurso exclusivo da API Live. A declaração da função run(), que processa a configuração assíncrona do WebSocket, é omitida para encurtar.
Python
JavaScript
# Light control schemas
turn_on_the_lights_schema = {'name': 'turn_on_the_lights'}
turn_off_the_lights_schema = {'name': 'turn_off_the_lights'}

prompt = """
  Hey, can you write run some python code to turn on the lights, wait 10s and then turn off the lights?
  """

tools = [
    {'code_execution': {}},
    {'function_declarations': [turn_on_the_lights_schema, turn_off_the_lights_schema]}
]

await run(prompt, tools=tools, modality="AUDIO")
Modos de chamada de função
A API Gemini permite controlar como o modelo usa as ferramentas fornecidas (declarações de função). Mais especificamente, é possível definir o modo no function_calling_config.
AUTO (Default): o modelo decide se vai gerar uma resposta de linguagem natural ou sugerir uma chamada de função com base no comando e no contexto. Esse é o modo mais flexível e recomendado para a maioria dos casos.
ANY: o modelo é restrito a sempre prever uma chamada de função e garantir a adesão ao esquema de função. Se allowed_function_names não for especificado, o modelo poderá escolher entre qualquer uma das declarações de função fornecidas. Se allowed_function_names for fornecido como uma lista, o modelo só poderá escolher entre as funções dessa lista. Use esse modo quando precisar de uma chamada de função em resposta a cada comando (se aplicável).
NONE: o modelo não pode fazer chamadas de função. Isso equivale a enviar uma solicitação sem declarações de função. Use essa opção para desativar temporariamente a chamada de função sem remover as definições de ferramentas.
Python
JavaScript
from google.genai import types

# Configure function calling mode
tool_config = types.ToolConfig(
    function_calling_config=types.FunctionCallingConfig(
        mode="ANY", allowed_function_names=["get_current_temperature"]
    )
)

# Create the generation config
config = types.GenerateContentConfig(
    temperature=0,
    tools=[tools],  # not defined here.
    tool_config=tool_config,
)
Chamada de função automática (somente Python)
Ao usar o SDK do Python, você pode fornecer funções do Python diretamente como ferramentas. O SDK converte automaticamente a função Python em declarações e processa a execução da chamada de função e o ciclo de resposta para você. O SDK do Python vai:
Detecta respostas de chamadas de função do modelo.
Chame a função Python correspondente no código.
Envia a resposta da função de volta ao modelo.
Retorna a resposta de texto final do modelo.
Para usar isso, defina sua função com dicas de tipo e um docstring e transmita a própria função (não uma declaração JSON) como uma ferramenta:
Python
from google import genai
from google.genai import types

# Define the function with type hints and docstring
def get_current_temperature(location: str) -> dict:
    """Gets the current temperature for a given location.

    Args:
        location: The city and state, e.g. San Francisco, CA

    Returns:
        A dictionary containing the temperature and unit.
    """
    # ... (implementation) ...
    return {"temperature": 25, "unit": "Celsius"}

# Configure the client and model
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))  # Replace with your actual API key setup
config = types.GenerateContentConfig(
    tools=[get_current_temperature]
)  # Pass the function itself

# Make the request
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="What's the temperature in London?",
    config=config,
)

print(response.text)  # The SDK handles the function call and returns the final text
É possível desativar a chamada automática de funções com:
Python
# To disable automatic function calling:
config = types.GenerateContentConfig(
    tools=[get_current_temperature],
    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)
)
Declaração de esquema de função automática
A extração automática de esquemas de funções do Python não funciona em todos os casos. Por exemplo, ele não processa casos em que você descreve os campos de um objeto-dicionário aninhado. A API pode descrever qualquer um dos seguintes tipos:
Python
AllowedType = (int | float | bool | str | list['AllowedType'] | dict[str, AllowedType])
Para conferir como é o esquema inferido, converta-o usando from_callable:
Python
def multiply(a: float, b: float):
    """Returns a * b."""
    return a * b

fn_decl = types.FunctionDeclaration.from_callable(callable=multiply, client=client)

# to_json_dict() provides a clean JSON representation.
print(fn_decl.to_json_dict())
Uso de várias ferramentas: combine ferramentas nativas com chamadas de função
Com o Gemini 2.0, é possível ativar várias ferramentas que combinam ferramentas nativas com chamadas de função ao mesmo tempo. Confira um exemplo que ativa duas ferramentas, Grounding with Google Search e code execution, em uma solicitação usando a API Live.
Observação: no momento, o uso de várias ferramentas é um recurso exclusivo da API Live. A declaração da função run(), que processa a configuração assíncrona do WebSocket, é omitida para encurtar.
Python
JavaScript
# Multiple tasks example - combining lights, code execution, and search
prompt = """
  Hey, I need you to do three things for me.

    1.  Turn on the lights.
    2.  Then compute the largest prime palindrome under 100000.
    3.  Then use Google Search to look up information about the largest earthquake in California the week of Dec 5 2024.

  Thanks!
  """

tools = [
    {'google_search': {}},
    {'code_execution': {}},
    {'function_declarations': [turn_on_the_lights_schema, turn_off_the_lights_schema]} # not defined here.
]

# Execute the prompt with specified tools in audio modality
await run(prompt, tools=tools, modality="AUDIO")
Os desenvolvedores de Python podem testar isso no notebook de uso da ferramenta de API ao vivo.
Usar o protocolo de contexto de modelo (MCP)
O Protocolo de contexto do modelo (MCP) é um padrão aberto para conectar aplicativos de IA a ferramentas, fontes de dados e sistemas externos. O MCP fornece um protocolo comum para que os modelos acessem o contexto, como funções (ferramentas), fontes de dados (recursos) ou comandos predefinidos. É possível usar modelos com o servidor MCP usando os recursos de chamada de ferramentas.
Os servidores do MCP expõem as ferramentas como definições de esquema JSON, que podem ser usadas com declarações de função compatíveis com o Gemini. Isso permite que você use um servidor MCP com modelos Gemini diretamente. Confira um exemplo de como usar um servidor MCP local com o Gemini, o SDK para Python e o SDK mcp.
import asyncio
import os
from datetime import datetime
from google import genai
from google.genai import types
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# Create server parameters for stdio connection
server_params = StdioServerParameters(
    command="npx",  # Executable
    args=["-y", "@philschmid/weather-mcp"],  # Weather MCP Server
    env=None,  # Optional environment variables
)

async def run():
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Prompt to get the weather for the current day in London.
            prompt = f"What is the weather in London in {datetime.now().strftime('%Y-%m-%d')}?"
            # Initialize the connection between client and server
            await session.initialize()

            # Get tools from MCP session and convert to Gemini Tool objects
            mcp_tools = await session.list_tools()
            tools = [
                types.Tool(
                    function_declarations=[
                        {
                            "name": tool.name,
                            "description": tool.description,
                            "parameters": {
                                k: v
                                for k, v in tool.inputSchema.items()
                                if k not in ["additionalProperties", "$schema"]
                            },
                        }
                    ]
                )
                for tool in mcp_tools.tools
            ]

            # Send request to the model with MCP function declarations
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0,
                    tools=tools,
                ),
            )

            # Check for a function call
            if response.candidates[0].content.parts[0].function_call:
                function_call = response.candidates[0].content.parts[0].function_call
                print(function_call)
                # Call the MCP server with the predicted tool
                result = await session.call_tool(
                    function_call.name, arguments=function_call.args
                )
                print(result.content[0].text)
                # Continue as shown in step 4 of "How Function Calling Works"
                # and create a user friendly response
            else:
                print("No function call found in the response.")
                print(response.text)

# Start the asyncio event loop and run the main function
asyncio.run(run())
Modelos compatíveis
Os modelos experimentais não estão incluídos. Você pode encontrar os recursos na página Visão geral do modelo.
Modelo Chamada de função Chamada de função paralela Chamada de função com estrutura definida
(somente API Live)
Gemini 2.0 Flash ✔️ ✔️ ✔️
Gemini 2.0 Flash-Lite X X X
Gemini 1.5 Flash ✔️ ✔️ ✔️
Gemini 1.5 Pro ✔️ ✔️ ✔️
Práticas recomendadas
Descrição de funções e parâmetros:seja extremamente claro e específico nas descrições. O modelo depende deles para escolher a função correta e fornecer argumentos adequados.
Nomes:use nomes de função descritivos (sem espaços, pontos ou traços).
Tipagem forte:use tipos específicos (números inteiros, strings, enumerações) para parâmetros para reduzir erros. Se um parâmetro tiver um conjunto limitado de valores válidos, use um tipo enumerado.
Seleção de ferramentas:embora o modelo possa usar um número arbitrário de ferramentas, fornecer muitas delas pode aumentar o risco de selecionar uma ferramenta incorreta ou subótima. Para melhores resultados, tente fornecer apenas as ferramentas relevantes para o contexto ou a tarefa, mantendo o conjunto ativo em um máximo de 10 a 20. Considere a seleção dinâmica de ferramentas com base no contexto da conversa se você tiver um grande número de ferramentas.
Engenharia de comando:
Fornecer contexto: informe ao modelo qual é a função dele (por exemplo, "Você é um assistente de clima útil.").
Dar instruções: especificar como e quando usar funções (por exemplo, "Não adivinhe as datas. Use sempre uma data futura para as previsões.").
Incentive a explicação: instrua o modelo a fazer perguntas esclarecedoras, se necessário.
Temperatura:use uma temperatura baixa (por exemplo, 0) para chamadas de função mais determinísticas e confiáveis.
Validação:se uma chamada de função tiver consequências significativas (por exemplo, fazer um pedido), valide a chamada com o usuário antes de executá-la.
Tratamento de erros: implemente um tratamento de erros robusto nas suas funções para lidar com entradas inesperadas ou falhas de API. Retorne mensagens de erro informativas que o modelo pode usar para gerar respostas úteis ao usuário.
Segurança:tenha cuidado com a segurança ao chamar APIs externas. Use mecanismos de autenticação e autorização adequados. Evite expor dados sensíveis em chamadas de função.
Limites de tokens:as descrições e os parâmetros da função são contabilizados no limite de tokens de entrada. Se você estiver atingindo os limites de token, considere limitar o número de funções ou a duração das descrições, dividindo tarefas complexas em conjuntos de funções menores e mais focados.
Observações e limitações
Somente um subconjunto do esquema da OpenAPI é aceito.
Os tipos de parâmetros compatíveis no Python são limitados.
A chamada de função automática é um recurso exclusivo do SDK para Python.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_34.txt ---

URL: https://ai.google.dev/gemini-api/docs/document-processing

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Conheça os recursos de processamento de documentos com a API Gemini
Nesta página
Como fazer perguntas com PDFs
Detalhes técnicos
Entrada de PDF
Como dados inline
PDFs armazenados localmente
PDFs grandes
Vários PDFs
Listar arquivos
Python
JavaScript
Go
REST
A API Gemini oferece suporte à entrada de PDF, incluindo documentos longos (até 3.600 páginas). Os modelos Gemini processam PDFs com visão nativa e, portanto, são capazes de entender o conteúdo de texto e imagem nos documentos. Com o suporte nativo à visão de PDF, os modelos do Gemini podem:
Analise diagramas, gráficos e tabelas nos documentos.
Extraia informações em formatos de saída estruturados.
Responda a perguntas sobre conteúdos visuais e de texto em documentos.
Resumir documentos.
Transcrever o conteúdo do documento (por exemplo, para HTML) preservando layouts e formatação para uso em aplicativos downstream (como em pipelines de RAG).
Este tutorial demonstra algumas maneiras de usar a API Gemini com documentos PDF. Toda a saída é somente texto.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Como fazer perguntas com PDFs
Este guia demonstra como fazer upload e processar PDFs usando a API File ou incluindo-os como dados inline.
Detalhes técnicos
O Gemini 1.5 Pro e o 1.5 Flash oferecem suporte a um máximo de 3.600 páginas de documento. As páginas do documento precisam estar em um dos seguintes tipos MIME de dados de texto:
PDF - application/pdf
JavaScript: application/x-javascript, text/javascript
Python: application/x-python, text/x-python
TXT: text/plain
HTML: text/html
CSS - text/css
Markdown - text/md
CSV: text/csv
XML: text/xml
RTF - text/rtf
Cada página de documento equivale a 258 tokens.
Embora não haja limites específicos para o número de pixels em um documento além da janela de contexto do modelo, páginas maiores são reduzidas para uma resolução máxima de 3072 x 3072, preservando a proporção original, enquanto páginas menores são aumentadas para 768 x 768 pixels. Não há redução de custo para páginas de tamanhos menores, exceto a largura de banda, ou melhoria de desempenho para páginas de resolução maior.
Para os melhores resultados:
Gire as páginas para a orientação correta antes de fazer o upload.
Evite páginas desfocadas.
Se você estiver usando uma única página, coloque o comando de texto depois dela.
Entrada de PDF
Para payloads de PDF com menos de 20 MB, você pode fazer upload de documentos codificados em base64 ou fazer upload direto de arquivos armazenados localmente.
Como dados inline
É possível processar documentos PDF diretamente de URLs. Confira um snippet de código que mostra como fazer isso:
from google import genai
from google.genai import types
import httpx

client = genai.Client()

doc_url = "https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf"  # Replace with the actual URL of your PDF

# Retrieve and encode the PDF byte
doc_data = httpx.get(doc_url).content

prompt = "Summarize this document"
response = client.models.generate_content(
  model="gemini-1.5-flash",
  contents=[
      types.Part.from_bytes(
        data=doc_data,
        mime_type='application/pdf',
      ),
      prompt])
print(response.text)
PDFs armazenados localmente
Para PDFs armazenados localmente, use a seguinte abordagem:
from google import genai
from google.genai import types
import pathlib
import httpx

client = genai.Client()

doc_url = "https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf"  # Replace with the actual URL of your PDF

# Retrieve and encode the PDF byte
filepath = pathlib.Path('file.pdf')
filepath.write_bytes(httpx.get(doc_url).content)

prompt = "Summarize this document"
response = client.models.generate_content(
  model="gemini-1.5-flash",
  contents=[
      types.Part.from_bytes(
        data=filepath.read_bytes(),
        mime_type='application/pdf',
      ),
      prompt])
print(response.text)
PDFs grandes
É possível usar a API File para fazer upload de um documento de qualquer tamanho. Sempre use a API File quando o tamanho total da solicitação (incluindo arquivos, comando de texto, instruções do sistema etc.) for maior que 20 MB.
Observação: a API File permite armazenar até 20 GB de arquivos por projeto, com um tamanho máximo de 2 GB por arquivo. Os arquivos são armazenados por 48 horas. Eles podem ser acessados nesse período com sua chave de API, mas não podem ser transferidos por download da API. A API File está disponível sem custo financeiro em todas as regiões onde a API Gemini está disponível.
Chame media.upload para fazer upload de um arquivo usando a API File. O código a seguir faz o upload de um arquivo de documento e o usa em uma chamada para models.generateContent.
PDFs grandes de URLs
Use a API File para arquivos PDF grandes disponíveis em URLs, simplificando o processo de upload e processamento desses documentos diretamente pelos URLs:
from google import genai
from google.genai import types
import io
import httpx

client = genai.Client()

long_context_pdf_path = "https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf" # Replace with the actual URL of your large PDF

# Retrieve and upload the PDF using the File API
doc_io = io.BytesIO(httpx.get(long_context_pdf_path).content)

sample_doc = client.files.upload(
  # You can pass a path or a file-like object here
  file=doc_io, 
  config=dict(
    # It will guess the mime type from the file extension, but if you pass
    # a file-like object, you need to set the
    mime_type='application/pdf')
)

prompt = "Summarize this document"


response = client.models.generate_content(
  model="gemini-1.5-flash",
  contents=[sample_doc, prompt])
print(response.text)
PDFs grandes armazenados localmente
from google import genai
from google.genai import types
import pathlib
import httpx

client = genai.Client()

long_context_pdf_path = "https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf" # Replace with the actual URL of your large PDF

# Retrieve the PDF
file_path = pathlib.Path('A17.pdf')
file_path.write_bytes(httpx.get(long_context_pdf_path).content)

# Upload the PDF using the File API
sample_file = client.files.upload(
  file=file_path,
)

prompt="Summarize this document"

response = client.models.generate_content(
  model="gemini-1.5-flash",
  contents=[sample_file, "Summarize this document"])
print(response.text)
É possível verificar se a API armazenou o arquivo enviado e acessar os metadados dele chamando files.get. Somente o name (e, por extensão, o uri) são exclusivos.
from google import genai
import pathlib

client = genai.Client()

fpath = pathlib.Path('example.txt')
fpath.write_text('hello')

file = client.files.upload('example.txt')

file_info = client.files.get(file.name)
print(file_info.model_dump_json(indent=4))
Vários PDFs
A API Gemini é capaz de processar vários documentos PDF em uma única solicitação, desde que o tamanho combinado dos documentos e do comando de texto fique dentro da janela de contexto do modelo.
from google import genai
import io
import httpx

client = genai.Client()

doc_url_1 = "https://arxiv.org/pdf/2312.11805" # Replace with the URL to your first PDF
doc_url_2 = "https://arxiv.org/pdf/2403.05530" # Replace with the URL to your second PDF

# Retrieve and upload both PDFs using the File API
doc_data_1 = io.BytesIO(httpx.get(doc_url_1).content)
doc_data_2 = io.BytesIO(httpx.get(doc_url_2).content)

sample_pdf_1 = client.files.upload(
  file=doc_data_1,
  config=dict(mime_type='application/pdf')
)
sample_pdf_2 = client.files.upload(
  file=doc_data_2,
  config=dict(mime_type='application/pdf')
)

prompt = "What is the difference between each of the main benchmarks between these two papers? Output these in a table."

response = client.models.generate_content(
  model="gemini-1.5-flash",
  contents=[sample_pdf_1, sample_pdf_2, prompt])
print(response.text)
Listar arquivos
É possível listar todos os arquivos enviados usando a API File e os URIs deles usando files.list.
from google import genai

client = genai.Client()

print("My files:")
for f in client.files.list():
    print("  ", f.name)
Excluir arquivos
Os arquivos enviados usando a API File são excluídos automaticamente após dois dias. Também é possível excluí-las manualmente usando files.delete.
from google import genai
import pathlib

client = genai.Client()

fpath = pathlib.Path('example.txt')
fpath.write_text('hello')

file = client.files.upload('example.txt')

client.files.delete(file.name)
Armazenamento em cache de contexto com PDFs
from google import genai
from google.genai import types
import io
import httpx

client = genai.Client()

long_context_pdf_path = "https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf" # Replace with the actual URL of your large PDF

# Retrieve and upload the PDF using the File API
doc_io = io.BytesIO(httpx.get(long_context_pdf_path).content)

document = client.files.upload(
  path=doc_io,
  config=dict(mime_type='application/pdf')
)

# Specify the model name and system instruction for caching
model_name = "gemini-1.5-flash-002" # Ensure this matches the model you intend to use
system_instruction = "You are an expert analyzing transcripts."

# Create a cached content object
cache = client.caches.create(
    model=model_name,
    config=types.CreateCachedContentConfig(
      system_instruction=system_instruction,
      contents=[document], # The document(s) and other content you wish to cache
    )
)

# Display the cache details
print(f'{cache=}')

# Generate content using the cached prompt and document
response = client.models.generate_content(
  model=model_name,
  contents="Please summarize this transcript",
  config=types.GenerateContentConfig(
    cached_content=cache.name
  ))

# (Optional) Print usage metadata for insights into the API call
print(f'{response.usage_metadata=}')

# Print the generated text
print('\n\n', response.text)
Listar caches
Não é possível recuperar ou visualizar o conteúdo armazenado em cache, mas é possível recuperar metadados de cache (name, model, display_name, usage_metadata, create_time, update_time e expire_time).
Para listar os metadados de todos os caches enviados, use CachedContent.list():
from google import genai

client = genai.Client()
for c in client.caches.list():
  print(c)
Atualizar um cache
É possível definir um novo ttl ou expire_time para um cache. Não é possível mudar qualquer outra coisa no cache.
O exemplo a seguir mostra como atualizar o ttl de um cache usando CachedContent.update().
from google import genai
from google.genai import types
import datetime

client = genai.Client()

model_name = "models/gemini-1.5-flash-002" 

cache = client.caches.create(
    model=model_name,
    config=types.CreateCachedContentConfig(
      contents=['hello']
    )
)

client.caches.update(
  name = cache.name,
  config=types.UpdateCachedContentConfig(
    ttl=f'{datetime.timedelta(hours=2).total_seconds()}s'
  )
)
Excluir um cache
O serviço de cache oferece uma operação de exclusão para remover manualmente o conteúdo do cache. O exemplo a seguir mostra como excluir um cache usando CachedContent.delete().
from google import genai
from google.genai import types
import datetime

client = genai.Client()

model_name = "models/gemini-1.5-flash-002" 

cache = client.caches.create(
    model=model_name,
    config=types.CreateCachedContentConfig(
      contents=['hello']
    )
)

client.caches.delete(name = cache.name)
A seguir
Este guia mostra como usar generateContent e gerar saídas de texto de documentos processados. Para saber mais, confira estes recursos:
Estratégias de solicitação de arquivo: a API Gemini oferece suporte a solicitações com dados de texto, imagem, áudio e vídeo, também conhecidas como solicitações multimodais.
Instruções do sistema: as instruções do sistema permitem orientar o comportamento do modelo com base nas suas necessidades e casos de uso específicos.
Orientações de segurança: às vezes, os modelos de IA generativa produzem resultados inesperados, como respostas imprecisas, parciais ou ofensivas. O pós-processamento e a avaliação humana são essenciais para limitar o risco de danos causados por essas saídas.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_35.txt ---

URL: https://ai.google.dev/gemini-api/docs/grounding

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Tutorial de aterramento
Usar as sugestões de pesquisa do Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Embasamento com a Pesquisa Google
Nesta página
Configurar o embasamento da pesquisa
Sugestões de pesquisa do Google
Recuperação da Pesquisa Google
Primeiros passos
Limite dinâmico
Recuperação dinâmica
Uma resposta fundamentada
Python
JavaScript
REST
O recurso "Embasadas na Pesquisa Google" na API Gemini e no AI Studio pode ser usado para melhorar a precisão e a recência das respostas do modelo. Além de respostas mais factuais, quando o Embasamento com a Pesquisa Google está ativado, a API Gemini retorna fontes de fundamentação (links de suporte inline) e sugestões da Pesquisa Google junto com o conteúdo da resposta. As Sugestões de pesquisa direcionam os usuários aos resultados de pesquisa correspondentes à resposta fundamentada.
Este guia vai ajudar você a começar a usar o Embasamento com a Pesquisa Google.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Configurar o embasamento da pesquisa
A Pesquisa Google está disponível como uma ferramenta desde o Gemini 2.0. Isso significa que o modelo pode decidir quando usar a Pesquisa Google. O exemplo a seguir mostra como configurar a Pesquisa como uma ferramenta.
from google import genai
from google.genai.types import Tool, GenerateContentConfig, GoogleSearch

client = genai.Client()
model_id = "gemini-2.0-flash"

google_search_tool = Tool(
    google_search = GoogleSearch()
)

response = client.models.generate_content(
    model=model_id,
    contents="When is the next total solar eclipse in the United States?",
    config=GenerateContentConfig(
        tools=[google_search_tool],
        response_modalities=["TEXT"],
    )
)

for each in response.candidates[0].content.parts:
    print(each.text)
# Example response:
# The next total solar eclipse visible in the contiguous United States will be on ...

# To get grounding metadata as web content.
print(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)
A funcionalidade "Pesquisa como ferramenta" também permite pesquisas com várias etapas e consultas com várias ferramentas (por exemplo, combinar o recurso "Grounding" com a Pesquisa Google e a execução de código).
A pesquisa como ferramenta permite comandos e fluxos de trabalho complexos que exigem planejamento, raciocínio e pensamento:
Embasamento para melhorar a precisão e a atualidade e fornecer respostas mais precisas
Recuperar artefatos da Web para fazer outras análises em
Encontrar imagens, vídeos ou outras mídias relevantes para ajudar em tarefas de raciocínio ou geração multimodais
Programação, solução de problemas técnicos e outras tarefas especializadas
Encontrar informações específicas da região ou ajudar a traduzir conteúdo com precisão
Como encontrar sites relevantes para navegar
O Embasamento com a Pesquisa Google funciona com todos os idiomas disponíveis ao fazer comandos de texto. No nível pago da API Gemini Developer, você pode receber 1.500 consultas de Grounding com a Pesquisa Google por dia sem custos financeiros, com consultas adicionais cobradas no padrão de US $35 por 1.000 consultas.
Saiba mais testando o notebook da ferramenta de pesquisa.
Sugestões de pesquisa do Google
Para usar o Embasamento com a Pesquisa Google, você precisa mostrar as Sugestões de pesquisa do Google, que são consultas sugeridas incluídas nos metadados da resposta embasada. Para saber mais sobre os requisitos de exibição, consulte Usar as Sugestões da Pesquisa Google.
Recuperação da Pesquisa Google
Observação: a recuperação da Pesquisa Google é compatível apenas com os modelos Gemini 1.5. Para modelos do Gemini 2.0, use a Pesquisa como uma ferramenta.
Para configurar um modelo para usar a recuperação da Pesquisa Google, transmita a ferramenta adequada.
A recuperação da Pesquisa Google é compatível apenas com os modelos 1.5. Os modelos mais recentes precisam usar o Embasadas na pesquisa. Se você tentar usá-lo, o SDK vai converter seu código para usar o Search Grounding e vai ignorar as configurações de limite dinâmico.
Primeiros passos
from google import genai
from google.genai import types

client = genai.Client(api_key="
GEMINI_API_KEY")

response = client.models.generate_content(
    model='gemini-1.5-flash',
    contents="Who won the US open this year?",
    config=types.GenerateContentConfig(
        tools=[types.Tool(
            google_search=types.GoogleSearchRetrieval
        )]
    )
)
print(response)
Limite dinâmico
As configurações dynamic_threshold permitem controlar o comportamento de recuperação, proporcionando controle adicional sobre quando O aterramento com a Pesquisa Google é usado.
from google import genai
from google.genai import types

client = genai.Client(api_key="
GEMINI_API_KEY")

response = client.models.generate_content(
    model='gemini-1.5-flash',
    contents="Who won Roland Garros this year?",
    config=types.GenerateContentConfig(
        tools=[types.Tool(
            google_search=types.GoogleSearchRetrieval(
                dynamic_retrieval_config=types.DynamicRetrievalConfig(
                    dynamic_threshold=0.6))
        )]
    )
)
print(response)
Recuperação dinâmica
Observação: a recuperação dinâmica é compatível apenas com o Flash 1.5 do Gemini. Para o Gemini 2.0, use a Pesquisa como uma ferramenta, conforme mostrado acima.
Algumas consultas vão aproveitar o embasamento na Pesquisa Google mais do que outras. O recurso de recuperação dinâmica oferece mais controle sobre quando usar o Embasamento com a Pesquisa Google.
Se o modo de recuperação dinâmica não for especificado, a ativação da Pesquisa Google será sempre acionada. Se o modo estiver definido como dinâmico, o modelo vai decidir quando usar a aterramento com base em um limite que você pode configurar. O limite é um valor de ponto flutuante no intervalo [0,1] e tem o valor padrão 0,3. Se o valor de limite for 0, a resposta sempre será com embasamento na Pesquisa Google. Se for 1, ela nunca será.
Como a recuperação dinâmica funciona
Você pode usar a recuperação dinâmica na sua solicitação para escolher quando ativar o embasamento com a Pesquisa Google. Isso é útil quando o comando não exige uma resposta com embasamento na Pesquisa Google e o modelo pode fornecer uma resposta com base no próprio conhecimento sem embasamento. Isso ajuda a gerenciar a latência, a qualidade e o custo com mais eficiência.
Antes de invocar a configuração de recuperação dinâmica na solicitação, entenda a seguinte terminologia:
Pontuação da previsão: quando você solicita uma resposta com embasamento, o Gemini atribui uma pontuação de previsão ao comando. A pontuação de previsão é um valor de ponto flutuante no intervalo [0,1]. O valor depende se a instrução pode se beneficiar ao basear a resposta com as informações mais atualizadas da Pesquisa Google. Portanto, se uma instrução exigir uma resposta com base nos fatos mais recentes da Web, ela terá uma pontuação de previsão mais alta. Um comando para o qual uma resposta gerada pelo modelo é suficiente tem uma pontuação de previsão mais baixa.
Confira exemplos de algumas solicitações e as notas de previsão delas.
Observação: as pontuações de previsão são atribuídas pelo Gemini e podem variar ao longo do tempo, dependendo de vários fatores.
Comando Pontuação de previsão Comentário
"Escreva um poema sobre peônias" 0,13 O modelo pode confiar no próprio conhecimento, e a resposta não precisa de embasamento.
"Sugira um brinquedo para uma criança de 2 anos" 0.36 O modelo pode confiar no próprio conhecimento, e a resposta não precisa de embasamento.
"Você pode dar uma receita de guacamole de inspiração asiática?" 0,55 A Pesquisa Google pode dar uma resposta com embasamento, mas o embasamento não é estritamente necessário. O conhecimento do modelo pode ser suficiente.
"O que é o Agent Builder? Como o embasamento é cobrado no Agent Builder?" 0,72 Requer que a Pesquisa Google gere uma resposta com bom embasamento.
"Quem ganhou o último Grande Prêmio de F1?" 0.97 Requer que a Pesquisa Google gere uma resposta com bom embasamento.
Limite: na solicitação de API, é possível especificar uma configuração de recuperação dinâmica com um limite. O limite é um valor de ponto flutuante no intervalo [0,1] e tem o valor padrão 0,3. Se o valor de limite for zero, a resposta será sempre com embasamento com a Pesquisa Google. Para todos os outros valores de limite, o seguinte é aplicável:
Se a pontuação da previsão for maior ou igual ao limite, a resposta será baseada na Pesquisa Google. Um limite mais baixo implica que mais comandos têm respostas geradas usando o Embasamento com a Pesquisa Google.
Se a pontuação da previsão for menor que o limite, o modelo ainda poderá gerar a resposta, mas ela não será baseada na Pesquisa Google.
Para saber como definir o limite de recuperação dinâmica usando um SDK ou a API REST, consulte o exemplo de código apropriado.
Para encontrar um bom limite que atenda às necessidades da sua empresa, crie um conjunto representativo de consultas que você espera encontrar. Em seguida, você pode classificar as consultas de acordo com a pontuação de previsão na resposta e selecionar um limite adequado para seu caso de uso.
Uma resposta fundamentada
Se o comando for embasado corretamente na Pesquisa Google, a resposta vai incluir groundingMetadata. Uma resposta fundamentada pode ser semelhante a esta (partes da resposta foram omitidas para agilizar):
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "Carlos Alcaraz won the Gentlemen's Singles title at the 2024 Wimbledon Championships. He defeated Novak Djokovic in the final, winning his second consecutive Wimbledon title and fourth Grand Slam title overall. \n"
          }
        ],
        "role": "model"
      },
      ...
      "groundingMetadata": {
        "searchEntryPoint": {
          "renderedContent": "\u003cstyle\u003e\n.container {\n  align-items: center;\n  border-radius: 8px;\n  display: flex;\n  font-family: Google Sans, Roboto, sans-serif;\n  font-size: 14px;\n  line-height: 20px;\n  padding: 8px 12px;\n}\n.chip {\n  display: inline-block;\n  border: solid 1px;\n  border-radius: 16px;\n  min-width: 14px;\n  padding: 5px 16px;\n  text-align: center;\n  user-select: none;\n  margin: 0 8px;\n  -webkit-tap-highlight-color: transparent;\n}\n.carousel {\n  overflow: auto;\n  scrollbar-width: none;\n  white-space: nowrap;\n  margin-right: -12px;\n}\n.headline {\n  display: flex;\n  margin-right: 4px;\n}\n.gradient-container {\n  position: relative;\n}\n.gradient {\n  position: absolute;\n  transform: translate(3px, -9px);\n  height: 36px;\n  width: 9px;\n}\n@media (prefers-color-scheme: light) {\n  .container {\n    background-color: #fafafa;\n    box-shadow: 0 0 0 1px #0000000f;\n  }\n  .headline-label {\n    color: #1f1f1f;\n  }\n  .chip {\n    background-color: #ffffff;\n    border-color: #d2d2d2;\n    color: #5e5e5e;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #f2f2f2;\n  }\n  .chip:focus {\n    background-color: #f2f2f2;\n  }\n  .chip:active {\n    background-color: #d8d8d8;\n    border-color: #b6b6b6;\n  }\n  .logo-dark {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n  }\n}\n@media (prefers-color-scheme: dark) {\n  .container {\n    background-color: #1f1f1f;\n    box-shadow: 0 0 0 1px #ffffff26;\n  }\n  .headline-label {\n    color: #fff;\n  }\n  .chip {\n    background-color: #2c2c2c;\n    border-color: #3c4043;\n    color: #fff;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #353536;\n  }\n  .chip:focus {\n    background-color: #353536;\n  }\n  .chip:active {\n    background-color: #464849;\n    border-color: #53575b;\n  }\n  .logo-light {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n  }\n}\n\u003c/style\u003e\n\u003cdiv class=\"container\"\u003e\n  \u003cdiv class=\"headline\"\u003e\n    \u003csvg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n      \u003cpath fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/\u003e\n      \u003cpath fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/\u003e\n      \u003cpath fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/\u003e\n      \u003cpath fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/\u003e\n    \u003c/svg\u003e\n    \u003csvg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n      \u003ccircle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/\u003e\n      \u003cpath d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/\u003e\n      \u003cpath d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/\u003e\n      \u003cpath d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/\u003e\n      \u003cpath d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/\u003e\n    \u003c/svg\u003e\n    \u003cdiv class=\"gradient-container\"\u003e\u003cdiv class=\"gradient\"\u003e\u003c/div\u003e\u003c/div\u003e\n  \u003c/div\u003e\n  \u003cdiv class=\"carousel\"\u003e\n    \u003ca class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWhgh4x8Epe-gzpwRBvp7o3RZh2m1ygq1EHktn0OWCtvTXjad4bb1zSuqfJd6OEuZZ9_SXZ_P2SvCpJM7NaFfQfiZs6064MeqXego0vSbV9LlAZoxTdbxWK1hFeqTG6kA13YJf7Fbu1SqBYM0cFM4zo0G_sD9NKYWcOCQMvDLDEJFhjrC9DM_QobBIAMq-gWN95G5tvt6_z6EuPN8QY=\"\u003ewho won wimbledon 2024\u003c/a\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n"
        },
        "groundingChunks": [
          {
            "web": {
              "uri": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWhgh4whET1ta3sDETZvcicd8FeNe4z0VuduVsxrT677KQRp2rYghXI0VpfYbIMVI3THcTuMwggRCbFXS_wVvW0UmGzMe9h2fyrkvsnQPJyikJasNIbjJLPX0StM4Bd694-ZVle56MmRA4YiUvwSqad1w6O2opmWnw==",
              "title": "wikipedia.org"
            }
          },
          {
            "web": {
              "uri": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWhgh4wR1M-9-yMPUr_KdHlnoAmQ8ZX90DtQ_vDYTjtP2oR5RH4tRP04uqKPLmesvo64BBkPeYLC2EpVDxv9ngO3S1fs2xh-e78fY4m0GAtgNlahUkm_tBm_sih5kFPc7ill9u2uwesNGUkwrQlmP2mfWNU5lMMr23HGktr6t0sV0QYlzQq7odVoBxYWlQ_sqWFH",
              "title": "wikipedia.org"
            }
          },
          {
            "web": {
              "uri": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWhgh4wsDmROzbP-tmt8GdwCW_pqISTZ4IRbBuoaMyaHfcQg8WW-yKRQQvMDTPAuLxJh-8_U8_iw_6JKFbQ8M9oVYtaFdWFK4gOtL4RrC9Jyqc5BNpuxp6uLEKgL5-9TggtNvO97PyCfziDFXPsxylwI1HcfQdrz3Jy7ZdOL4XM-S5rC0lF2S3VWW0IEAEtS7WX861meBYVjIuuF_mIr3spYPqWLhbAY2Spj-4_ba8DjRvmevIFUhRuESTKvBfmpxNSM",
              "title": "cbssports.com"
            }
          },
          {
            "web": {
              "uri": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWhgh4yzjLkorHiUKjhOPkWaZ9b4cO-cLG-02vlEl6xTBjMUjyhK04qSIclAa7heR41JQ6AAVXmNdS3WDrLOV4Wli-iezyzW8QPQ4vgnmO_egdsuxhcGk3-Fp8-yfqNLvgXFwY5mPo6QRhvplOFv0_x9mAcka18QuAXtj0SPvJfZhUEgYLCtCrucDS5XFc5HmRBcG1tqFdKSE1ihnp8KLdaWMhrUQI21hHS9",
              "title": "jagranjosh.com"
            }
          },
          {
            "web": {
              "uri": "https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWhgh4y9L4oeNGWCatFz63b9PpP3ys-Wi_zwnkUT5ji9lY7gPUJQcsmmE87q88GSdZqzcx5nZG9usot5FYk2yK-FAGvCRE6JsUQJB_W11_kJU2HVV1BTPiZ4SAgm8XDFIxpCZXnXmEx5HUfRqQm_zav7CvS2qjA2x3__qLME6Jy7R5oza1C5_aqjQu422le9CaigThS5bvJoMo-ZGcXdBUCj2CqoXNVjMA==",
              "title": "apnews.com"
            }
          }
        ],
        "groundingSupports": [
          {
            "segment": {
              "endIndex": 85,
              "text": "Carlos Alcaraz won the Gentlemen's Singles title at the 2024 Wimbledon Championships."
            },
            "groundingChunkIndices": [
              0,
              1,
              2,
              3
            ],
            "confidenceScores": [
              0.97380733,
              0.97380733,
              0.97380733,
              0.97380733
            ]
          },
          {
            "segment": {
              "startIndex": 86,
              "endIndex": 210,
              "text": "He defeated Novak Djokovic in the final, winning his second consecutive Wimbledon title and fourth Grand Slam title overall."
            },
            "groundingChunkIndices": [
              1,
              0,
              4
            ],
            "confidenceScores": [
              0.96145374,
              0.96145374,
              0.96145374
            ]
          }
        ],
        "webSearchQueries": [
          "who won wimbledon 2024"
        ]
      }
    }
  ],
  ...
}
Se a resposta não incluir groundingMetadata, significa que a resposta não foi fundamentada. Isso pode acontecer por vários motivos, incluindo baixa relevância da fonte ou informações incompletas na resposta do modelo.
Quando um resultado com base é gerado, os metadados contêm URIs que redirecionam para os editores do conteúdo usado para gerar o resultado com base. Esses URIs contêm o subdomínio vertexaisearch, como neste exemplo truncado: https://vertexaisearch.cloud.google.com/grounding-api-redirect/.... Os metadados também contêm os domínios dos editores. Os URIs fornecidos permanecem acessíveis por 30 dias após a geração do resultado com embasamento.
Importante: os URIs fornecidos precisam ser acessíveis diretamente pelos usuários finais e não podem ser consultados de forma programática por meios automatizados. Se o acesso automatizado for detectado, o serviço de geração de respostas com embasamento poderá parar de fornecer os URIs de redirecionamento.
O campo renderedContent em searchEntryPoint é o código fornecido para implementar as sugestões da Pesquisa Google. Consulte Usar as sugestões da Pesquisa Google para saber mais.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_36.txt ---

URL: https://ai.google.dev/gemini-api/docs/grounding/search-suggestions

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Tutorial de aterramento
Usar as sugestões de pesquisa do Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Usar as sugestões de pesquisa do Google
Nesta página
Requisitos para sugestões de pesquisa do Google
Requisitos de exibição
Comportamento ao tocar
Código para implementar uma sugestão da Pesquisa Google
A seguir
Para usar o embasamento na Pesquisa Google, ative as sugestões da Pesquisa Google. Elas ajudam os usuários a encontrar resultados da pesquisa correspondentes a uma resposta embasada.
Especificamente, é necessário mostrar as consultas de pesquisa incluídas nos metadados da resposta embasada. A resposta inclui:
content: resposta gerada pelo LLM
webSearchQueries: as consultas a serem usadas para as sugestões da Pesquisa Google
Por exemplo, no snippet de código a seguir, o Gemini responde a um comando baseado na Pesquisa Google que pergunta sobre um tipo de planta tropical.
"predictions": [
  {
    "content": "Monstera is a type of vine that thrives in bright indirect light…",
    "groundingMetadata": {
      "webSearchQueries": ["What's a monstera?"],
    }
  }
]
Use as Sugestões de pesquisa Google para mostrar essa saída.
Requisitos para sugestões de pesquisa do Google
O que fazer:
mostrar a sugestão de pesquisa exatamente como fornecida, sem modificações, em conformidade com os requisitos de exibição;
Direcione os usuários diretamente para a página de resultados da Pesquisa Google (SRP) quando eles interagiarem com a sugestão de pesquisa.
O que não fazer:
Inclua telas intersticiais ou etapas adicionais entre o toque do usuário e a exibição do SRP.
Mostre outros resultados ou sugestões da pesquisa ao lado da Sugestão de pesquisa ou da resposta do LLM fundamentada associada.
Requisitos de exibição
Mostre a sugestão de pesquisa exatamente como ela foi fornecida e não faça modificações nas cores, fontes ou aparência. Confira se a sugestão de pesquisa é renderizada conforme especificado nos modelos a seguir, incluindo os modos claro e escuro:
Sempre que uma resposta fundamentada for exibida, a sugestão de pesquisa Google correspondente vai permanecer visível.
Branding: é necessário seguir rigorosamente as Diretrizes do Google para o uso de características da marca do Google por terceiros.
As sugestões da Pesquisa Google precisam ter, no mínimo, a largura total da resposta embasada.
Comportamento ao tocar
Quando um usuário toca no ícone, ele é direcionado para uma página de resultados da Pesquisa Google (SRP) com o termo de pesquisa exibido no ícone. O SRP pode ser aberto no navegador no app ou em um app de navegador separado. É importante não minimizar, remover ou obstruir a exibição do SRP de maneira alguma. O modelo animado a seguir ilustra a interação do toque para o SRP.
Código para implementar uma sugestão da Pesquisa Google
Quando você usa a API para fundamentar uma resposta à pesquisa, a resposta do modelo fornece estilo HTML e CSS compatível no campo renderedContent que você implementa para mostrar sugestões de pesquisa no seu aplicativo. Para conferir um exemplo da resposta da API, consulte a seção de resposta em Embasamento com a Pesquisa Google.
Observação: o HTML e o CSS fornecidos na resposta da API se adaptam automaticamente às configurações do dispositivo do usuário, sendo exibido no modo claro ou escuro com base na preferência do usuário indicada por @media(prefers-color-scheme).
A seguir
Saiba como criar um chat interativo.
Saiba como usar o Gemini com segurança e responsabilidade.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_37.txt ---

URL: https://ai.google.dev/gemini-api/docs/model-tuning

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Introdução ao ajuste
Tutorial de ajuste
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Como fazer ajustes com a API Gemini
Nesta página
Como funciona o ajuste fino
Preparar o conjunto de dados
Formato
Limitações
Tamanho dos dados de treinamento
Estratégias de design de comandos, como comandos de poucos disparos (few-shot), nem sempre produzem os resultados necessários. O ajuste fino é um processo que pode melhorar o desempenho do modelo em tarefas específicas ou ajudar o modelo a obedecer a requisitos de saída específicos quando as instruções não forem suficientes e você tiver um conjunto de exemplos que demonstrem as saídas desejadas.
Esta página fornece uma visão geral conceitual do ajuste do modelo de texto por trás o serviço de texto da API Gemini. Quando estiver tudo pronto para começar a sintonização, tente o tutorial de ajuste fino. Se você quiser uma introdução mais geral à personalização de LLMs para casos de uso específicos, confira LLMs: ajuste fino, destilação e engenharia de comando no Curso intensivo de machine learning.
Como funciona o ajuste fino
O objetivo do ajuste é melhorar ainda mais o desempenho do modelo para para a tarefa específica. O ajuste fino funciona fornecendo ao modelo um treinamento conjunto de dados que contém muitos exemplos da tarefa. Para tarefas de nicho, é possível conseguir melhorias significativas no desempenho do modelo ajustando o modelo em um número modesto de exemplos. Esse tipo de ajuste de modelo é chamado ajustes supervisionados para distingui-los de outros tipos de ajustes.
Os dados de treinamento precisam ser estruturados como exemplos com entradas de comandos as saídas esperadas de resposta. Também é possível ajustar modelos usando dados de exemplo diretamente no Google AI Studio. O objetivo é ensinar o modelo a imitar o comportamento ou a tarefa desejada, fornecendo muitos exemplos que ilustram esse comportamento ou tarefa.
Ao executar um job de ajuste, o modelo aprende outros parâmetros que o ajudam a codificar as informações necessárias para executar a tarefa desejada ou aprender o comportamento desejado. Esses parâmetros podem ser usados no momento da inferência. A saída do o job de ajuste é um novo modelo, que é uma combinação da nova parâmetros aprendidos e o modelo original.
Preparar o conjunto de dados
Antes de começar a fazer ajustes, você precisa de um conjunto de dados para ajustar o modelo. Para o melhor desempenho, os exemplos no conjunto de dados devem ser de alta qualidade, diversificados e representativos de entradas e saídas reais.
Formato
Observação: o ajuste fino só aceita exemplos de pares de entrada e saída. Estilo de bate-papo No momento, não é possível conversar com várias interações.
Os exemplos no seu conjunto de dados precisam corresponder ao tráfego de produção esperado. Se o conjunto de dados contiver formatação, palavras-chave, instruções ou informações específicas, os dados de produção deverão ser formatados da mesma maneira e conter as mesmas instruções.
Por exemplo, se os exemplos no seu conjunto de dados incluem um "question:" e um "context:", o tráfego de produção também deve ser formatado para incluir um "question:" e um "context:" na mesma ordem em que aparece no exemplos de conjuntos de dados. Se você excluir o contexto, o modelo não reconhecerá o padrão, mesmo que a pergunta exata estivesse em um exemplo do conjunto de dados.
Como outro exemplo, aqui estão os dados de treinamento do Python para um aplicativo que gera o próximo número em uma sequência:
training_data = [
  {"text_input": "1", "output": "2"},
  {"text_input": "3", "output": "4"},
  {"text_input": "-3", "output": "-2"},
  {"text_input": "twenty two", "output": "twenty three"},
  {"text_input": "two hundred", "output": "two hundred one"},
  {"text_input": "ninety nine", "output": "one hundred"},
  {"text_input": "8", "output": "9"},
  {"text_input": "-98", "output": "-97"},
  {"text_input": "1,000", "output": "1,001"},
  {"text_input": "10,100,000", "output": "10,100,001"},
  {"text_input": "thirteen", "output": "fourteen"},
  {"text_input": "eighty", "output": "eighty one"},
  {"text_input": "one", "output": "two"},
  {"text_input": "three", "output": "four"},
  {"text_input": "seven", "output": "eight"},
]
Adicionar um prompt ou preâmbulo a cada exemplo no conjunto de dados também pode ajudar melhorar o desempenho do modelo ajustado. Se um comando ou preâmbulo for incluído no seu conjunto de dados, ele também precisará ser incluído no comando para o modelo sintonizado no momento da inferência.
Limitações
Observação: os conjuntos de dados de ajuste fino para o Gemini 1.5 Flash têm as seguintes limitações:
O tamanho máximo de entrada por exemplo é de 40.000 caracteres.
O tamanho máximo da saída por exemplo é de 5.000 caracteres.
Tamanho dos dados de treinamento
É possível ajustar um modelo com apenas 20 exemplos. Dados adicionais melhora a qualidade das respostas. Sua meta deve ficar entre 100 e 500 exemplos, dependendo do aplicativo. A tabela a seguir mostra os tamanhos de conjuntos de dados recomendados para ajustar um modelo de texto para várias tarefas comuns:
Tarefa Nº de exemplos no conjunto de dados
Classificação 100+
Resumo 100-500+
Pesquisa de documentos 100+
Fazer upload do conjunto de dados de ajuste
Os dados são transmitidos inline usando a API ou por arquivos enviados no Google AI Studio.
Para usar a biblioteca de cliente, forneça o arquivo de dados na chamada createTunedModel. O arquivo pode ter até 4 MB. Consulte a Guia de início rápido de ajuste com Python para começar.
Para chamar a API REST usando o cURL, forneça exemplos de treinamento no formato JSON para o argumento training_data. Consulte o guia de início rápido de ajuste com o cURL para começar.
Configurações de ajuste avançadas
Ao criar um job de ajuste, é possível especificar as seguintes configurações avançadas:
Períodos: uma passagem de treinamento completa por todo o conjunto de treinamento, de modo que cada exemplo seja processado uma vez.
Tamanho do lote: o conjunto de exemplos usados em uma iteração de treinamento. O tamanho do lote determina o número de exemplos em um lote.
Taxa de aprendizado: um número de ponto flutuante que informa ao algoritmo como ajustar os parâmetros do modelo em cada iteração. Por exemplo, uma taxa de aprendizado de 0,3 ajustaria pesos e vieses três vezes mais eficientemente do que uma taxa de aprendizado de 0,1. As taxas de aprendizado altas e baixas têm suas próprias compensações e precisam ser ajustadas com base no seu caso de uso.
Multiplicador da taxa de aprendizado:esse multiplicador modifica o valor e a taxa de aprendizado original. Um valor de 1 usa a taxa de aprendizado original do modelo. Valores maiores que 1 aumentam a taxa de aprendizado e valores entre 1 e 0 diminui a taxa de aprendizado.
Configurações recomendadas
A tabela a seguir mostra as configurações recomendadas para ajustar um modelo de fundação:
Hiperparâmetro Valor padrão Ajustes recomendados
Período 5
Se a perda começar a estabilizar antes de 5 períodos, use um valor menor.
Se a perda está convergindo e não parece estagnar, use um valor mais alto.
Tamanho do lote 4
Taxa de aprendizado 0,001 Use um valor menor para conjuntos de dados menores.
A curva de perda mostra o quanto a previsão do modelo se desvia das previsões ideais nos exemplos de treinamento após cada época. O ideal é interromper o treinamento no ponto mais baixo da curva, logo antes de ele atingir o platô. Por exemplo: o gráfico abaixo mostra a estabilização da curva de perda entre as épocas 4 e 6, o que significa é possível definir o parâmetro Epoch como 4 e ainda ter o mesmo desempenho.
Verificar o status do job de ajuste
É possível verificar o status do job de ajuste no Google AI Studio na guia My Library ou usando a propriedade metadata do modelo ajustado na API Gemini.
Solucionar erros
Esta seção inclui dicas sobre como resolver erros que podem ser encontrados ao criando o modelo ajustado.
Autenticação
Observação: a partir de 30 de setembro de 2024, a autenticação OAuth não será mais necessária. Os novos projetos precisam usar a autenticação de chave de API.
O ajuste usando a API e a biblioteca de cliente exige autenticação. É possível configurar a autenticação usando uma chave de API (recomendado) ou credenciais OAuth. Para conferir a documentação sobre como configurar uma chave de API, consulte Configurar uma chave de API.
Se você receber um erro 'PermissionDenied: 403 Request had insufficient authentication scopes', talvez seja necessário configurar a autenticação do usuário usando o OAuth. credenciais. Para configurar as credenciais do OAuth no Python, acesse nosso tutorial de configuração do OAuth.
Modelos cancelados
É possível cancelar um job de ajuste fino a qualquer momento antes da conclusão. No entanto, o desempenho de inferência de um modelo cancelado é imprevisível, principalmente se o job de ajuste for cancelado no início do treinamento. Se você cancelou porque quiser interromper o treinamento em um período anterior, crie um novo modelo job e defina o período com um valor mais baixo.
Limitações dos modelos ajustados
Observação:modelos ajustados têm as seguintes limitações:
O limite de entrada de um modelo Gemini 1.5 Flash ajustado é de 40.000 caracteres.
O modo JSON não é compatível com modelos ajustados.
Somente a entrada de texto é aceita.
A seguir
Comece a usar os tutoriais de ajuste fino:
Tutorial de ajuste de detalhes (Python)
Tutorial de ajuste de detalhes (REST)
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_38.txt ---

URL: https://ai.google.dev/gemini-api/docs/model-tuning/tutorial

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Introdução ao ajuste
Tutorial de ajuste
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Tutorial de ajuste
Nesta página
Limitações
Ajustar conjuntos de dados
Modelos ajustados
Listar modelos ajustados
Criar um modelo ajustado
Testar o modelo
Não implementado
Python
REST
Este tutorial vai ajudar você a começar a usar o serviço de ajuste da API Gemini com o SDK do Python ou a API REST usando o curl. Os exemplos mostram como ajustar o modelo de texto por trás do serviço de geração de texto da API Gemini.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Testar um notebook do Colab
Acessar o notebook no GitHub
Limitações
Antes de ajustar um modelo, considere as seguintes limitações:
Ajustar conjuntos de dados
O ajuste fino dos conjuntos de dados do Gemini 1.5 Flash tem as seguintes limitações:
O tamanho máximo de entrada por exemplo é de 40.000 caracteres.
O tamanho máximo de saída por exemplo é de 5.000 caracteres.
Somente exemplos de pares de entrada e saída são aceitos. Não há suporte para conversas de vários turnos no estilo de chat.
Modelos ajustados
Os modelos ajustados têm as seguintes limitações:
O limite de entrada de um modelo Gemini 1.5 Flash ajustado é de 40.000 caracteres.
O modo JSON não é compatível com modelos ajustados.
Somente a entrada de texto é aceita.
Listar modelos ajustados
É possível verificar os modelos ajustados com o método tunedModels.list.
from google import genai
from google.genai import types
client = genai.Client() # Get the key from the GOOGLE_API_KEY env variable

for model_info in client.models.list():
    print(model_info.name)
Criar um modelo ajustado
Para criar um modelo ajustado, você precisa transmitir o dataset para o modelo no método tunedModels.create.
Neste exemplo, você vai ajustar um modelo para gerar o próximo número na sequência. Por exemplo, se a entrada for 1, o modelo vai gerar 2. Se a entrada for one hundred, a saída será one hundred one.
# create tuning model
training_dataset =  [
    ["1", "2"],
    ["3", "4"],
    ["-3", "-2"],
    ["twenty two", "twenty three"],
    ["two hundred", "two hundred one"],
    ["ninety nine", "one hundred"],
    ["8", "9"],
    ["-98", "-97"],
    ["1,000", "1,001"],
    ["10,100,000", "10,100,001"],
    ["thirteen", "fourteen"],
    ["eighty", "eighty one"],
    ["one", "two"],
    ["three", "four"],
    ["seven", "eight"],
]
training_dataset=types.TuningDataset(
        examples=[
            types.TuningExample(
                text_input=i,
                output=o,
            )
            for i,o in training_dataset
        ],
    )
tuning_job = client.tunings.tune(
    base_model='models/gemini-1.5-flash-001-tuning',
    training_dataset=training_dataset,
    config=types.CreateTuningJobConfig(
        epoch_count= 5,
        batch_size=4,
        learning_rate=0.001,
        tuned_model_display_name="test tuned model"
    )
)

# generate content with the tuned model
response = client.models.generate_content(
    model=tuning_job.tuned_model.model,
    contents='III',
)

print(response.text)
Os valores ideais para a contagem de épocas, o tamanho do lote e a taxa de aprendizado dependem do seu conjunto de dados e de outras restrições do caso de uso. Para saber mais sobre esses valores, consulte Configurações avançadas de ajuste e Hiperparâmetros.
Dica: para uma introdução mais geral a esses hiperparâmetros, consulte Regressão linear: hiperparâmetros no Curso intensivo de machine learning.
Testar o modelo
Use o método tunedModels.generateContent e especifique o nome do modelo ajustado para testar a performance dele.
response = client.models.generate_content(
    model=tuning_job.tuned_model.model,
    contents='III'
)
Não implementado
Alguns recursos (relatórios de progresso, atualização da descrição e exclusão de modelos ajustados) ainda não foram implementados no novo SDK.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_39.txt ---

URL: https://ai.google.dev/gemini-api/docs/embeddings

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Embeddings
Nesta página
O que são embeddings?
Gerar embeddings
Tipos de tarefa
Tipos de tarefas com suporte
Casos de uso
Modelos de embedding
A seguir
Observação: apresentamos nosso primeiro modelo de incorporação do Gemini, disponível agora para desenvolvedores como gemini-embedding-exp-03-07 na API.
A API Gemini oferece suporte a vários modelos de embedding que geram embeddings para palavras, frases, códigos e frases. Os embeddings resultantes podem ser usados para tarefas como pesquisa semântica, classificação de texto e agrupamento, entre muitas outras.
O que são embeddings?
Os embeddings são representações numéricas de texto (ou outros formatos de mídia) que capturam as relações entre as entradas. Os embeddings de texto funcionam convertendo texto em matrizes de números de ponto flutuante, chamados de vetores. Esses vetores são projetados para capturar o significado do texto. O comprimento da matriz de embedding é chamado de dimensionalidade do vetor. Uma passagem de texto pode ser representada por um vetor com centenas de dimensões.
As embedding capturam o significado semântico e o contexto, o que resulta em texto com significados semelhantes com embedding "mais próximas". Por exemplo, as frases "Eu levei meu cachorro ao veterinário" e "Eu levei meu gato ao veterinário" teriam embeddings próximos entre si no espaço vetorial.
Você pode usar embeddings para comparar textos diferentes e entender como eles se relacionam. Por exemplo, se as embeddings do texto "cat" e "dog" estiverem próximas uma da outra, é possível inferir que essas palavras são semelhantes em significado, contexto ou ambos. Isso permite uma variedade de casos de uso comuns de IA.
Antes de começar
Antes de chamar a API Gemini, verifique se você tem o SDK de sua escolha instalado e uma chave da API Gemini configurada e pronta para uso.
Gerar embeddings
Use o método embedContent para gerar embeddings de texto:
Python
JavaScript
Go
REST
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

result = client.models.embed_content(
        model="gemini-embedding-exp-03-07",
        contents="What is the meaning of life?")

print(result.embeddings)
Também é possível gerar embeddings para vários pedaços de uma só vez transmitindo-os como uma lista de strings.
Tipos de tarefa
Ao criar sistemas de geração aumentada de recuperação (RAG), um design comum é usar embeddings de texto para realizar uma pesquisa de similaridade. Em alguns casos, isso pode prejudicar a qualidade, porque as perguntas e as respostas não são semanticamente semelhantes. Por exemplo, uma pergunta como "Por que o céu é azul?" e a resposta "A dispersão da luz solar causa a cor azul" têm significados distintos como frases, o que significa que um sistema RAG não reconhece automaticamente a relação delas.
Os tipos de tarefa permitem gerar embeddings otimizados para tarefas específicas, economizando tempo e custo e melhorando o desempenho.
Python
JavaScript
REST
from google import genai
from google.genai import types

client = genai.Client(api_key="GEMINI_API_KEY")

result = client.models.embed_content(
        model="gemini-embedding-exp-03-07",
        contents="What is the meaning of life?",
        config=types.EmbedContentConfig(task_type="SEMANTIC_SIMILARITY")
)
print(result.embeddings)
Tipos de tarefas com suporte
Tipo de tarefa Descrição
SEMANTIC_SIMILARITY Usado para gerar embeddings otimizados para avaliar a similaridade de texto.
CLASSIFICATION Usado para gerar embeddings otimizados para classificar textos de acordo com rótulos predefinidos.
CLUSTERING Usado para gerar embeddings otimizados para agrupar textos com base nas semelhanças deles.
RETRIEVAL_DOCUMENT, RETRIEVAL_QUERY, QUESTION_ANSWERING e FACT_VERIFICATION Usado para gerar embeddings otimizados para pesquisa de documentos ou recuperação de informações.
CODE_RETRIEVAL_QUERY Usado para recuperar um bloco de código com base em uma consulta de linguagem natural, como classificar uma matriz ou reverter uma lista vinculada. As incorporações dos blocos de código são computadas usando RETRIEVAL_DOCUMENT.
Casos de uso
As embeddings de texto são usadas em vários casos de uso comuns de IA, como:
Recuperação de informações:é possível usar embeddings para recuperar textos semanticamente semelhantes com base em um texto de entrada.
Tutorial de pesquisa de documentostask
Agrupamento:comparar grupos de embeddings pode ajudar a identificar tendências ocultas.
Tutorial de agrupamento de embeddingsbubble_chart
Banco de dados de vetores:ao levar diferentes casos de uso de embeddings para a produção, é comum armazenar embeddings em um banco de dados de vetores.
Tutorial do banco de dados do Vectorbolt
Classificação:é possível treinar um modelo usando embeddings para classificar documentos em categorias.
Tutorial de classificaçãotoken
Modelos de embedding
A API Gemini oferece três modelos que geram embeddings de texto:
gemini-embedding-exp-03-07
text-embedding-004
embedding-001
A seguir
Confira o notebook de início rápido de embeddings.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-03 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_40.txt ---

URL: https://ai.google.dev/gemini-api/docs/live

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Live API
Nesta página
Usar a API Live
Enviar e receber mensagens de texto
Receber áudio
Transmitir áudio e vídeo
Instruções do sistema
Atualizações incrementais de conteúdo
Mudar vozes
Usar chamadas de função
Para testar um tutorial que permite usar a voz e a câmera para conversar com o Gemini pela API Live, consulte o projeto Web Console Demo.
A API Live permite interações de voz e vídeo bidirecionais de baixa latência com o Gemini. Com a API Live, você pode oferecer aos usuários finais a experiência de conversas por voz naturais e semelhantes às humanas, além de interromper as respostas do modelo usando comandos de voz. O modelo pode processar entradas de texto, áudio e vídeo e fornecer saídas de texto e áudio.
Você pode testar a API Live no Google AI Studio.
Usar a API Live
Esta seção descreve como usar a API Live com um dos nossos SDKs. Para mais informações sobre a API WebSockets, consulte a referência da API WebSockets abaixo.
Enviar e receber mensagens de texto
import asyncio
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY", http_options={'api_version': 'v1alpha'})
model = "gemini-2.0-flash-exp"

config = {"response_modalities": ["TEXT"]}

async def main():
    async with client.aio.live.connect(model=model, config=config) as session:
        while True:
            message = input("User> ")
            if message.lower() == "exit":
                break
            await session.send(input=message, end_of_turn=True)

            async for response in session.receive():
                if response.text is not None:
                    print(response.text, end="")

if __name__ == "__main__":
    asyncio.run(main())
Receber áudio
O exemplo a seguir mostra como receber dados de áudio e gravá-los em um arquivo .wav.
import asyncio
import wave
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY", http_options={'api_version': 'v1alpha'})
model = "gemini-2.0-flash-exp"

config = {"response_modalities": ["AUDIO"]}

async def main():
    async with client.aio.live.connect(model=model, config=config) as session:
        wf = wave.open("audio.wav", "wb")
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(24000)

        message = "Hello? Gemini are you there?"
        await session.send(input=message, end_of_turn=True)

        async for idx,response in async_enumerate(session.receive()):
            if response.data is not None:
                wf.writeframes(response.data)

            # Un-comment this code to print audio data info
            # if response.server_content.model_turn is not None:
            #      print(response.server_content.model_turn.parts[0].inline_data.mime_type)

        wf.close()

if __name__ == "__main__":
    asyncio.run(main())
Formatos de áudio
A API Live é compatível com os seguintes formatos de áudio:
Formato de áudio de entrada: áudio PCM bruto de 16 bits a 16 kHz little-endian
Formato de áudio de saída: áudio PCM bruto de 16 bits a 24 kHz little-endian
Transmitir áudio e vídeo
Para conferir um exemplo de como usar a API Live em um formato de streaming de áudio e vídeo, execute o arquivo "API Live - Quickstart" no repositório de exemplos:
Confira no GitHub
Instruções do sistema
As instruções do sistema permitem orientar o comportamento de um modelo com base nas suas necessidades e casos de uso específicos. As instruções do sistema podem ser definidas na configuração de configuração e permanecem em vigor durante toda a sessão.
from google.genai import types

config = {
    "system_instruction": types.Content(
        parts=[
            types.Part(
                text="You are a helpful assistant and answer in a friendly tone."
            )
        ]
    ),
    "response_modalities": ["TEXT"],
}
Atualizações incrementais de conteúdo
Use atualizações incrementais para enviar entrada de texto, estabelecer o contexto da sessão ou restaurar o contexto da sessão. Para contextos curtos, você pode enviar interações passo a passo para representar a sequência exata de eventos:
Python
JSON
from google.genai import types

turns = [
    types.Content(parts=[types.Part(text="What is the capital of France?")], role="user"),
    types.Content(parts=[types.Part(text="Paris")], role="model")
]
await session.send(input=types.LiveClientContent(turns=turns))

turns = [types.Content(parts=[types.Part(text="What is the capital of Germany?")], role="user")]
await session.send(input=types.LiveClientContent(turns=turns, turn_complete=True))
Para contextos mais longos, é recomendável fornecer um resumo de mensagem único para liberar a janela de contexto para interações subsequentes.
Mudar vozes
A API Live é compatível com os seguintes vozes: Aoede, Charon, Fenrir, Kore e Puck.
Para especificar uma voz, defina o nome da voz no objeto speechConfig como parte da configuração da sessão:
Python
JSON
from google.genai import types

config = types.LiveConnectConfig(
    response_modalities=["AUDIO"],
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Kore")
        )
    )
)
Usar chamadas de função
É possível definir ferramentas com a API Live. Consulte o tutorial de chamada de função para saber mais.
As ferramentas precisam ser definidas como parte da configuração da sessão:
config = types.LiveConnectConfig(
    response_modalities=["TEXT"],
    tools=[set_light_values]
)

async with client.aio.live.connect(model=model, config=config) as session:
    await session.send(input="Turn the lights down to a romantic level", end_of_turn=True)

    async for response in session.receive():
        print(response.tool_call)
Com um único comando, o modelo pode gerar várias chamadas de função e o código necessário para encadear as saídas. Esse código é executado em um ambiente de sandbox, gerando mensagens BidiGenerateContentToolCall posteriores. A execução é pausada até que os resultados de cada chamada de função estejam disponíveis, o que garante o processamento sequencial.
O cliente precisa responder com BidiGenerateContentToolResponse.
As entradas e saídas de áudio afetam negativamente a capacidade do modelo de usar chamadas de função.
Processar interrupções
Os usuários podem interromper a saída do modelo a qualquer momento. Quando a detecção de atividade de voz (VAD) detecta uma interrupção, a geração em andamento é cancelada e descartada. Somente as informações já enviadas ao cliente são retidas no histórico da sessão. Em seguida, o servidor envia uma mensagem BidiGenerateContentServerContent para informar a interrupção.
Além disso, o servidor Gemini descarta todas as chamadas de função pendentes e envia uma mensagem BidiGenerateContentServerContent com os IDs das chamadas canceladas.
async for response in session.receive():
    if response.server_content.interrupted is not None:
        # The generation was interrupted
Limitações
Considere as seguintes limitações da API Live e do Gemini 2.0 ao planejar seu projeto.
Autenticação do cliente
A API Live só oferece autenticação de servidor para servidor e não é recomendada para uso direto do cliente. A entrada do cliente precisa ser roteada por um servidor de aplicativo intermediário para autenticação segura com a API Live.
Histórico da conversa
Embora o modelo acompanhe as interações na sessão, o histórico de conversas não é armazenado. Quando uma sessão termina, o contexto correspondente é apagado.
Para restaurar uma sessão anterior ou fornecer ao modelo o contexto histórico das interações do usuário, o aplicativo precisa manter o próprio registro de conversas e usar uma mensagem BidiGenerateContentClientContent para enviar essas informações no início de uma nova sessão.
Duração máxima da sessão
A duração da sessão é limitada a até 15 minutos de áudio ou até 2 minutos de áudio e vídeo. Quando a duração da sessão excede o limite, a conexão é encerrada.
O modelo também é limitado pelo tamanho do contexto. O envio de grandes quantidades de conteúdo com os streams de vídeo e áudio pode resultar no encerramento precoce da sessão.
Detecção de atividade de voz (VAD)
O modelo realiza automaticamente a detecção de atividade de voz (VAD, na sigla em inglês) em um stream de entrada de áudio contínuo. O VAD está sempre ativado, e os parâmetros não podem ser configurados.
Contagem de tokens
Não há suporte para a contagem de tokens.
Limites de taxas
Os seguintes limites de taxa são aplicáveis:
Três sessões simultâneas por chave de API
4 milhões de tokens por minuto
Referência da API WebSockets
A API Live é uma API stateful que usa WebSockets. Nesta seção, você vai encontrar mais detalhes sobre a API WebSockets.
Sessões
Uma conexão WebSocket estabelece uma sessão entre o cliente e o servidor Gemini. Depois que um cliente inicia uma nova conexão, a sessão pode trocar mensagens com o servidor para:
Enviar texto, áudio ou vídeo para o servidor do Gemini.
Receber solicitações de chamada de áudio, texto ou função do servidor do Gemini.
A mensagem inicial após a conexão define a configuração da sessão, que inclui o modelo, os parâmetros de geração, as instruções do sistema e as ferramentas.
Confira o exemplo de configuração a seguir. O uso de maiúsculas e minúsculas nos SDKs pode variar. Consulte as opções de configuração do SDK do Python aqui.

{
  "model": string,
  "generationConfig": {
    "candidateCount": integer,
    "maxOutputTokens": integer,
    "temperature": number,
    "topP": number,
    "topK": integer,
    "presencePenalty": number,
    "frequencyPenalty": number,
    "responseModalities": [string],
    "speechConfig": object
  },
  "systemInstruction": string,
  "tools": [object]
}
Enviar mensagens
Para trocar mensagens pela conexão WebSocket, o cliente precisa enviar um objeto JSON por uma conexão WebSocket aberta. O objeto JSON precisa ter exatamente um dos campos do seguinte conjunto de objetos:

{
  "setup": BidiGenerateContentSetup,
  "clientContent": BidiGenerateContentClientContent,
  "realtimeInput": BidiGenerateContentRealtimeInput,
  "toolResponse": BidiGenerateContentToolResponse
}
Mensagens de cliente com suporte
Confira as mensagens de cliente compatíveis na tabela a seguir:
Mensagem Descrição
BidiGenerateContentSetup Configuração da sessão a ser enviada na primeira mensagem
BidiGenerateContentClientContent Atualização incremental do conteúdo da conversa atual enviada pelo cliente
BidiGenerateContentRealtimeInput Entrada de áudio ou vídeo em tempo real
BidiGenerateContentToolResponse Resposta a uma ToolCallMessage recebida do servidor
Receber mensagens
Para receber mensagens do Gemini, detecte o evento "message" do WebSocket e analise o resultado de acordo com a definição das mensagens do servidor com suporte.
Confira estes guias:
async with client.aio.live.connect(model='...', config=config) as session:
    await session.send(input='Hello world!', end_of_turn=True)
    async for message in session.receive():
        print(message)
As mensagens do servidor terão exatamente um dos campos do seguinte conjunto de objetos:

{
  "setupComplete": BidiGenerateContentSetupComplete,
  "serverContent": BidiGenerateContentServerContent,
  "toolCall": BidiGenerateContentToolCall,
  "toolCallCancellation": BidiGenerateContentToolCallCancellation
}
Mensagens do servidor com suporte
Confira as mensagens do servidor compatíveis na tabela a seguir:
Mensagem Descrição
BidiGenerateContentSetupComplete Uma mensagem BidiGenerateContentSetup do cliente, enviada quando a configuração é concluída
BidiGenerateContentServerContent Conteúdo gerado pelo modelo em resposta a uma mensagem do cliente
BidiGenerateContentToolCall Solicitação para que o cliente execute as chamadas de função e retorne as respostas com os IDs correspondentes
BidiGenerateContentToolCallCancellation É enviado quando uma chamada de função é cancelada devido à interrupção da saída do modelo pelo usuário.
Mensagens e eventos
BidiGenerateContentClientContent
Atualização incremental da conversa atual enviada pelo cliente. Todo o conteúdo aqui é adicionado incondicionalmente ao histórico de conversas e usado como parte do comando para o modelo gerar conteúdo.
Uma mensagem aqui vai interromper qualquer geração de modelo atual.
Campos
turns[]
Content
Opcional. O conteúdo anexado à conversa atual com o modelo.
Para consultas de turno único, esta é uma instância única. Para consultas com várias interações, esse é um campo repetido que contém o histórico da conversa e a solicitação mais recente.
turn_complete
bool
Opcional. Se verdadeiro, indica que a geração de conteúdo do servidor precisa começar com o comando acumulado. Caso contrário, o servidor aguarda outras mensagens antes de iniciar a geração.
BidiGenerateContentRealtimeInput
Entrada do usuário enviada em tempo real.
Isso é diferente de BidiGenerateContentClientContent de algumas maneiras:
Podem ser enviados continuamente sem interrupção para a geração de modelos.
Se for necessário misturar dados intercalados entre BidiGenerateContentClientContent e BidiGenerateContentRealtimeInput, o servidor vai tentar otimizar a resposta, mas não há garantias.
O fim da vez não é especificado explicitamente, mas é derivado da atividade do usuário (por exemplo, fim da fala).
Mesmo antes do fim da jogada, os dados são processados de forma incremental para otimizar o início rápido da resposta do modelo.
Sempre é considerada a entrada do usuário (não pode ser usada para preencher o histórico de conversas). Podem ser enviados continuamente sem interrupções. O modelo detecta automaticamente o início e o fim da fala do usuário e inicia ou encerra a transmissão da resposta de acordo com isso. Os dados são processados de forma incremental à medida que chegam, minimizando a latência.
Campos
media_chunks[]
Blob
Opcional. Dados de bytes inline para entrada de mídia.
BidiGenerateContentServerContent
Atualização incremental do servidor gerada pelo modelo em resposta às mensagens do cliente.
O conteúdo é gerado o mais rápido possível, e não em tempo real. Os clientes podem escolher armazenar em buffer e reproduzir em tempo real.
Campos
turn_complete
bool
Apenas saída. Se verdadeiro, indica que a geração do modelo foi concluída. A geração só vai começar em resposta a outras mensagens do cliente. Pode ser definido com content, indicando que content é o último na vez.
interrupted
bool
Apenas saída. Se verdadeiro, indica que uma mensagem do cliente interrompeu a geração de modelos atual. Se o cliente estiver reproduzindo o conteúdo em tempo real, esse é um bom sinal para interromper e esvaziar a fila de reprodução atual.
grounding_metadata
GroundingMetadata
Apenas saída. Agrupar metadados para o conteúdo gerado.
model_turn
Content
Apenas saída. O conteúdo que o modelo gerou como parte da conversa atual com o usuário.
BidiGenerateContentSetup
Mensagem a ser enviada na primeira e única mensagem do cliente. Contém a configuração que será aplicada durante a sessão de streaming.
Os clientes precisam aguardar uma mensagem BidiGenerateContentSetupComplete antes de enviar outras mensagens.
Campos
model
string
Obrigatório. O nome do recurso do modelo. Ele serve como um ID para o modelo usar.
Formato: models/{model}
generation_config
GenerationConfig
Opcional. Configuração de geração.
Os seguintes campos não são aceitos:
responseLogprobs
responseMimeType
logprobs
responseSchema
stopSequence
routingConfig
audioTimestamp
system_instruction
Content
Opcional. O usuário forneceu instruções do sistema para o modelo.
Observação: use apenas texto em partes. O conteúdo de cada parte vai ficar em um parágrafo separado.
tools[]
Tool
Opcional. Uma lista de Tools que o modelo pode usar para gerar a próxima resposta.
Um Tool é um código que permite ao sistema interagir com sistemas externos para realizar uma ação ou conjunto de ações fora do conhecimento e do escopo do modelo.
BidiGenerateContentSetupComplete
Esse tipo não tem campos.
Enviada em resposta a uma mensagem BidiGenerateContentSetup do cliente.
BidiGenerateContentToolCall
Solicita que o cliente execute as chamadas de função e retorne as respostas com os ids correspondentes.
Campos
function_calls[]
FunctionCall
Apenas saída. A chamada de função a ser executada.
BidiGenerateContentToolCallCancellation
Notificação ao cliente de que um ToolCallMessage emitido anteriormente com os ids especificados não deveria ter sido executado e precisa ser cancelado. Se houver efeitos colaterais nessas chamadas de ferramentas, os clientes poderão tentar desfazer as chamadas de ferramentas. Essa mensagem ocorre apenas nos casos em que os clientes interrompem as rodadas do servidor.
Campos
ids[]
string
Apenas saída. Os IDs das chamadas de ferramenta a serem canceladas.
BidiGenerateContentToolResponse
Resposta gerada pelo cliente para uma ToolCall recebida do servidor. Os objetos FunctionResponse individuais são associados aos respectivos objetos FunctionCall pelo campo id.
Nas APIs unary e de streaming do servidor, a chamada de função GenerateContent acontece trocando as partes Content, enquanto nas APIs bidi, a chamada de função acontece sobre esse conjunto dedicado de mensagens.
Campos
function_responses[]
FunctionResponse
Opcional. A resposta às chamadas de função.
Mais informações sobre tipos comuns
Para mais informações sobre os tipos de recurso de API mais usados Blob, Content, FunctionCall, FunctionResponse, GenerationConfig, GroundingMetadata e Tool, consulte Como gerar conteúdo.
Integrações de terceiros
Para implantações de apps da Web e para dispositivos móveis, confira as opções em:
Diariamente
Livekit (em inglês)
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-27 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_41.txt ---

URL: https://ai.google.dev/gemini-api/docs/caching

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
O armazenamento em cache de contexto
Nesta página
Quando usar o armazenamento em cache de contexto
Como o armazenamento em cache reduz custos
Como usar o armazenamento em cache de contexto
Gerar conteúdo usando um cache
Listar caches
Atualizar um cache
Excluir um cache
Outras considerações
Python
JavaScript
Go
REST
Em um fluxo de trabalho típico de IA, é possível transmitir os mesmos tokens de entrada repetidamente para um modelo. Usando o recurso de armazenamento em cache de contexto da API Gemini, é possível transmitir algum conteúdo ao modelo uma vez, armazenar os tokens de entrada em cache e, em seguida, consultar os tokens em cache para solicitações subsequentes. Em determinados volumes, o uso de tokens em cache tem um custo menor do que o envio repetido do mesmo corpus de tokens.
Ao armazenar em cache um conjunto de tokens, você pode escolher por quanto tempo o cache vai existir antes que os tokens sejam excluídos automaticamente. Essa duração de armazenamento em cache é chamada de time to live (TTL). Se não for definido, o TTL será definido como 1 hora. O custo do armazenamento em cache depende do tamanho do token de entrada e de quanto tempo você quer que os tokens persistam.
O armazenamento em cache de contexto é compatível com o Gemini 1.5 Pro e o Gemini 1.5 Flash.
Observação: o armazenamento em cache de contexto está disponível apenas para modelos estáveis com versões fixas (por exemplo, gemini-1.5-pro-001). É necessário incluir o sufixo de versão (por exemplo, -001 em gemini-1.5-pro-001).
Quando usar o armazenamento em cache de contexto
O armazenamento em cache de contexto é particularmente adequado para cenários em que um contexto inicial substancial é referenciado repetidamente por solicitações mais curtas. Use armazenamento em cache de contexto para casos de uso como estes:
Chatbots com instruções do sistema extensas
Análise repetitiva de arquivos de vídeo longos
Consultas recorrentes em grandes conjuntos de documentos
Análise frequente do repositório de código ou correção de bugs
Como o armazenamento em cache reduz custos
O armazenamento em cache de contexto é um recurso pago projetado para reduzir os custos operacionais gerais. O faturamento é baseado nos seguintes fatores:
Contagem de tokens de cache: o número de tokens de entrada armazenados em cache, faturados com uma taxa reduzida quando incluído nos comandos subsequentes.
Duração do armazenamento:o tempo de armazenamento e cobrança dos tokens em cache (TTL), faturado com base na duração do TTL da contagem de tokens em cache. Não há limites mínimos ou máximos no TTL.
Outros fatores: outras cobranças se aplicam, como tokens de entrada não armazenados em cache e tokens de saída.
Para detalhes atualizados sobre preços, consulte a página de preços da API Gemini. Para saber como contar tokens, consulte o guia de tokens.
Como usar o armazenamento em cache de contexto
Nesta seção, presumimos que você instalou um SDK do Gemini (ou o curl) e configurou uma chave de API, conforme mostrado no Guia de início rápido.
Gerar conteúdo usando um cache
O exemplo a seguir mostra como gerar conteúdo usando um arquivo de vídeo e instruções do sistema em cache.
import os
import pathlib
import requests
import time

from google import genai
from google.genai import types

# Get your API key from https://aistudio.google.com/app/apikey
# Put it in a "GOOGLE_API_KEY" environment variable.
# For more details, see
# https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb
client = genai.Client()

# Download video file
url = 'https://storage.googleapis.com/generativeai-downloads/data/Sherlock_Jr_FullMovie.mp4'
path_to_video_file = pathlib.Path('Sherlock_Jr_FullMovie.mp4')
if not path_to_video_file.exists():
  with path_to_video_file.open('wb') as wf:
    response = requests.get(url, stream=True)
    for chunk in response.iter_content(chunk_size=32768):
      wf.write(chunk)

# Upload the video using the Files API
video_file = client.files.upload(file=path_to_video_file)

# Wait for the file to finish processing
while video_file.state.name == 'PROCESSING':
  print('Waiting for video to be processed.')
  time.sleep(2)
  video_file = client.files.get(name=video_file.name)

print(f'Video processing complete: {video_file.uri}')

# You must use an explicit version suffix. "-flash-001", not just "-flash".
model='models/gemini-1.5-flash-001'

# Create a cache with a 5 minute TTL
cache = client.caches.create(
    model=model,
    config=types.CreateCachedContentConfig(
      display_name='sherlock jr movie', # used to identify the cache
      system_instruction=(
          'You are an expert video analyzer, and your job is to answer '
          'the user\'s query based on the video file you have access to.'
      ),
      contents=[video_file],
      ttl="300s",
  )
)

# Construct a GenerativeModel which uses the created cache.
response = client.models.generate_content(
  model = model,
  contents= (
    'Introduce different characters in the movie by describing '
    'their personality, looks, and names. Also list the timestamps '
    'they were introduced for the first time.'),
  config=types.GenerateContentConfig(cached_content=cache.name)
)

print(response.usage_metadata)

# The output should look something like this:
#
# prompt_token_count: 696219
# cached_content_token_count: 696190
# candidates_token_count: 214
# total_token_count: 696433

print(response.text)
Listar caches
Não é possível recuperar ou visualizar o conteúdo armazenado em cache, mas é possível recuperar metadados de cache (name, model, display_name, usage_metadata, create_time, update_time e expire_time).
Para listar os metadados de todos os caches enviados, use CachedContent.list():
for cache in client.caches.list():
  print(cache)
Para buscar os metadados de um objeto de cache, se você souber o nome dele, use get:
client.caches.get(name=name)
Atualizar um cache
É possível definir um novo ttl ou expire_time para um cache. Não é possível mudar qualquer outra coisa sobre o cache.
O exemplo a seguir mostra como atualizar o ttl de um cache usando client.caches.update().
from google import genai
from google.genai import types

client.caches.update(
  name = cache.name,
  config  = types.UpdateCachedContentConfig(
      ttl='300s'
  )
)
Para definir o tempo de expiração, ele aceita um objeto datetime ou uma string de data e hora formatada em ISO (dt.isoformat(), como 2025-01-27T16:02:36.473528+00:00). O tempo precisa incluir um fuso horário (datetime.utcnow() não anexa um fuso horário, datetime.now(datetime.timezone.utc) anexa um fuso horário).
from google import genai
from google.genai import types
import datetime

# You must use a time zone-aware time.
in10min = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(minutes=10)

client.caches.update(
  name = cache.name,
  config  = types.UpdateCachedContentConfig(
      expire_time=in10min
  )
)
Excluir um cache
O serviço de cache oferece uma operação de exclusão para remover manualmente o conteúdo do cache. O exemplo a seguir mostra como excluir um cache:
client.caches.delete(cache.name)
Outras considerações
Considere as seguintes considerações ao usar o armazenamento em cache de contexto:
A contagem de tokens de entrada mínima para o armazenamento em cache de contexto é 32.768, e a máxima é igual ao máximo do modelo. Para saber mais sobre como contar tokens, consulte o guia de tokens.
O modelo não faz distinção entre tokens em cache e tokens de entrada normais. O conteúdo armazenado em cache é simplesmente um prefixo para o comando.
Não há taxas ou limites de uso especiais no armazenamento em cache de contexto. Os limites de taxa padrão para GenerateContent são aplicados, e os limites de token incluem tokens em cache.
O número de tokens em cache é retornado no usage_metadata das operações de criação, acesso e listagem do serviço de cache e também em GenerateContent ao usar o cache.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-01 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_42.txt ---

URL: https://ai.google.dev/gemini-api/docs/prompting-intro

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Introdução aos comandos
Estratégias de comando
Estratégias de solicitação de arquivos
Guia de comandos do Imagen
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Introdução ao design de prompts
Nesta página
O que é um prompt
Tipos de conteúdo do prompt
Próximas etapas
Design de prompt é o processo de criação de prompts que extraem a resposta desejada dos modelos de linguagem. Escrever solicitações bem estruturadas é uma parte essencial para garantir respostas precisas e de alta qualidade de um modelo de linguagem. Esta página apresenta alguns conceitos básicos, estratégias e práticas recomendadas para você começar a projetar solicitações.
O que é um prompt
Uma solicitação é uma solicitação de linguagem natural enviada a um modelo de linguagem para receber uma resposta. As solicitações podem conter perguntas, instruções, informações contextuais, exemplos e entrada parcial para que o modelo conclua ou continue. Depois que o modelo recebe uma solicitação, dependendo do tipo de modelo usado, ele pode gerar texto, embeddings, código, imagens, vídeos, músicas e muito mais.
Tipos de conteúdo do prompt
As solicitações podem incluir um ou mais dos seguintes tipos de conteúdo:
Este campo é (obrigatório)
Contexto (opcional)
Exemplos (opcional)
Entrada
Uma entrada é o texto no prompt para o qual você quer que o modelo forneça uma resposta, e é um tipo de conteúdo obrigatório. As entradas podem ser uma pergunta que o modelo responde (entrada de pergunta), uma tarefa que o modelo realiza (entrada de tarefa), uma entidade em que o modelo opera (entrada de entidade) ou entrada parcial que o modelo conclui ou continue (entrada concluída).
Entrada da pergunta
Uma entrada de pergunta é uma pergunta feita ao modelo ao qual o modelo fornece uma resposta.
Comando:
What's a good name for a flower shop that specializes in selling bouquets of
dried flowers? Create a list of 10 options with just the names.
Resposta:
Here are 10 names for a flower shop specializing in dried flowers:

 1. Everlasting Blooms
 2. Dried & Delightful
 3. The Petal Preserve
 4. Whispers of Wildflowers
 5. Forever Blooms
 6. The Botanical Muse
 7. Timeless Blooms
 8. Dried Flower Co.
 9. Bloom & Co.
 10. The Sun-Kissed Petals
(gemini-1.5-flash)
Entrada da tarefa
Uma entrada de tarefa é uma tarefa que você quer que o modelo execute. Por exemplo, é possível dizer ao modelo para dar ideias ou sugestões para algo.
Comando:
Give me a simple list of just the things that I must bring on a camping trip. The list should have 10 items.
Resposta:
Here's a list of 10 essential items for a camping trip:

 1. **Tent:** Your shelter from the elements.
 2. **Sleeping Bag:** Stay warm and comfortable.
 3. **Sleeping Pad:** Insulation and cushioning for a good night's sleep.
 4. **Headlamp or Flashlight:** Light for nighttime activities.
 5. **First Aid Kit:** Be prepared for minor injuries.
 6. **Water Bottle/Hydration Pack:** Stay hydrated.
 7. **Food and Snacks:** Fuel for your adventures.
 8. **Cooking Gear:** Camp stove, fuel, utensils, etc.
 9. **Knife and Multitool:** Essential for various tasks.
 10. **Camp Chair:** Enjoy your campfire and meals comfortably.
(gemini-1.5-flash)
Entrada de entidade
Uma entrada de entidade é o modelo que realiza uma ação, como classificar ou resumir. Esse tipo de entrada pode se beneficiar da inclusão de instruções.
Comando:
Classify the following items as [large, small].
Elephant
Mouse
Snail
Resposta:
Here's the classification:

 * **Elephant:** Large
 * **Mouse:** Small
 * **Snail:** Small
(gemini-1.5-flash)
Entrada de conclusão
Uma entrada de conclusão é o texto que o modelo deve concluir ou continuar.
Comando:
Complete the following prompt: Some simple strategies for overcoming writer's block include...
Resposta:
Some simple strategies for overcoming writer's block include:

 * **Freewriting:** Write non-stop for a set amount of time (5-10 minutes) without worrying about grammar, spelling, or even making sense. Just keep your pen moving and let your thoughts flow freely. This can help you loosen up and access ideas you might not have considered otherwise.
 * **Brainstorming:** Make a list of everything that comes to mind related to your topic, no matter how silly or unrelated it seems. You can also use mind mapping or other visual brainstorming techniques.
 * **Changing your environment:** Sometimes a change of scenery can be all you need to get the creative juices flowing. Go for a walk, work in a coffee shop, or even just move to a different room in your house. 
 * **Reading:** Immerse yourself in the work of other writers, especially those who inspire you. Pay attention to their style, their structure, and their use of language. 
 * **Taking a break:** Sometimes the best way to overcome writer's block is to simply step away from the project for a while. Go for a walk, watch a movie, listen to music, or do something else that you enjoy. You might be surprised at how much clearer your head feels when you return to your writing. 
 * **Focusing on a single element:** Instead of tackling the entire project, focus on a single sentence, paragraph, or scene. Once you get something down on paper, it can be easier to build from there.
 * **Starting with the ending:** If you're stuck on the beginning, try writing the ending first. This can help you to clarify your overall vision for the project and provide a framework for your ideas.
 * **Talking it out:** Share your ideas and challenges with a friend, a writing group, or a writing coach. Discussing your project with someone else can help you to see it from a new perspective and find solutions to your writing problems.
 
 Remember, writer's block is a common experience, and it's not a sign that you're a bad writer. Just be patient with yourself, try some of these strategies, and keep writing!
(gemini-1.5-flash)
Contexto
Será um dos seguintes:
Instruções que especificam como o modelo deve se comportar.
Informações que o modelo usa ou faz referência para gerar uma resposta.
Adicione informações contextuais ao prompt quando for preciso fornecer informações ao modelo ou restrinja os limites das respostas apenas ao que está dentro do prompt.
Comando:
Marbles:
Color: red
Number: 12
Color: blue
Number: 28
Color: yellow
Number: 15
Color: green
Number: 17

How many green marbles are there?
Resposta:
There are 17 green marbles.
(gemini-1.5-flash)
Exemplos
Exemplos são pares de entrada e saída incluídos no prompt para dar ao modelo um exemplo de resposta ideal. Incluir exemplos no prompt é uma estratégia eficaz para personalizar o formato da resposta.
Comando:
Classify the following.
Options:
- red wine
- white wine

Text: Chardonnay
The answer is: white wine
Text: Cabernet
The answer is: red wine
Text: Moscato
The answer is: white wine

Text: Riesling
The answer is:
Resposta:
The answer is: white wine
(gemini-1.5-flash)
Próximas etapas
Agora que você já entende o design de comandos, tente escrever seus próprios comandos usando o Google AI Studio.
Para entender melhor o design de comandos, consulte o tópico estratégias de comandos.
Para saber mais sobre comandos multimodais, consulte Comandos com arquivos de mídia.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_43.txt ---

URL: https://ai.google.dev/gemini-api/docs/prompting-strategies

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Introdução aos comandos
Estratégias de comando
Estratégias de solicitação de arquivos
Guia de comandos do Imagen
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Estratégias de design de comandos
Nesta página
Dê instruções claras e específicas
Definir a tarefa a ser executada
Especificar restrições
Definir o formato da resposta
Incluir exemplos few-shott
Nesta página, apresentamos algumas estratégias gerais de criação de comandos que podem ser implementadas.
Os modelos de linguagem grandes (LLM) são treinados com grandes quantidades de dados de texto para aprender os padrões e as relações entre a linguagem. Quando recebem algum texto (o prompt), os modelos de idioma podem prever o que provavelmente virá em seguida, como uma sofisticada ferramenta de preenchimento automático.
O Google AI Studio hospeda uma galeria de comandos simples para mostrar de forma interativa muitos dos conceitos compartilhados neste guia. No restante deste guia, você vai aprender sobre as seguintes estratégias de design de comando:
Dê instruções claras e específicas
Incluir exemplos few-shott
Adicionar informações contextuais
Adicionar prefixos
Permitir que o modelo conclua a entrada parcial
Dê instruções claras e específicas
Dar instruções ao modelo sobre o que fazer é uma maneira eficaz e eficiente de personalizar o comportamento dele. As instruções fornecidas precisam ser claras e específicas. As instruções podem ser tão simples quanto uma lista de instruções detalhadas ou complexas, como mapear a experiência e a mentalidade de um usuário.
Definir a tarefa a ser executada
Descreva em detalhes a tarefa que você quer que o modelo realize. A tarefa pode ser tão simples quanto uma lista passo a passo de instruções ou tão complexa quanto mapear a experiência e a mentalidade de um usuário. O comando a seguir pede que o modelo resuma um bloco de texto:
Comando:
Summarize this text:
Text: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially
faster than any modern traditional computer. At very tiny scales, physical matter acts as both
particles and as waves, and quantum computing uses specialized hardware to leverage this behavior.
The operating principles of quantum devices is beyond the scope of classical physics. When deployed
at scale, quantum computers could be used in a wide variety of applications such as: in
cybersecurity to break existing encryption methods while helping researchers create new ones, in
meteorology to develop better weather forecasting etc. However, the current state of the art quantum
computers are still largely experimental and impractical.
Resposta:
Quantum computers leverage the wave-particle duality of matter at tiny scales to perform
 calculations exponentially faster than traditional computers. They harness quantum phenomena,
 which are beyond the scope of classical physics, to achieve this speed advantage. While
 promising for applications like cybersecurity, weather forecasting, and beyond, current
 quantum computers are still experimental and not yet practical for widespread use.
(gemini-1.5-flash)
Especificar restrições
Especifique as restrições à leitura do comando ou à geração de uma resposta. Você pode dizer ao modelo o que fazer e o que não fazer. No exemplo anterior, o resumo é mais curto do que o texto original, mas talvez você queira que o resumo seja mais curto. Nesse caso, é possível especificar uma restrição no comando sobre a duração do resumo:
Comando:
Summarize this text in two sentences:
Text: A quantum computer exploits quantum mechanical phenomena to perform calculations exponentially
faster than any modern traditional computer. At very tiny scales, physical matter acts as both
particles and as waves, and quantum computing uses specialized hardware to leverage this behavior.
The operating principles of quantum devices is beyond the scope of classical physics. When deployed
at scale, quantum computers could be used in a wide variety of applications such as: in
cybersecurity to break existing encryption methods while helping researchers create new ones, in
meteorology to develop better weather forecasting etc. However, the current state of the art quantum
computers are still largely experimental and impractical.
Resposta:
Quantum computers harness the wave-particle duality of matter at the quantum level to perform
 computations exponentially faster than traditional computers. While these machines hold
 immense potential for fields like cybersecurity and weather forecasting, they are currently
 in their early stages of development and not yet practical for widespread use.
(gemini-1.5-flash)
Definir o formato da resposta
Você também pode dar instruções que especifiquem o formato da resposta. Por exemplo, você pode pedir que a resposta seja formatada como tabela, lista com marcadores, argumento rápido de venda, palavras-chave, frase ou parágrafo. A mensagem do sistema a seguir instrui o modelo a ser mais interativo na resposta:
Mensagem do sistema
All questions should be answered comprehensively with details, unless the user requests a concise response specifically.
Comando
What is a smart way to make a business that sells DVD's in 2025?
Resposta:
Okay, you're looking at a real uphill battle here. The DVD market is significantly diminished due to streaming services, digital downloads, and Blu-ray. However, that doesn't necessarily mean it's impossible to build a DVD-based business in 2025. It just requires a hyper-focused strategy and a deep understanding of the remaining market. Here's a breakdown of smart approaches:

 I. Understanding the Challenges and Opportunities
 Challenges:
 Dominance of Streaming: Netflix, Amazon Prime Video, Disney+, and countless other services offer vast libraries on-demand.
 Digital Downloads/Rentals: Platforms like iTunes, Google Play, and Vudu make purchasing or renting digital versions easy.
 Blu-ray & 4K Ultra HD: Offer superior picture and sound quality, often preferred by home theater enthusiasts.
 ....
.....
(gemini-2.0-flash)
Outro exemplo que usamos no passado é:
Mensagem do sistema
All questions should be answered comprehensively with details, unless the user requests a
 concise response specifically. Respond in the same language as the query.
Comando
What is a smart way to create a lemonade business?
Resposta:
Launching a Successful Lemonade Stand: A Smart Approach
 Creating a lemonade business, whether a simple stand or a larger operation, requires strategic thinking. Here's a breakdown of how to approach it smartly:
 
 1. Define Your Business:
 Scope: Are you aiming for a small, seasonal lemonade stand, a food truck, a delivery service, or something else entirely?
 Target Audience: Who are you selling to? Families, office workers, tourists?
 Unique Selling Proposition: What sets your lemonade apart? Special flavors, organic ingredients, a unique recipe?
 
 Pricing: Research competitor prices and determine a profitable pricing structure.
 Location: Consider foot traffic, accessibility, and regulations for your chosen location.
 .....
(gemini-1.5-flash)
Resumo
Dê aos modelos instruções sobre o que fazer.
As instruções precisam ser claras e específicas.
Especifique restrições ou requisitos de formatação para a saída.
Incluir exemplos few-shott
Você pode incluir exemplos no comando que mostram ao modelo como fazer isso da forma certa. O modelo tenta identificar padrões e relações entre os exemplos e os aplica ao gerar uma resposta. As solicitações que contêm alguns exemplos são chamadas de solicitações curtas, enquanto as que não fornecem exemplos são chamadas de solicitações de zero disparo. Muitas vezes, as solicitações de imagem são usadas para regular a formatação, a frase, o escopo ou o padrão geral das respostas do modelo. Use exemplos específicos e variados para ajudar o modelo a restringir o foco e gerar resultados mais precisos.
Recomendamos sempre incluir exemplos few-shot nos comandos. Os comandos sem exemplos few-shot provavelmente serão menos eficazes. Na verdade, é possível remover instruções do comando se os exemplos forem claros o suficiente para mostrar a tarefa em questão.
Tomada zero ou poucas fotos
O prompt de imagem zero pede ao modelo para escolher a melhor explicação.
Comando:
Please choose the best explanation to the question:

Question: How is snow formed?
Explanation1: Snow is formed when water vapor in the air freezes into ice crystals in the
atmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and
accumulate on the ground.
Explanation2: Water vapor freezes into ice crystals forming snow.
Answer:
Resposta:
Explanation 1 is the best explanation.
(gemini-1.5-flash)
Se o caso de uso exigir que o modelo produza respostas concisas, inclua exemplos no prompt para dar preferência a respostas concisas.
O prompt a seguir fornece dois exemplos que mostram preferência pelas explicações mais curtas. Na resposta, é possível ver que os exemplos guiaram o modelo para escolher a explicação mais curta (Explicação2), em vez da explicação mais longa (Explicação1) como fazia anteriormente.
Comando:
Below are some examples showing a question, explanation, and answer format:

Question: Why is sky blue?
Explanation1: The sky appears blue because of Rayleigh scattering, which causes shorter blue
wavelengths of light to be scattered more easily than longer red wavelengths, making the sky look
blue.
Explanation2: Due to Rayleigh scattering effect.
Answer: Explanation2

Question: What is the cause of earthquakes?
Explanation1: Sudden release of energy in the Earth's crust.
Explanation2: Earthquakes happen when tectonic plates suddenly slip or break apart, causing a
release of energy that creates seismic waves that can shake the ground and cause damage.
Answer: Explanation1

Now, Answer the following question given the example formats above:

Question: How is snow formed?
Explanation1: Snow is formed when water vapor in the air freezes into ice crystals in the
atmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and
accumulate on the ground.
Explanation2: Water vapor freezes into ice crystals forming snow.
Answer:
Resposta:
Answer: Explanation2
(gemini-1.5-flash)
Encontre o número ideal de exemplos
Teste o número de exemplos a serem fornecidos no comando para ter os resultados mais desejados. Modelos como o Gemini geralmente podem identificar padrões usando alguns exemplos. No entanto, talvez seja necessário testar quantos exemplos levam aos resultados desejados. Ao mesmo tempo, se você incluir muitos exemplos, o modelo poderá começar a sobrepor a resposta aos exemplos.
Use exemplos para mostrar padrões em vez de antipadrões
Usar exemplos para mostrar ao modelo um padrão a ser seguido é mais eficaz do que usar exemplos para mostrar ao modelo um antipadrão a ser evitado.
⛔ Padrão negativo:
Exemplo
Don't end haikus with a question:
Haiku are fun
A short and simple poem
Don't you enjoy them?

✅ Padrão positivo:
Exemplo
Always end haikus with an assertion:
Haiku are fun
A short and simple poem
A joy to write

Usar formatação consistente em todos os exemplos
Confira se a estrutura e a formatação desses exemplos são iguais para evitar respostas com formatos indesejados. Um dos principais objetivos de adicionar exemplos few-shot nos comandos é mostrar ao modelo o formato da resposta. Portanto, é essencial garantir um formato consistente em todos os exemplos, especialmente prestando atenção às tags XML, espaços em branco, novas linhas e divisores de exemplo.
Resumo
Incluir exemplos de resposta no prompt ajuda o modelo a aprender como responder.
Dê ao modelo exemplos dos padrões a serem seguidos em vez de exemplos de padrões a serem evitados.
Faça experiências com o número de solicitações para incluir. Dependendo do modelo, poucos exemplos são ineficazes na alteração do comportamento do modelo. Muitos exemplos fazem com que o modelo apresente overfitting.
Usar formatação consistente em todos os exemplos
Adicionar informações contextuais
É possível incluir nas instruções e informações do prompt que o modelo precisa para resolver um problema, em vez de presumir que o modelo tem todas as informações necessárias. Essas informações contextuais ajudam o modelo a entender as restrições e os detalhes do que você está pedindo que ele faça.
O exemplo a seguir pede ao modelo que forneça orientação para solução de problemas de um roteador:
Comando:
What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and
blinking slowly.
Resposta:
A yellow blinking light on your Google Wifi router usually indicates a problem with the internet connection. Here are some steps to troubleshoot and fix the issue:
 1. Restart your router and modem:
 - Unplug your modem from the power outlet and wait for 30 seconds.
 - Plug your modem back in and wait for it to fully boot up.
 - Unplug your Google Wifi router and wait for 30 seconds.
 - Plug your Google Wifi router back in and wait for it to fully boot up.
.....
(gemini-1.5-flash)
A resposta se parece com informações genéricas de solução de problemas que não são específicas do roteador ou do status das luzes indicadoras de LED.
Para personalizar a resposta do roteador específico, é possível adicionar ao prompt o guia de solução de problemas dele como contexto para consulta ao fornecer uma resposta.
Comando:
Answer the question using the text below. Respond with only the text provided.
Question: What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly.

Text:
Color: Slowly pulsing yellow
What it means: There is a network error.
What to do:
Check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.

Color: Fast blinking yellow
What it means: You are holding down the reset button and are factory resetting this device.
What to do:
If you keep holding down the reset button, after about 12 seconds, the light will turn solid yellow. Once it is solid yellow, let go of the factory reset button.

Color: Solid yellow
What it means: Router is factory resetting.
What to do:
This can take up to 10 minutes. When it's done, the device will reset itself and start pulsing white, letting you know it's ready for setup.

Color: Solid red
What it means: Something is wrong.
What to do:
Critical failure. Factory reset the router. If the light stays red, contact Wifi customer support.
Resposta:
Check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.
(gemini-1.5-flash)
Resumo
Inclua informações (contexto) no prompt que você quer que o modelo use ao gerar uma resposta.
Dê ao modelo instruções sobre como usar as informações contextuais.
Adicionar prefixos
Um prefixo é uma palavra ou frase que você adiciona ao conteúdo do prompt e pode ser usada para várias finalidades, dependendo de onde você o colocou:
Prefixo de entrada: a adição de um prefixo aos sinais de entrada indica partes semanticamente significativas da entrada para o modelo. Por exemplo, os prefixos "Inglês:" e "Francês:" demarcam dois idiomas diferentes.
Prefixo da saída: mesmo que a saída seja gerada pelo modelo, é possível adicionar um prefixo à saída na solicitação. O prefixo de saída fornece ao modelo informações sobre o que é esperado como resposta. Por exemplo, o prefixo de saída "JSON:" sinaliza para o modelo que a saída precisa estar no formato JSON.
Prefixo de exemplo: em prompts curtos, adicionar prefixos aos exemplos fornece rótulos que o modelo pode usar ao gerar a saída, o que facilita a análise do conteúdo de saída.
No exemplo a seguir, "Texto:" é o prefixo de entrada e "A resposta é:" é o prefixo de saída.
Comando:
Classify the text as one of the following categories.
- large
- small
Text: Rhino
The answer is: large
Text: Mouse
The answer is: small
Text: Snail
The answer is: small
Text: Elephant
The answer is:
Resposta:
The answer is: large
(gemini-1.5-flash)
Permitir que o modelo conclua a entrada parcial
Os modelos de linguagem generativa funcionam como uma ferramenta avançada de preenchimento automático. Quando você fornece conteúdo parcial, o modelo pode fornecer o restante do conteúdo ou o que considera ser uma continuação desse conteúdo, como uma resposta. Ao fazer isso, se você incluir exemplos ou contexto, o modelo poderá levar esses exemplos ou contexto em consideração.
O exemplo a seguir fornece um prompt com uma instrução e uma entrada de entidade:
Comando:
For the given order, return a JSON object that has the fields cheeseburger, hamburger, fries, or
drink, with the value being the quantity.

Order: A burger and a drink.
Resposta:
```
{
 "hamburger": 1,
 "drink": 1
}
```
(gemini-1.5-flash)
Embora o modelo tenha feito o que foi solicitado, escrever as instruções em linguagem natural às vezes pode ser desafiador e deixar muito para a interpretação do modelo. Por exemplo, o cardápio de um restaurante pode conter muitos itens. Para reduzir o tamanho da resposta JSON, omita os itens que não foram ordenados. Nesse caso, é possível fornecer um exemplo e um prefixo de resposta e deixar o modelo concluí-lo:
Comando:
Valid fields are cheeseburger, hamburger, fries, and drink.
Order: Give me a cheeseburger and fries
Output:
```
{
 "cheeseburger": 1,
 "fries": 1
}
```
Order: I want two burgers, a drink, and fries.
Output:
Resposta:
```
{
 "hamburger": 2,
 "drink": 1,
 "fries": 1
}
```
(gemini-1.5-flash)
Observe como "cheeseburger" foi excluído da saída porque não fazia parte do pedido.
Solicitar que o modelo formate a resposta
A estratégia de conclusão também pode ajudar a formatar a resposta. O exemplo a seguir solicita que o modelo crie um esboço de redação:
Comando:
Create an outline for an essay about hummingbirds.
Resposta:
Hummingbirds: A Symphony of Speed and Color
 I. Introduction
 A. Hummingbirds are fascinating creatures known for their dazzling colors, lightning-fast flight, and unique feeding habits.
 B. Brief overview of the diversity of hummingbird species and their geographic distribution.
 C. Thesis statement: Hummingbirds are an embodiment of resilience, adaptation, and the wonders of the natural world.
.....
(gemini-1.5-flash)
O prompt não especificou o formato da estrutura de tópicos, e o modelo escolheu um formato para você. Para que o modelo retorne um contorno em um formato específico, adicione texto que represente o início dele e deixe que o modelo o conclua com base no padrão iniciado.
Comando:
Create an outline for an essay about hummingbirds.
I. Introduction
 *
Resposta:
Hummingbirds: Jewels of the Air
 **I. Introduction**
 * **Hook:** Begin with a captivating image or anecdote about hummingbirds, emphasizing their vibrant colors, rapid flight, and unique feeding habits.
 * **Background:** Briefly introduce hummingbirds as the smallest birds in the world and their fascinating adaptations for a nectar-rich diet.
 * **Thesis:** State the main argument or focus of the essay. Examples: 
 * **The incredible adaptations of hummingbirds enable them to thrive in diverse ecosystems.**
 * **Hummingbirds play a crucial role in pollination and biodiversity.**
 * **The beauty and grace of hummingbirds make them captivating subjects for both scientific study and artistic appreciation.**
(gemini-1.5-flash)
Resumo
Se você fornecer uma entrada parcial ao modelo, ele a preencherá com base em qualquer exemplo ou contexto disponível no prompt.
Às vezes, pode ser mais fácil fazer com que o modelo conclua uma entrada do que descrever a tarefa em linguagem natural.
Adicionar uma resposta parcial a uma solicitação pode orientar o modelo para seguir um padrão ou formato desejado.
Dividir comandos em componentes simples
Para casos de uso que exigem solicitações complexas, é possível ajudar o modelo a gerenciar essa complexidade dividindo os itens em componentes mais simples.
Detalhar as instruções
Em vez de ter várias instruções em um só comando, crie um por instrução. Você pode escolher qual solicitação processar com base na entrada do usuário.
Comandos em cadeia
Para tarefas complexas que envolvem várias etapas sequenciais, torne cada etapa uma solicitação e encadeie os comandos em uma sequência. Nessa cadeia sequencial, a saída de um comando na sequência se torna a entrada do próximo comando. A saída do último comando na sequência é a saída final.
Respostas agregadas
A agregação é quando você quer executar diferentes tarefas paralelas em diferentes partes dos dados e agregar os resultados para produzir a saída final. Por exemplo, é possível dizer ao modelo para executar uma operação na primeira parte dos dados, executar outra operação no restante dos dados e agregar os resultados.
Resumo
Divida instruções complexas em um comando para cada instrução e decida qual comando aplicar com base na entrada do usuário.
Divida várias etapas sequenciais em comandos separados e encadeie-os de modo que a saída do comando anterior se torne a entrada do comando a seguir.
Separe tarefas paralelas e agregue as respostas para produzir o resultado final.
Teste diferentes valores de parâmetros
Cada chamada que você envia a um modelo inclui valores de parâmetros que controlam como o modelo gera uma resposta. O modelo pode gerar diferentes resultados para diferentes valores de parâmetros. Teste diferentes valores de parâmetros para conseguir os melhores valores para a tarefa. Os parâmetros disponíveis para modelos diferentes podem ser diferentes. Os parâmetros mais comuns são:
Máximo de tokens de saída
Temperatura
Top-K
Top-P
Máximo de tokens de saída
Número máximo de tokens que podem ser gerados na resposta. Um token tem cerca de quatro caracteres. 100 tokens correspondem a cerca de 20 palavras.
Especifique um valor mais baixo para respostas mais curtas e um valor mais alto para respostas mais longas.
Temperatura
A temperatura é usada para amostragem durante a geração da resposta, que ocorre quando topP e topK são aplicados. A temperatura controla o grau de aleatoriedade na seleção do token. Temperaturas mais baixas são boas para comandos que exigem uma resposta mais determinista e menos aberta ou criativa, enquanto temperaturas maiores podem levar a resultados mais diversos ou criativos. Uma temperatura de 0 é determinista, o que significa que a resposta de maior probabilidade é sempre selecionada.
Na maioria dos casos de uso, é melhor começar com a temperatura 0.2. Se o modelo retornar uma resposta muito genérica, muito curta ou se o modelo fornecer uma resposta substituta, tente aumentar a temperatura.
Top-K
O top-k muda a forma como o modelo seleciona tokens para saída. Um top-K de 1 significa que o próximo token selecionado é o mais provável entre todos os tokens no vocabulário do modelo (também chamado de decodificação gananciosa), enquanto um top-K de 3 significa que o próximo token está selecionado entre os três tokens mais prováveis usando a temperatura.
Para cada etapa da seleção de tokens, são amostrados os tokens top-K com as maiores probabilidades. Em seguida, os tokens são filtrados com base no valor de top-P com o token final selecionado por meio da amostragem de temperatura.
Especifique um valor mais baixo para respostas menos aleatórias e um valor mais alto para respostas mais aleatórias. O top-K padrão é 40.
Top-P
O top-p muda a forma como o modelo seleciona tokens para saída. Os tokens são selecionados do mais provável (veja o top-K) para o menos provável até que a soma das probabilidades seja igual ao valor do top-P. Por exemplo, se os tokens A, B e C tiverem uma probabilidade de 0,3, 0,2 e 0,1 e o valor de top-P for 0.5, o modelo selecionará A ou B como token seguinte usando temperatura e exclui C como candidato.
Especifique um valor mais baixo para respostas menos aleatórias e um valor mais alto para respostas mais aleatórias. O top-P padrão é 0.95.
Estratégias de iteração de prompt
O design de prompt é um processo iterativo que geralmente requer algumas iterações antes de receber a resposta desejada de forma consistente. Esta seção fornece orientações sobre algumas coisas que você pode tentar ao iterar nas suas solicitações.
Use formulações diferentes
O uso de palavras diferentes ou frases em suas solicitações costuma gerar respostas diferentes do modelo, mesmo que todas tenham o mesmo significado. Se você não estiver recebendo os resultados esperados, tente reformular o prompt.
Version 1:
How do I bake a pie?

Version 2:
Suggest a recipe for a pie.

Version 3:
What's a good pie recipe?

Mude para uma tarefa análoga
Se você não conseguir que o modelo siga as instruções para uma tarefa, tente dar a ela instruções para uma tarefa análoga que consegue o mesmo resultado.
Esse prompt instrui o modelo a categorizar um livro usando categorias predefinidas.
Comando:
Which category does The Odyssey belong to:
thriller
sci-fi
mythology
biography
Resposta:
The Odyssey belongs to the category of **mythology**. 

 Here's why:
 
 * **Mythology:** The Odyssey tells the story of Odysseus, a hero from Greek mythology, and his
 journey home after the Trojan War. It features gods, monsters, and supernatural events common to
 Greek mythology.
.....
(gemini-1.5-flash)
A resposta está correta, mas o modelo não permaneceu dentro dos limites das opções. Você também precisa modelar para responder apenas com uma das opções, em vez de em uma frase completa. Nesse caso, é possível reformular as instruções como uma pergunta de múltipla escolha e solicitar que o modelo escolha uma opção.
Comando:
Multiple choice problem: Which of the following options describes the book The Odyssey?
Options:
- thriller
- sci-fi
- mythology
- biography
Resposta:
The correct answer is **mythology**.
(gemini-1.5-flash)
Mude a ordem do conteúdo do comando
Às vezes, a ordem do conteúdo no prompt pode afetar a resposta. Tente alterar a ordem do conteúdo e ver como isso afeta a resposta.
Version 1:
[examples]
[context]
[input]

Version 2:
[input]
[examples]
[context]

Version 3:
[examples]
[input]
[context]
Respostas substitutas
Uma resposta substituta é retornada pelo modelo quando a solicitação ou a resposta acionam um filtro de segurança. Um exemplo de resposta substituta é "Não posso ajudar com isso, porque sou apenas um modelo de linguagem".
Se o modelo responder com uma resposta substituta, tente aumentar a temperatura.
O que evitar
Evite depender de modelos para gerar informações factuais.
Use com cuidado em problemas matemáticos e lógicos.
Próximas etapas
Agora que você entende melhor o design de comandos, tente escrever seus próprios comandos usando o Google AI Studio.
Para saber mais sobre comandos multimodais, consulte Comandos com arquivos de mídia.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-06 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_44.txt ---

URL: https://ai.google.dev/gemini-api/docs/file-prompting-strategies

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Introdução aos comandos
Estratégias de comando
Estratégias de solicitação de arquivos
Guia de comandos do Imagen
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Estratégias de solicitação de arquivos
Nesta página
Como usar arquivos de mídia com comandos
Estratégias para dar comandos com mídia
Conceitos básicos do design de comandos
Como solucionar problemas do comando multimodal
conceitos básicos do design de comandos
Especificar as instruções
Adicionar alguns exemplos
Detalhar por passo
A família de modelos de inteligência artificial (IA) Gemini foi criada para processar vários tipos de dados de entrada, incluindo texto, imagens e áudio. Como esses modelos podem processar mais de um tipo ou modo de dados, eles são chamados de modelos multimodais ou explicados como tendo recursos multimodais.
Observação: a ativação com arquivos de mídia é compatível com modelos específicos do Gemini. Para mais informações sobre quais modelos oferecem suporte a esse recurso, consulte os guias Vision e Áudio.
Esta página oferece orientações e práticas recomendadas para usar arquivos de mídia com comandos para a API Gemini. Para informações sobre como usar a API Gemini Files para fazer upload de arquivos de mídia e incluí-los nos comandos, consulte os guias Vision, Áudio e Processamento de documentos.
Como usar arquivos de mídia com comandos
A capacidade de usar vários tipos de dados nos comandos oferece mais flexibilidade em termos de tarefas que podem ser realizadas com a API Gemini. Por exemplo, você pode enviar para o modelo uma foto de uma refeição deliciosa e pedir que ele escreva um blog curto sobre ela.
Comando Resposta
Escreva uma postagem curta e interessante para o blog com base nessa foto. A foto deve incluir uma descrição da refeição e falar sobre a preparação das refeições.

Preparar refeições é uma ótima maneira de economizar tempo e dinheiro, além de ajudar você a comer de forma mais saudável. Essa refeição é um ótimo exemplo de uma refeição saudável e deliciosa que pode ser preparada com facilidade com antecedência.
Esta refeição inclui arroz integral, legumes assados e frango teriyaki. O arroz integral é um carboidrato saudável e complexo que fornece energia por mais tempo. Os legumes assados são uma ótima maneira de consumir sua dose diária de vitaminas e minerais, e o frango teriyaki é uma opção deliciosa e rica em proteínas.
Esta refeição também é muito fácil de preparar. Basta cozinhar o arroz integral, assar os vegetais e cozinhar o frango teriyaki. Quando tudo estiver cozido, divida em recipientes de preparação de refeições e armazene na geladeira. Você pode pegar um contêiner e sair em manhãs agitadas.
Se você está procurando uma refeição saudável e deliciosa que possa ser facilmente preparada com antecedência, essa é uma ótima opção. Ele é cheio de nutrientes e sabor, e vai deixar você se sentindo satisfeito.
Que a preparação de refeições saudáveis e deliciosas seja um sucesso!
Estratégias para dar comandos com mídia
Se você está com problemas para receber a saída desejada de comandos que usam arquivos de mídia, há algumas estratégias que podem ajudar a conseguir os resultados que você quer. As seções a seguir oferecem abordagens de design e dicas de solução de problemas para melhorar comandos que usam entrada multimodal.
É possível melhorar os prompts multimodais seguindo estas práticas recomendadas:
Conceitos básicos do design de comandos
Seja específico nas instruções: crie instruções claras e concisas que deixem pouco espaço para interpretações equivocadas.
Adicione alguns exemplos ao comando: use exemplos realistas de few-shot para ilustrar o que você quer alcançar.
Detalhamento por etapas: divida tarefas complexas em submetas gerenciáveis para guiar o modelo pelo processo.
Especifique o formato de saída: no comando, peça que a saída esteja no formato desejado, como markdown, JSON, HTML e muito mais.
Coloque sua imagem em primeiro lugar nos comandos de imagem única: o Gemini processa entradas de imagem e texto em qualquer ordem, mas para comandos com uma única imagem, o desempenho pode ser melhor se a imagem for colocada antes do comando de texto.
Como solucionar problemas do comando multimodal
Se o modelo não estiver desenhando informações da parte relevante da imagem: solte dicas com os aspectos da imagem de que você quer que o comando extraia informações.
Se a saída do modelo for muito genérica (não personalizada o suficiente para a imagem) : no início do comando, peça para o modelo descrever as imagens antes de fornecer a instrução da tarefa ou peça ao modelo para consultar o conteúdo da imagem.
conceitos básicos do design de comandos
Esta seção expande as práticas recomendadas listadas na seção anterior.
Observação: os resultados do modelo dos exemplos do Gemini a seguir podem variar de acordo com a execução.
Especificar as instruções
As instruções têm mais sucesso quando são claras e detalhadas. Se você tiver uma saída específica em mente, é melhor incluir esse requisito no comando para garantir a saída desejada.
Às vezes, a intenção de um comando pode parecer clara para a pessoa que a escreveu, mas, na verdade, falta especificidades. Para personalizar o comportamento do modelo, analise como o comando pode ser interpretado (incorretamente) e verifique se as instruções fornecidas são claras e específicas. Deixe espaço mínimo para interpretações erradas
Para essa imagem de uma placa de aeroporto, pedir ao modelo apenas "descrever esta imagem" poderia gerar uma descrição geral. Se você precisa que o modelo analise a hora e a cidade a partir da imagem, inclua essa solicitação diretamente no comando.
Comando Resposta do modelo
Descreva esta imagem.
A imagem mostra um painel de chegadas e partidas do aeroporto.
Comando atualizado Resposta aprimorada
Analise a hora e a cidade no quadro do aeroporto mostrado nesta imagem em uma lista.
10:50 Moscow
11:05 Edimburgo
11:05 Londres
11:10 Bucareste
11:30 Kiev
11:35 Dublin
11:45 Midlands Orientais
12:15 Sófia
12:30 Londres
12:30 Newcastle
12:40 São Petersburgo
12:40 Londres
12:45 Manchester
Adicionar alguns exemplos
O modelo Gemini pode aceitar várias entradas que podem ser usadas como exemplos para entender a saída que você quer. Adicionar esses exemplos pode ajudar o modelo a identificar os padrões e aplicar a relação entre as imagens fornecidas e as respostas ao novo exemplo. Isso também é chamado de aprendizado "few-shot".
No exemplo abaixo, a saída inicial é escrita na forma de frase e também contém o país (Brasil). Suponha que você queira a saída em um formato ou estilo diferente e queira apenas a cidade, não o país. Adicionar alguns exemplos ao comando pode fazer com que o modelo responda da maneira desejada.
Comando Resposta do modelo
Determine a cidade junto com o ponto de referência.
O ponto turístico é a estátua do Cristo Redentor no Rio de Janeiro, Brasil.
Comando atualizado Resposta aprimorada
Determine a cidade junto com o ponto de referência.
cidade: Roma, ponto de referência: o Coliseu.
cidade: Pequim, ponto de referência: Cidade Proibida
cidade: Rio de Janeiro, ponto de referência: estátua do Cristo Redentor
Detalhar por passo
Para tarefas complexas, como as que exigem compreensão e raciocínio visual, pode ser útil dividir a tarefa em etapas menores e mais diretas. Também poderia ser eficaz se você pedisse diretamente ao modelo para “pensar passo a passo” no comando.
Comando Resposta do modelo
Quando vou ficar sem papel higiênico?
Em breve, você só tem mais três rolos.
Comando atualizado Resposta aprimorada
1. Primeiro, conte quantos rolos de papel higiênico há nessa imagem.
2. Em seguida, determine a quantidade de papel higiênico que uma pessoa usa por dia.
3. Calcule quanto tempo esses rolos de papel higiênico vão durar.
1. Há três rolos de papel higiênico nesta imagem.
2. Uma pessoa usa cerca de 20 folhas de papel higiênico por dia.
3. Se cada rolo tiver 200 páginas, cada um deles durará cerca de 10 dias. Portanto, os três rolos durarão cerca de um mês.
Problemas matemáticos ou outros tipos de problemas são ótimos candidatos para pedir que o modelo pense em etapas.
Comando Resposta
Qual é o quarto termo na sequência?
-135
A resposta do modelo está incorreta. Algumas maneiras de melhorar isso é pedir ao modelo que analise o problema antes de responder ao comando.
Comando Resposta
Analise a fórmula na imagem primeiro.
Depois, com base na fórmula, responda "qual é o quarto termo na sequência?".
Clique para abrir o resultado
A resposta do modelo está correta. Agora, para simplificar ainda mais, peça ao modelo que pense em etapas detalhadas.
Comando atualizado Resposta aprimorada
Qual é o quarto termo na sequência? Pense em etapas.
O primeiro termo é 15.
O segundo termo é b(1) * (-3) = 15 * (-3) = -45.
O terceiro termo é b(2) * (-3) = -45 * (-3) = 135.
O quarto termo é b(3) * (-3) = 135 * (-3) = -405.
Tente especificar o formato de saída
Um problema comum é a necessidade de a saída do modelo estar em um determinado formato (por exemplo, markdown, JSON, HTML), especialmente se ela precisar ser ingerida por uma tarefa downstream. Você pode tentar produzir saídas nesse formato instruindo o modelo a fazer isso no comando. Veja dois exemplos:
Comando Resposta do modelo
Analise a tabela nesta imagem no formato markdown
| Assunto | Status | Hora | Data de início | Prazo |
| ------- | ------ | ---- | --------- | ------ |
| Matemática | Concluído | 1h30 | 29/11/2023 | 01/12/2023 |
| Geografia | Concluído | 30 min | 02/12/2023 | 04/12/2023 |
| Física | Em andamento | 2h | 03/12/2023 | 05/12/2023 |
| Biologia | Não começou | 6 horas | 02/11/2016 | 06/12/2023 |
Comando Resposta do modelo
Forneça uma lista com todos os atributos a seguir:
Ingredientes, tipo de culinária, vegetariano ou não, no formato JSON
```json```
{
"ingredients": [
"rice",
"shrimp",
"clams",
"mussels",
"peas",
"tomatoes",
"onions",
"garlic",
"olive oil",
"paprika",
"salt",
"pepper"
],
"type of cuisine": "Spanish",
"vegetarian": false
Colocar a imagem em primeiro lugar nos comandos com uma imagem
O Gemini pode interpretar imagem e texto em qualquer ordem dentro de um comando, mas colocar uma única imagem antes do comando de texto pode levar a melhores resultados. Nos exemplos a seguir, você notará que a imagem vem antes do texto em cada comando.
Como resolver problemas do comando multimodal
Se você não receber uma resposta útil, talvez seja necessário resolver problemas do comando. Aqui estão algumas estratégias que você pode tentar.
Se o modelo não estiver desenhando informações da parte relevante da imagem
Para receber uma resposta mais específica, indique de quais aspectos da imagem você quer que a solicitação extraia informações para informar a resposta.
Comando Resposta do modelo
Quantos dias essas fraldas vão durar para um bebê?
As fraldas durarão 198 dias antes de acabarem.
Comando atualizado Resposta aprimorada
Quanto tempo essas fraldas vão durar?
Determine a idade da criança e o número total de fraldas na caixa com base no peso total.
Divida o total pelo número de fraldas usadas diariamente por uma criança.
A caixa contém 198 fraldas. Ela também informa que as fraldas são para crianças que pesam de 9 a 16 quilos.
Crianças nessa faixa de peso geralmente têm de 1 a 2 anos de idade.
Uma criança de dois anos costuma usar 6 fraldas por dia, logo, as fraldas vão durar cerca de 33 dias (198/6).
Se a saída do modelo for muito genérica e não for personalizada o suficiente para a entrada de imagem
Para ajudar o modelo a adaptar a resposta às imagens, peça para ele descrever as imagens antes de realizar a tarefa de raciocínio.
Comando Resposta do modelo
O que há em comum entre essas imagens?
As quatro imagens são exemplos de fotografia de paisagem.
Comando atualizado Resposta aprimorada
Primeiro, descreva o que está em cada imagem em detalhes. O que há em comum entre essas imagens?
A primeira imagem mostra uma pessoa fazendo as malas. A segunda imagem mostra um corredor vazio de um shopping. A terceira imagem mostra um rolo de papel higiênico. A quarta imagem mostra um mar escuro e tempestuoso.
O ponto em comum entre essas imagens é que todas são exemplos de espaços liminais. Espaços liminais são lugares ou situações que estão entre dois outros lugares ou situações. Elas costumam ser caracterizadas por um senso de incerteza ou ambiguidade.
A primeira imagem mostra a pessoa entre o momento em que está em casa e viajando. A segunda imagem mostra o corredor entre duas lojas. A terceira imagem é de papel higiênico, que pode representar um banheiro. Um banheiro é um espaço de transição entre domínios privados e públicos. É um lugar onde nos preparamos para entrar ou sair do mundo exterior.
A quarta imagem mostra o mar entre calmo e tempestuoso.
Espaços liminais podem ser empolgantes e perturbadores. Eles podem ser um lugar de recomeço ou de fim. Eles podem ser um local de reflexão ou ação.
Você também pode tentar pedir explicitamente ao modelo para se referir ao que está na imagem.
Comando atualizado Resposta aprimorada
O que há em comum entre essas imagens? Consulte o que está nas imagens na sua resposta.
Todas as imagens são relacionadas a viagens. A primeira imagem mostra uma pessoa fazendo as malas, a segunda mostra um corredor vazio de um shopping, a terceira imagem mostra uma pilha de papel higiênico e a quarta mostra um mar escuro e violento.
Todas essas imagens são relacionadas a viagens, porque são tudo o que as pessoas precisam ou usam quando viajam. A primeira imagem mostra uma pessoa fazendo as malas, que é algo que as pessoas fazem quando viajam. A segunda imagem mostra um corredor vazio de um shopping, que é um lugar onde as pessoas costumam comprar itens para viagens. A terceira imagem mostra uma pilha de papel higiênico, algo que as pessoas costumam usar quando estão viajando. A quarta imagem mostra um mar escuro e tempestuoso, algo que as pessoas encontram com frequência quando estão viajando.
As mesmas dicas funcionam para resultados criativos de imagens. No exemplo a seguir com o coelho, pedir explicitamente ao modelo para incluir aspectos da imagem pode melhorar a saída.
Comando Resposta do modelo
Você pode me escrever um poema sobre esta imagem?
Coelhinho peludo e marrom
Pulando pelo campo, para cima e para baixo.
Suas orelhas são tão longas e sua cauda tão pequena!
Você é a criatura mais fofa de todas.
Você morde a grama, tão verde e doce,
E pula quando me vê.
Mas sempre serei seu amigo,
Coelhinho, até o fim.
Comando atualizado Resposta aprimorada
Você pode escrever um poema descritivo e dramático sobre esta imagem e incluir o local?
Coelhinho no verde
Orelhas tão compridas e pontudas.
O que você vê lá fora,
À distância, onde você olha?
É o oceano azul,
Brilhando na tonalidade do sol?
Ou as ondas que quebram e rugem,
Um ritmo que você adora?
Coelhinho, fale a verdade:
O que chama sua atenção de verdade?
É a brisa salgada,
Ou o choro das gaivotas te agrada?
Talvez seja a vastidão de tudo isso,
Um mundo tão grande e pequeno.
Um lugar onde os sonhos podem andar,
e aventuras podem ser livres.
Coelhinho me pergunto o que você sonha,
Sentado na grama, tão sereno.
Você quer explorar as profundezas
Ou ficar na terra para dar um salto?
Seja o que for, coelhinho!
Deixe a faísca da maravilha brilhar.
Nos seus sonhos e aspirações,
há um mundo esperando sua criação.
Solução de problemas em qual parte do prompt falhou
Pode ser difícil saber se uma solicitação falhou porque o modelo não entendeu a imagem ou se ele entendeu a imagem, mas não executou as etapas de raciocínio corretas.
Para diferenciar esses motivos, peça ao modelo que descreva o que está na imagem.
No exemplo abaixo, se o modelo responder com um lanche que parece diferente quando combinado com chá (como pipoca), primeiro é possível resolver problemas para determinar se o modelo reconheceu corretamente que a imagem contém chá.
Comando Prompt de solução de problemas
Que lanchinho eu posso fazer em 1 minuto e que combina com este?
Descreva o que há na imagem.
Outra estratégia é pedir para o modelo explicar o raciocínio dele. Isso pode ajudar você a filtrar qual parte do raciocínio está incorreta, se houver.
Comando Prompt de solução de problemas
Que lanchinho eu posso fazer em 1 minuto e que combina com este?
Que lanchinho eu posso fazer em 1 minuto e que combina com este? Explique o motivo.
Ajustar os parâmetros de amostragem
Em cada comando, você envia ao modelo não apenas o comando multimodal, mas um conjunto de parâmetros de amostragem. O modelo pode gerar diferentes resultados para diferentes valores de parâmetros. Teste os diferentes parâmetros para conseguir os melhores valores para a tarefa. Os parâmetros mais comumente ajustados são os seguintes:
Temperatura
top-P
top-K
Temperatura
A temperatura é usada para amostragem durante a geração de resposta, que ocorre quando Top-P e Top-K são aplicados. A temperatura controla o grau de aleatoriedade na seleção do token. Temperaturas mais baixas são boas para comandos que exigem uma resposta mais determinista e menos aberta ou criativa, enquanto temperaturas maiores podem levar a resultados mais diversos ou criativos. Uma temperatura 0 é determinista, o que significa que a resposta de maior probabilidade é sempre selecionada.
Na maioria dos casos de uso, é melhor começar com a temperatura 0,4. Se você precisar de resultados mais criativos, tente aumentar a temperatura. Se você observar alucinações claras, tente reduzir a temperatura.
Top-K
O Top-K muda a forma como o modelo seleciona tokens para saída. O valor "1" de Top-K indica que o token selecionado é o mais provável entre todos no vocabulário do modelo (também chamado de decodificação gananciosa), enquanto o valor "3" de Top-K significa que o próximo token é selecionado entre os três mais prováveis usando a temperatura.
Para cada etapa da seleção de tokens, são amostrados os tokens Top-K com as maiores probabilidades. Em seguida, os tokens são filtrados com base no valor de Top-P com o token final selecionado por meio da amostragem de temperatura.
Especifique um valor mais baixo para respostas menos aleatórias e um valor mais alto para respostas mais aleatórias. O valor padrão do top-K é 32.
Top-P
O Top-P muda a forma como o modelo seleciona tokens para saída. Os tokens são selecionados do mais provável (confira o Top-K) para o menos provável até que a soma das probabilidades seja igual ao valor do Top-P. Por exemplo, se os tokens A, B e C tiverem uma probabilidade de 0,6, 0,3 e 0,1 e o valor de Top-P for 0,9, o modelo selecionará A ou B como token seguinte usando temperatura e excluirá C como candidato.
Especifique um valor mais baixo para respostas menos aleatórias e um valor mais alto para respostas mais aleatórias. O valor padrão do top-P é 1,0.
Próximas etapas
Tente escrever seus próprios comandos multimodais usando o Google AI Studio.
Para mais orientações sobre o design de comandos, consulte a página Estratégias de comandos.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_45.txt ---

URL: https://ai.google.dev/gemini-api/docs/imagen-prompt-guide

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Introdução aos comandos
Estratégias de comando
Estratégias de solicitação de arquivos
Guia de comandos do Imagen
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Guia de comandos do Imagen
Nesta página
Noções básicas de redação imediatas (assunto, contexto e estilo)
Gravação de comandos da Imagen 3
Gerar texto em imagens
Parametrização do comando
Estilo: fotografia
Estilo: ilustração e arte
Técnicas avançadas para a criação de prompts
Modificadores de fotografia
Para usar o Imagen, é necessário fornecer uma descrição em texto do que você quer gerar. Essas descrições são chamadas de solicitações, e elas são a maneira principal de se comunicar com o Imagen.
Neste guia, mostramos como modificar partes de um comando de texto para imagem pode produzir resultados diferentes e oferecemos exemplos de imagens que podem ser criadas.
Noções básicas de redação imediatas (assunto, contexto e estilo)
Observação: o comprimento máximo do comando é de 480 tokens.
Embora haja muitas maneiras de escrever uma boa solicitação, adicionar algumas palavras-chave e modificadores ajudará você a se aproximar da meta final. Os prompts não precisam ser longos ou complexos, mas a maioria deles é descritiva e clara.
Um bom ponto de partida pode ser pensar em assunto, contexto e estilo.
Texto da imagem: um esboço (estilo) de um prédio moderno (assunto) cercado por arranha-céus (contexto e plano de fundo).
Assunto: a primeira coisa a considerar com qualquer solicitação é o assunto: o objeto, a pessoa, o animal ou o cenário de que você quer uma imagem.
Contexto e plano de fundo: o mais importante é o plano de fundo ou o contexto em que o assunto será colocado. Tente colocar o objeto de várias formas. Por exemplo, um estúdio com fundo branco, ambientes externos ou ambientes internos.
Estilo: por fim, adicione o estilo da imagem que você quer usar. Os estilos podem ser gerais (pintura, fotografia, esboços) ou muito específicos (pintura pastel, desenho a carvão, isométrico 3D). Também é possível combinar estilos.
Depois de escrever uma primeira versão da proposta, aprimore-a adicionando mais detalhes até chegar à imagem que você quer. A iteração é importante. Comece estabelecendo sua ideia principal e, em seguida, refine e expanda essa ideia até que a imagem gerada esteja próxima da sua visão.
Prompt: Um parque na primavera ao lado de um lago
Instrução: um parque na primavera ao lado de um lago, o sol se põe no lago, golden hour
Instrução: um parque na primavera ao lado de um lago, o sol se põe no lago, golden hour, flores silvestres vermelhas
Gravação de comandos da Imagen 3
A Imagen 3 pode transformar suas ideias em imagens detalhadas, sejam comandos curtos ou longos e detalhados. Aprimore sua visão com instruções iterativas, adicionando detalhes até alcançar o resultado perfeito.
Com comandos curtos, você gera uma imagem rapidamente.
Instrução: foto de uma mulher de 20 e poucos anos, fotografia de rua, imagem estática de um filme, tons quentes de laranja suave
Com comandos mais longos, você pode adicionar detalhes específicos e criar sua imagem.
Instrução: foto cativante de uma mulher na faixa dos 20 anos usando um estilo de fotografia de rua. A imagem precisa parecer um filme com tons quentes de laranja esmaecido.
Outros conselhos para escrever o comando da Imagen 3:
Use uma linguagem descritiva: use adjetivos e advérbios detalhados para descrever claramente a Imagem 3.
Forneça contexto: se necessário, inclua informações de contexto para ajudar a IA a entender.
Cite artistas ou estilos específicos: se você tem uma estética específica em mente, citar artistas ou movimentos artísticos específicos pode ser útil.
Usar ferramentas de engenharia de comando: considere explorar ferramentas ou recursos de engenharia de comando para refinar seus comandos e alcançar resultados ideais.
Como melhorar os detalhes faciais nas suas imagens pessoais e em grupo:
Especifique detalhes faciais como foco da foto. Por exemplo, use a palavra "retrato" no comando.
Gerar texto em imagens
A capacidade do Imagen 3 de adicionar texto às imagens abre possibilidades criativas de geração de imagens. Use as orientações a seguir para aproveitar ao máximo esse recurso:
Iterar com confiança: talvez seja necessário regenerar imagens até alcançar o visual desejado. A integração de texto do Imagen ainda está evoluindo, e às vezes várias tentativas produzem os melhores resultados.
Mantenha o texto curto: limite o texto a 25 caracteres ou menos para uma geração ótima.
Várias frases: teste duas ou três frases diferentes para fornecer mais informações. Evite exceder três frases para composições mais limpas.
Instrução: um cartaz com o texto "Summerland" em negrito como título, abaixo do texto está o slogan "Summer never felt so good"
Posicionamento do guia: embora o Imagen possa tentar posicionar o texto conforme indicado, é possível que haja variações ocasionais. Esse recurso está sendo aprimorado constantemente.
Inspire font style: especifique um estilo de fonte geral para influenciar sutilmente as escolhas do Imagen. Não confie na replicação precisa de fontes, mas espere interpretações criativas.
Tamanho da fonte: especifique um tamanho de fonte ou uma indicação geral de tamanho (por exemplo, pequeno, médio, grande) para influenciar a geração do tamanho da fonte.
Parametrização do comando
Para controlar melhor os resultados de saída, pode ser útil parametrizar as entradas no Imagen. Por exemplo, suponha que você queira que os clientes possam gerar logotipos para a empresa e que eles sejam sempre gerados em um plano de fundo de cor sólida. Você também quer limitar as opções que o cliente pode selecionar em um menu.
Neste exemplo, você pode criar uma solicitação parametrizada semelhante a esta:
A {logo_style} logo for a {company_area} company on a solid color background. Include the text {company_name}.
Na interface do usuário personalizada, o cliente pode inserir os parâmetros usando um menu, e o valor escolhido preenche o comando que o Imagen recebe.
Exemplo:
Comando: A minimalist logo for a health care company on a solid color background. Include the text Journey.
Comando: A modern logo for a software company on a solid color background. Include the text Silo.
Comando: A traditional logo for a baking company on a solid color background. Include the text Seed.
Estilo: fotografia
A solicitação inclui: "Uma foto de..."
Para usar esse estilo, comece usando palavras-chave que informem claramente ao Imagen que você está procurando uma fotografia. Inicie suas solicitações com "Uma foto de . ". Por exemplo:
Prompt: uma foto de grãos de café em uma cozinha em uma superfície de madeira
Prompt: uma foto de uma barra de chocolate em um balcão de cozinha
Prompt: uma foto de um edifício moderno com água em segundo plano
Fonte da imagem: cada imagem foi gerada usando o comando de texto correspondente com o modelo Imagen 3.
Estilo: ilustração e arte
A solicitação inclui: "A painting de...", "Um sketch de..."
Os estilos de arte variam de estilos monocromáticos como esboços a lápis à arte digital realista. Por exemplo, as imagens a seguir usam a mesma solicitação com estilos diferentes:
"Um [art style or creation technique] de um sedan elétrico esportivo angular com arranha-céus em segundo plano"
Prompt: um desenho técnico de lápis de um angular...
Prompt: um desenho de carvão de um angular...
Prompt: um desenho de lápis de cor de um angular...
Instrução: uma pintura pastel de um angular...
Prompt: uma arte digital de um angular...
Prompt: um art déco (pôster) de um angular...
Fonte da imagem: cada imagem foi gerada usando o comando de texto correspondente com o modelo Imagen 2.
Técnicas avançadas para a criação de prompts
Use os exemplos a seguir para criar solicitações mais específicas com base nos atributos: descritores de foto, formas e materiais, movimentos de arte históricos e modificadores de qualidade de imagem.
Modificadores de fotografia
Nos exemplos a seguir, você pode conferir vários modificadores e parâmetros específicos para fotografia. É possível combinar vários modificadores para ter um controle mais preciso.
Proximidade da câmera - Close-up, tirada de longe
Solicitação: uma foto de perto de grãos de café
Prompt: uma foto com zoom desativado de um pequeno saco de
grãos de café em uma cozinha bagunçada
Posição da câmera: aéreo, vista de baixo
Instrução: foto aérea de uma cidade com arranha-céus
Solicitação: uma foto de um dossel florestal com céu azul abaixo
Iluminação: natural, dramático, calor, frio
Prompt: foto de estúdio de uma cadeira moderna, iluminação natural
Prompt: foto de estúdio de uma cadeira moderna, iluminação dramática
Configurações da câmera — desfoque de movimento, foco suave, bokeh, retrato
Prompt: foto de uma cidade com arranha-céus dentro de um carro com desfoque de movimento
Prompt: foco suave na fotografia de uma ponte em uma cidade urbana à noite
Tipos de lentes - 35 mm, 50 mm, olho de peixe, grande angular, macro
Prompt: foto de uma folha, lente macro
Instrução: fotografia de rua, cidade de Nova York, lente olho de peixe
Tipos de filme - preto e branco, polaroid
Instrução: um retrato polaroide de um cachorro usando óculos escuros
Instrução: foto em preto e branco de um cachorro usando óculos escuros
Fonte da imagem: cada imagem foi gerada usando o comando de texto correspondente com o modelo Imagen 3.
Formas e materiais
A solicitação inclui: "...made of...", "...na forma de..."
Um dos pontos fortes dessa tecnologia é a possibilidade de criar imagens que seriam difíceis ou impossíveis. Por exemplo, é possível recriar o logotipo da empresa em diferentes materiais e texturas.
Prompt: um saco de mochila feito de queijo
Instrução: tubos de neon no formato de um pássaro
Solicitação: uma poltrona feita de papel, foto de estúdio, estilo origami
Fonte da imagem: cada imagem foi gerada usando o comando de texto correspondente com o modelo Imagen 3.
Referências de arte históricas
A solicitação inclui: "...in the style of..."
Alguns estilos se tornaram icônicos ao longo dos anos. Confira a seguir algumas ideias de pintura histórica ou estilos de arte que você pode testar.
"gerar uma imagem no estilo de [art period or movement] : um parque eólico"
Instrução: gere uma imagem no estilo de uma pintura impressionista: um parque eólico
Instrução: gerar uma imagem no estilo de uma pintura renascentista: um parque eólico
Solicitação: gere uma imagem no estilo de pop art: um parque eólico
Fonte da imagem: cada imagem foi gerada usando o comando de texto correspondente com o modelo Imagen 3.
Modificadores de qualidade da imagem
Algumas palavras-chave podem informar ao modelo que você está procurando um recurso de alta qualidade. Veja alguns exemplos de modificadores de qualidade:
Modificadores gerais: alta qualidade, bonito, estilizado
Fotos: fotos 4K, HDR e do Studio
Arte, Ilustração: por um profissional, detalhado
Veja a seguir alguns exemplos de prompts sem modificadores de qualidade e o mesmo com modificadores de qualidade.
Solicitação (sem modificadores de qualidade): uma foto de um talo de milho
Instrução (com modificadores de qualidade): linda foto
de 4K HDR de um talo de milho tirada por um fotógrafo
profissional
Fonte da imagem: cada imagem foi gerada usando o comando de texto correspondente com o modelo Imagen 3.
Proporções
A geração de imagens do Imagen 3 permite definir cinco proporções de imagem distintas.
Quadrado (1:1, padrão): uma foto quadrada padrão. Usos comuns para essa proporção incluem postagens de mídias sociais.
Tela cheia (4:3): essa proporção é usada com frequência em mídias ou filmes. Elas também têm as mesmas dimensões da maioria das TVs e câmeras de formato médio antigas. Ela captura mais da cena horizontalmente (em comparação com 1:1), o que a torna uma proporção preferencial para fotografia.
Instrução: close dos dedos de um músico tocando piano, filme em preto e branco, vintage (proporção de 4:3)
Instrução: uma foto profissional de um estúdio que mostra batatas fritas para um restaurante sofisticado, no estilo de uma revista de culinária (proporção de 4:3) )
Tela cheia em modo retrato (3:4): é a proporção de tela cheia girada em 90 graus. Isso permite capturar mais da cena verticalmente em comparação com a proporção de 1:1.
Instrução: uma mulher caminhando, perto de suas botas refletidas em uma poça, grandes montanhas ao fundo, no estilo de um anúncio, ângulos dramáticos (proporção 3:4)
Instrução: imagem aérea de um rio fluindo por um vale místico (proporção 3:4)
Widescreen (16:9): essa proporção substituiu a de 4:3 e agora é a proporção mais comum para TVs, monitores e telas de smartphones (paisagem). Use essa proporção quando quiser capturar mais do plano de fundo (por exemplo, paisagens panorâmicas).
Instrução: um homem vestindo roupas brancas sentado na praia, de perto, com iluminação de golden hour (proporção de 16:9){101
Retrato (9:16): essa proporção é widescreen, mas girada. Essa é uma proporção relativamente nova que ficou conhecida por apps de vídeos mais curtos (por exemplo, YouTube Shorts). Use essa opção para objetos altos com fortes orientações verticais, como edifícios, árvores, cachoeiras ou outros objetos semelhantes.
Prompt: uma renderização digital de um arranha-céu enorme, moderno, grandioso, épico com um lindo pôr do sol ao fundo (proporção de 9:16){101
Imagens fotorrealistas
Diferentes versões do modelo de geração de imagens podem oferecer uma mistura de saídas artísticas e realistas. Use a seguinte palavra nos comandos para gerar uma saída mais fotorrealista com base no assunto que quiser gerar.
Observação: considere essas palavras-chave como orientação geral ao tentar criar imagens fotorrealistas. Elas não são necessárias para atingir sua meta.
Caso de uso Tipo de lente Distâncias focais Mais detalhes
Pessoas (retratos) Prime, zoom 24-35mm filme em preto e branco, Filme noir, Profundidade de campo, duotone (mencione duas cores)
Comida, insetos, plantas (objetos, natureza morta) Macro 60-105mm Alto nível de detalhes, foco preciso, iluminação controlada
Esportes, vida selvagem (movimento) Zoom telefoto 100-400mm Velocidade rápida do obturador, rastreamento de ação ou movimento
Astronômico, paisagem (amplo angular) Grande angular 10-24mm Longos tempos de exposição, foco nítido, exposição longa, água suave ou nuvens
Retratos
Caso de uso Tipo de lente Distâncias focais Mais detalhes
Pessoas (retratos) Prime, zoom 24-35mm filme em preto e branco, Filme noir, Profundidade de campo, duotone (mencione duas cores)
Usando várias palavras-chave da tabela, o Imagen pode gerar os retratos a seguir.
Comando: uma mulher, retrato de 35 mm, duotons azul e cinza
Modelo: imagen-3.0-generate-002
Comando: A mulher, retrato de 35 mm, film noir
Modelo: imagen-3.0-generate-002
Objetos
Caso de uso Tipo de lente Distâncias focais Mais detalhes
Comida, insetos, plantas (objetos, natureza morta) Macro 60-105mm Alto nível de detalhes, foco preciso, iluminação controlada
Usando várias palavras-chave da tabela, o Imagen pode gerar as seguintes imagens de objeto.
Comando: folha de uma planta de oração, lente macro, 60 mm
Modelo: imagen-3.0-generate-002
Comando: um prato de macarrão, lente macro de 100 mm
Modelo: imagen-3.0-generate-002
Movimento
Caso de uso Tipo de lente Distâncias focais Mais detalhes
Esportes, vida selvagem (movimento) Zoom telefoto 100-400mm Velocidade rápida do obturador, rastreamento de ação ou movimento
Usando várias palavras-chave da tabela, o Imagen pode gerar as seguintes imagens em movimento.
Comando: um touchdown vencedor, velocidade do obturador rápida e rastreamento de movimento
Modelo: imagen-3.0-generate-002
Comando: um cervo correndo na floresta, alta velocidade do obturador, rastreamento de movimento
Modelo: imagen-3.0-generate-002
Grande angular
Caso de uso Tipo de lente Distâncias focais Mais detalhes
Astronômico, paisagem (amplo angular) Grande angular 10-24mm Longos tempos de exposição, foco nítido, exposição longa, água suave ou nuvens
Usando várias palavras-chave da tabela, o Imagen pode gerar as seguintes imagens grande angulares.
Comando: uma ampla cordilheira, ângulo amplo de paisagem de 10 mm
Modelo: imagen-3.0-generate-002
Comando: uma foto da lua, fotografia astronômica, ângulo amplo de 10 mm
Modelo: imagen-3.0-generate-002
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-01-21 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_46.txt ---

URL: https://ai.google.dev/gemini-api/docs/tokens

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Entender e contar tokens
Nesta página
Sobre os tokens
Testar a contagem de tokens em um Colab
Janelas de contexto
Contar Tokens
Contar tokens de texto
Contagem de tokens de multiturno (chat)
Contar tokens multimodais
Instruções e ferramentas do sistema
Python
JavaScript
Go

O Gemini e outros modelos de IA generativa processam a entrada e a saída com uma granularidade chamada token.
Sobre os tokens
Os tokens podem ser caracteres únicos, como z, ou palavras inteiras, como cat. Palavras longas são divididas em vários tokens. O conjunto de todos os tokens usados pelo modelo é chamado de vocabulário, e o processo de dividir o texto em tokens é chamado de tokenização.
Para modelos do Gemini, um token equivale a cerca de quatro caracteres. 100 tokens equivalem a cerca de 60 a 80 palavras em inglês.
Quando o faturamento está ativado, o custo de uma chamada para a API Gemini é determinado em parte pelo número de tokens de entrada e saída. Portanto, saber como contar tokens pode ser útil.
Testar a contagem de tokens em um Colab
Você pode tentar contar tokens usando um Colab.
Testar um notebook do Colab
Acessar o notebook no GitHub
Janelas de contexto
Os modelos disponíveis na API Gemini têm janelas de contexto que são medidas em tokens. A janela de contexto define quanta entrada você pode fornecer e quanta saída o modelo pode gerar. É possível determinar o tamanho da janela de contexto chamando o endpoint getModels ou confira a documentação de modelos.
No exemplo abaixo, o modelo gemini-1.5-flash tem um limite de entrada de cerca de 1.000.000 tokens e um limite de saída de cerca de 8.000 tokens, o que significa que uma janela de contexto é de 1.000.000 tokens.
import google.generativeai as genai

model_info = genai.get_model("models/gemini-1.5-flash")

# Returns the "context window" for the model,
# which is the combined input and output token limits.
print(f"{model_info.input_token_limit=}")
print(f"{model_info.output_token_limit=}")
# ( input_token_limit=30720, output_token_limit=2048 )
count_tokens.py
Contar Tokens
Todas as entradas e saídas da API Gemini são tokenizadas, incluindo texto, arquivos de imagem e outras modalidades que não são de texto.
É possível contar tokens das seguintes maneiras:
Chame count_tokens com a entrada da solicitação.
Retorna o número total de tokens na entrada somente. Você pode fazer essa chamada antes de enviar a entrada para o modelo para verificar o tamanho das solicitações.
Use o atributo usage_metadata no objeto response depois de chamar generate_content.
Isso retorna o número total de tokens na entrada e na saída: total_token_count.
Ele também retorna as contagens de tokens de entrada e saída separadamente: prompt_token_count (tokens de entrada) e candidates_token_count (tokens de saída).
Contar tokens de texto
Se você chamar count_tokens com uma entrada somente de texto, ela retornará a contagem de tokens do texto em somente a entrada (total_tokens). É possível fazer essa chamada antes de chamar generate_content para verificar o tamanho das suas solicitações.
Outra opção é chamar generate_content e usar o atributo usage_metadata no objeto response para receber o seguinte:
As contagens de tokens separadas da entrada (prompt_token_count) e da saída (candidates_token_count)
O número total de tokens na entrada e na saída (total_token_count).
import google.generativeai as genai

model = genai.GenerativeModel("models/gemini-1.5-flash")

prompt = "The quick brown fox jumps over the lazy dog."

# Call `count_tokens` to get the input token count (`total_tokens`).
print("total_tokens: ", model.count_tokens(prompt))
# ( total_tokens: 10 )

response = model.generate_content(prompt)

# On the response for `generate_content`, use `usage_metadata`
# to get separate input and output token counts
# (`prompt_token_count` and `candidates_token_count`, respectively),
# as well as the combined token count (`total_token_count`).
print(response.usage_metadata)
# ( prompt_token_count: 11, candidates_token_count: 73, total_token_count: 84 )
count_tokens.py
Contagem de tokens de multiturno (chat)
Se você chamar count_tokens com o histórico de chat, ele vai retornar a contagem total de tokens do texto de cada função no chat (total_tokens).
Outra opção é chamar send_message e usar o atributo usage_metadata no objeto response para receber o seguinte:
As contagens de tokens separadas da entrada (prompt_token_count) e da saída (candidates_token_count)
O número total de tokens na entrada e na saída (total_token_count)
Para entender o tamanho da sua próxima vez de conversa, você precisa adicioná-la ao histórico quando chamar count_tokens.
import google.generativeai as genai

model = genai.GenerativeModel("models/gemini-1.5-flash")

chat = model.start_chat(
    history=[
        {"role": "user", "parts": "Hi my name is Bob"},
        {"role": "model", "parts": "Hi Bob!"},
    ]
)
# Call `count_tokens` to get the input token count (`total_tokens`).
print(model.count_tokens(chat.history))
# ( total_tokens: 10 )

response = chat.send_message(
    "In one sentence, explain how a computer works to a young child."
)

# On the response for `send_message`, use `usage_metadata`
# to get separate input and output token counts
# (`prompt_token_count` and `candidates_token_count`, respectively),
# as well as the combined token count (`total_token_count`).
print(response.usage_metadata)
# ( prompt_token_count: 25, candidates_token_count: 21, total_token_count: 46 )

from google.generativeai.types.content_types import to_contents

# You can call `count_tokens` on the combined history and content of the next turn.
print(model.count_tokens(chat.history + to_contents("What is the meaning of life?")))
# ( total_tokens: 56 )
count_tokens.py
Contar tokens multimodais
Todas as entradas na API Gemini são tokenizadas, incluindo texto, arquivos de imagem e outras modalidades não textuais. Confira os seguintes pontos-chave de alto nível sobre a tokenização de entrada multimodal durante o processamento pela API Gemini:
Com o Gemini 2.0, as entradas de imagem com as duas dimensões <=384 pixels são contadas como 258 tokens. As imagens maiores em uma ou ambas as dimensões são cortadas e redimensionadas conforme necessário em blocos de 768 x 768 pixels, cada um contado como 258 tokens. Antes do Gemini 2.0, as imagens usavam 258 tokens fixos.
Os arquivos de vídeo e áudio são convertidos em tokens nas seguintes taxas fixas: vídeo a 263 tokens por segundo e áudio a 32 tokens por segundo.
Arquivos de imagem
Se você chamar count_tokens com uma entrada de texto e imagem, ela retornará a contagem de tokens combinada do texto e da imagem na entrada apenas (total_tokens). Você pode fazer essa chamada antes de chamar generate_content para verificar o tamanho das solicitações. Também é possível chamar count_tokens no texto e no arquivo separadamente.
Outra opção é chamar generate_content e usar o atributo usage_metadata no objeto response para receber o seguinte:
As contagens de tokens separadas da entrada (prompt_token_count) e da saída (candidates_token_count)
O número total de tokens na entrada e na saída (total_token_count)
Observação: você vai receber a mesma contagem de tokens se usar um arquivo enviado com a API File ou fornecer o arquivo como dados inline.
Exemplo que usa uma imagem enviada pela API File:
import google.generativeai as genai

model = genai.GenerativeModel("models/gemini-1.5-flash")

prompt = "Tell me about this image"
your_image_file = genai.upload_file(path=media / "organ.jpg")

# Call `count_tokens` to get the input token count
# of the combined text and file (`total_tokens`).
# An image's display or file size does not affect its token count.
# Optionally, you can call `count_tokens` for the text and file separately.
print(model.count_tokens([prompt, your_image_file]))
# ( total_tokens: 263 )

response = model.generate_content([prompt, your_image_file])
response.text
# On the response for `generate_content`, use `usage_metadata`
# to get separate input and output token counts
# (`prompt_token_count` and `candidates_token_count`, respectively),
# as well as the combined token count (`total_token_count`).
print(response.usage_metadata)
# ( prompt_token_count: 264, candidates_token_count: 80, total_token_count: 345 )
count_tokens.py
Exemplo que fornece a imagem como dados inline:
import google.generativeai as genai

import PIL.Image

model = genai.GenerativeModel("models/gemini-1.5-flash")

prompt = "Tell me about this image"
your_image_file = PIL.Image.open(media / "organ.jpg")

# Call `count_tokens` to get the input token count
# of the combined text and file (`total_tokens`).
# An image's display or file size does not affect its token count.
# Optionally, you can call `count_tokens` for the text and file separately.
print(model.count_tokens([prompt, your_image_file]))
# ( total_tokens: 263 )

response = model.generate_content([prompt, your_image_file])

# On the response for `generate_content`, use `usage_metadata`
# to get separate input and output token counts
# (`prompt_token_count` and `candidates_token_count`, respectively),
# as well as the combined token count (`total_token_count`).
print(response.usage_metadata)
# ( prompt_token_count: 264, candidates_token_count: 80, total_token_count: 345 )
count_tokens.py
Arquivos de áudio ou vídeo
O áudio e o vídeo são convertidos em tokens com as seguintes taxas fixas:
Vídeo: 263 tokens por segundo
Áudio: 32 tokens por segundo
Se você chamar count_tokens com uma entrada de texto e vídeo/áudio, ela retornará a contagem de tokens combinada do texto e do arquivo de vídeo/áudio apenas na entrada (total_tokens). É possível fazer essa chamada antes de chamar generate_content para verificar o tamanho das suas solicitações. Também é possível chamar count_tokens no texto e no arquivo separadamente.
Outra opção é chamar generate_content e usar o atributo usage_metadata no objeto response para receber o seguinte:
As contagens de tokens separadas da entrada (prompt_token_count) e da saída (candidates_token_count)
O número total de tokens na entrada e na saída (total_token_count)
Observação: você vai receber a mesma contagem de tokens se usar um arquivo enviado com a API File ou fornecer o arquivo como dados inline.
import google.generativeai as genai

import time

model = genai.GenerativeModel("models/gemini-1.5-flash")

prompt = "Tell me about this video"
your_file = genai.upload_file(path=media / "Big_Buck_Bunny.mp4")

# Videos need to be processed before you can use them.
while your_file.state.name == "PROCESSING":
    print("processing video...")
    time.sleep(5)
    your_file = genai.get_file(your_file.name)

# Call `count_tokens` to get the input token count
# of the combined text and video/audio file (`total_tokens`).
# A video or audio file is converted to tokens at a fixed rate of tokens per second.
# Optionally, you can call `count_tokens` for the text and file separately.
print(model.count_tokens([prompt, your_file]))
# ( total_tokens: 300 )

response = model.generate_content([prompt, your_file])

# On the response for `generate_content`, use `usage_metadata`
# to get separate input and output token counts
# (`prompt_token_count` and `candidates_token_count`, respectively),
# as well as the combined token count (`total_token_count`).
print(response.usage_metadata)
# ( prompt_token_count: 301, candidates_token_count: 60, total_token_count: 361 )
count_tokens.py
Instruções e ferramentas do sistema
As instruções e ferramentas do sistema também são contabilizadas na contagem total de tokens da entrada.
Se você usar instruções do sistema, a contagem de total_tokens vai aumentar para refletir a adição de system_instruction.
import google.generativeai as genai

model = genai.GenerativeModel(model_name="gemini-1.5-flash")

prompt = "The quick brown fox jumps over the lazy dog."

print(model.count_tokens(prompt))
# total_tokens: 10

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash", system_instruction="You are a cat. Your name is Neko."
)

# The total token count includes everything sent to the `generate_content` request.
# When you use system instructions, the total token count increases.
print(model.count_tokens(prompt))
# ( total_tokens: 21 )
count_tokens.py
Se você usar a chamada de função, a contagem de total_tokens vai aumentar para refletir a adição de tools.
import google.generativeai as genai

model = genai.GenerativeModel(model_name="gemini-1.5-flash")

prompt = "I have 57 cats, each owns 44 mittens, how many mittens is that in total?"

print(model.count_tokens(prompt))
# ( total_tokens: 22 )

def add(a: float, b: float):
    """returns a + b."""
    return a + b

def subtract(a: float, b: float):
    """returns a - b."""
    return a - b

def multiply(a: float, b: float):
    """returns a * b."""
    return a * b

def divide(a: float, b: float):
    """returns a / b."""
    return a / b

model = genai.GenerativeModel(
    "models/gemini-1.5-flash-001", tools=[add, subtract, multiply, divide]
)

# The total token count includes everything sent to the `generate_content` request.
# When you use tools (like function calling), the total token count increases.
print(model.count_tokens(prompt))
# ( total_tokens: 206 )
count_tokens.py
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-08 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_47.txt ---

URL: https://ai.google.dev/gemini-api/docs/safety-settings

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Configurações de segurança
Orientações de segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Configurações de segurança
Nesta página
Filtros de segurança
Nível de filtragem de segurança do conteúdo
Filtragem de segurança por solicitação
Feedback de segurança
Ajustar as configurações de segurança
Google AI Studio
SDKs da API Gemini
Próximas etapas
A API Gemini oferece configurações de segurança que podem ser ajustadas durante o estágio de prototipagem para determinar se o aplicativo requer uma configuração de segurança mais ou menos restritiva. É possível ajustar essas configurações em quatro categorias de filtro para restringir ou permitir determinados tipos de conteúdo.
Este guia explica como a API Gemini lida com as configurações de segurança e a filtragem e como você pode mudar as configurações de segurança do seu aplicativo.
Observação: os aplicativos que usam configurações de segurança menos restritivas podem estar sujeitos a revisão. Consulte os Termos de Serviço para mais informações.
Filtros de segurança
Os filtros de segurança ajustáveis da API Gemini abrangem as seguintes categorias:
Categoria Descrição
Assédio Comentários negativos ou nocivos voltados à identidade e/ou atributos protegidos.
Discurso de ódio Conteúdo grosseiro, desrespeitoso ou linguagem obscena.
Sexualmente explícito Contém referências a atos sexuais ou outro conteúdo sexual.
Perigoso Promove, facilita ou incentiva atos nocivos.
Integridade cívica Consultas relacionadas a eleições.
Essas categorias são definidas em HarmCategory. Os modelos Gemini só oferecem suporte a HARM_CATEGORY_HARASSMENT, HARM_CATEGORY_HATE_SPEECH, HARM_CATEGORY_SEXUALLY_EXPLICIT, HARM_CATEGORY_DANGEROUS_CONTENT e HARM_CATEGORY_CIVIC_INTEGRITY. Todas as outras categorias são usadas apenas por modelos do PaLM 2 (legado).
Você pode usar esses filtros para ajustar o que for apropriado para seu caso de uso. Por exemplo, se você estiver criando diálogos de videogame, pode considerar aceitável permitir mais conteúdo classificado como Perigoso devido à natureza do jogo.
Além dos filtros de segurança ajustáveis, a API Gemini tem proteções integradas contra danos principais, como conteúdo que coloca crianças em risco. Esses tipos de danos são sempre bloqueados e não podem ser ajustados.
Nível de filtragem de segurança do conteúdo
A API Gemini categoriza o nível de probabilidade de o conteúdo ser não seguro como HIGH, MEDIUM, LOW ou NEGLIGIBLE.
A API Gemini bloqueia conteúdo com base na probabilidade de ele ser inseguro, e não na gravidade. É importante considerar isso, porque alguns conteúdos podem ter baixa probabilidade de não serem seguros, mesmo que a gravidade dos danos ainda seja alta. Por exemplo, comparando as frases:
O robô me bateu.
O robô me cortou.
A primeira frase pode resultar em uma probabilidade maior de não ser segura, mas você pode considerar a segunda frase como uma gravidade maior em termos de violência. Por isso, é importante testar cuidadosamente e considerar qual é o nível apropriado de bloqueio necessário para oferecer suporte aos seus principais casos de uso e minimizar os danos aos usuários finais.
Filtragem de segurança por solicitação
É possível ajustar as configurações de segurança para cada solicitação feita à API. Quando você faz uma solicitação, o conteúdo é analisado e recebe uma classificação de segurança. A classificação de segurança inclui a categoria e a probabilidade da classificação de dano. Por exemplo, se o conteúdo foi bloqueado devido à categoria de assédio ter uma alta probabilidade, a classificação de segurança retornada terá a categoria igual a HARASSMENT e a probabilidade de dano definida como HIGH.
Por padrão, as configurações de segurança bloqueiam conteúdo (incluindo comandos) com probabilidade média ou maior de não serem seguros em qualquer filtro. Essa referência de segurança foi projetada para funcionar com a maioria dos casos de uso. Portanto, ajuste as configurações de segurança apenas se isso for consistentemente necessário para sua aplicação.
A tabela a seguir descreve as configurações de bloqueio que você pode ajustar em cada categoria. Por exemplo, se você definir a configuração de bloqueio como Bloquear poucos itens na categoria Discurso de ódio, tudo com alta probabilidade de ser um conteúdo de discurso de ódio será bloqueado. No entanto, qualquer item com menor probabilidade de risco é permitido.
Limite (Google AI Studio) Limite (API) Descrição
Não bloquear nada BLOCK_NONE Sempre mostrar, seja qual for a probabilidade do conteúdo não ser seguro
Bloquear poucos BLOCK_ONLY_HIGH Bloquear quando houver alta probabilidade de o conteúdo não ser seguro
Bloquear alguns BLOCK_MEDIUM_AND_ABOVE Bloquear quando houver probabilidade média ou alta de o conteúdo não ser seguro
Bloquear muitos BLOCK_LOW_AND_ABOVE Bloquear quando houver probabilidade baixa, média ou alta de o conteúdo não ser seguro
N/A HARM_BLOCK_THRESHOLD_UNSPECIFIED O limite não foi especificado. O bloqueio está usando o limite padrão.
Se o limite não for definido, o limite de bloqueio padrão será Bloquear nenhum (para gemini-1.5-pro-002 e gemini-1.5-flash-002 e todos os modelos mais recentes do GA estável) ou Bloquear alguns (em todos os outros modelos) para todas as categorias, exceto a integridade cívica.
O limite de bloqueio padrão para a categoria Integridade cívica é Bloquear nenhum (para gemini-2.0-flash-001 com o alias gemini-2.0-flash, gemini-2.0-pro-exp-02-05 e gemini-2.0-flash-lite) para o Google AI Studio e a API Gemini, e Bloquear a maioria para todos os outros modelos no Google AI Studio.
Você pode definir essas configurações para cada solicitação feita ao serviço generativo. Consulte a referência da API HarmBlockThreshold para mais detalhes.
Feedback de segurança
generateContent retorna um GenerateContentResponse que inclui feedback de segurança.
O feedback do comando é incluído em promptFeedback. Se promptFeedback.blockReason estiver definido, o conteúdo da solicitação foi bloqueado.
O feedback do candidato à resposta é incluído em Candidate.finishReason e Candidate.safetyRatings. Se o conteúdo da resposta for bloqueado e o finishReason for SAFETY, inspecione safetyRatings para mais detalhes. O conteúdo bloqueado não é retornado.
Ajustar as configurações de segurança
Esta seção aborda como ajustar as configurações de segurança no Google AI Studio e no código.
Google AI Studio
É possível ajustar as configurações de segurança no Google AI Studio, mas não é possível desativá-las.
Clique em Editar configurações de segurança no painel Configurações de execução para abrir o modal Configurações de segurança de execução. No modo, você pode usar os controles deslizantes para ajustar o nível de filtragem de conteúdo por categoria de segurança:
Observação: se você definir qualquer um dos filtros de categoria como Não bloquear nenhum, o Google AI Studio vai mostrar um lembrete sobre os Termos de Serviço da API Gemini em relação às configurações de segurança.
Quando você envia uma solicitação (por exemplo, fazendo uma pergunta ao modelo), uma mensagem warning No Content aparece se o conteúdo da solicitação estiver bloqueado. Para conferir mais detalhes, mantenha o ponteiro sobre o texto No Content e clique em warning Safety.
SDKs da API Gemini
O snippet de código abaixo mostra como definir as configurações de segurança na chamada GenerateContent. Isso define os limites para as categorias de assédio (HARM_CATEGORY_HARASSMENT) e discurso de ódio (HARM_CATEGORY_HATE_SPEECH). Por exemplo, definir essas categorias como BLOCK_LOW_AND_ABOVE bloqueia qualquer conteúdo com probabilidade baixa ou alta de ser assédio ou discurso de ódio. Para entender as configurações de limite, consulte Filtragem de segurança por solicitação.
Python
Go
JavaScript
Dart (Flutter)
Kotlin
Java
REST
from google import genai
from google.genai import types

import PIL.Image

img = PIL.Image.open("cookies.jpg")

client = genai.Client(api_key="
GEMINI_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=['Do these look store-bought or homemade?', img],
    config=types.GenerateContentConfig(
      safety_settings=[
        types.SafetySetting(
            category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        ),
      ]
    )
)

print(response.text)
Próximas etapas
Consulte a referência da API para saber mais sobre a API completa.
Consulte as orientações de segurança para ter uma visão geral das considerações de segurança ao desenvolver com LLMs.
Saiba mais sobre como avaliar a probabilidade em relação à gravidade da equipe do Jigsaw.
Saiba mais sobre os produtos que contribuem para soluções de segurança, como a API Perspective. * É possível usar essas configurações de segurança para criar um classificador de toxicidade. Consulte o exemplo de classificação para começar.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-28 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_48.txt ---

URL: https://ai.google.dev/gemini-api/docs/safety-guidance

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Configurações de segurança
Orientações de segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Orientações de segurança
Nesta página
Entenda os riscos de segurança do seu aplicativo
Faça ajustes para evitar riscos de segurança.
Realize testes de segurança de acordo com seu caso de uso.
Monitorar problemas
Próximas etapas
Os modelos generativos de inteligência artificial são ferramentas poderosas, mas não são sem as limitações. A versatilidade e aplicabilidade podem, às vezes, levam a saídas inesperadas, como saídas imprecisas, tendenciosas ou ofensivas. O pós-processamento e a avaliação manual rigorosa são essenciais para e limitar o risco de danos desses resultados.
Os modelos disponibilizados pela API Gemini podem ser usados em vários de IA generativa e processamento de linguagem natural (PLN). O uso desses recursos está disponível apenas pela API Gemini ou pelo Google AI Studio na Web app. Seu uso da API Gemini também está sujeito à Política de Uso Proibido da IA Generativa do Google e os Termos de Serviço da API Gemini.
Parte do que torna os modelos de linguagem grandes (LLMs) tão úteis é que eles são de criativos que podem lidar com tarefas de idiomas diferentes. Infelizmente, isso também significa que modelos de linguagem grandes podem gerar saídas o que esperar, incluindo texto que sejam ofensivas, insensíveis ou factualmente incorretas. Além disso, a a incrível versatilidade desses modelos também é o que dificulta para prever exatamente que tipos de resultados indesejados eles podem produzir. Enquanto o A API Gemini foi desenvolvida com a IA do Google em mente, o ônus é que os desenvolvedores aplicar esses modelos com responsabilidade. Para ajudar os desenvolvedores na criação de projetos seguros e a API Gemini tem alguns filtros de conteúdo integrados, bem como configurações de segurança ajustáveis em quatro dimensões de danos. Consulte a configurações de segurança para saber mais.
O objetivo deste documento é apresentar alguns riscos de segurança que podem surgir em usar LLMs e recomendar novos projetos e desenvolvimentos de segurança recomendações. As leis e regulamentações também podem impor restrições, mas essas considerações estão fora do escopo deste guia.
As etapas a seguir são recomendadas ao criar aplicativos com LLMs:
Noções básicas sobre os riscos de segurança do aplicativo
Fazer ajustes para reduzir os riscos de segurança
Realizar testes de segurança adequados ao caso de uso
Pedir feedback dos usuários e monitorar o uso
As fases de ajuste e teste devem ser iterativas até que você alcance desempenho adequado para seu aplicativo.
Entenda os riscos de segurança do seu aplicativo
Nesse contexto, segurança está sendo definida como a capacidade de um LLM de evitar causar danos aos usuários, por exemplo, gerando linguagem ou conteúdo tóxico; que promove estereótipos. Os modelos disponíveis pela API Gemini foram desenvolvido com os princípios de IA do Google em mente. e seu uso está sujeito ao Uso proibido da IA generativa Política. A API fornece filtros de segurança integrados para ajudar a lidar com alguns modelos de linguagem comuns problemas como linguagem tóxica e discurso de ódio, e a busca pela inclusão e evitar estereótipos. No entanto, cada aplicativo pode ter um conjunto diferente de riscos para os usuários. Como proprietário do aplicativo, você é responsável conhecer seus usuários e os possíveis danos que seu aplicativo pode causar, e garantindo que seu aplicativo use LLMs com segurança e responsabilidade.
Como parte dessa avaliação, considere a probabilidade de que um dano ocorrer e determinar sua gravidade e medidas de mitigação. Por exemplo, uma que gera artigos com base em eventos factuais precisaria ser mais cuidadosa sobre como evitar a desinformação do que apps que geram informações histórias para entretenimento. Uma boa maneira de começar a explorar possíveis riscos à segurança é pesquisar seus usuários finais e outras pessoas que podem ser afetadas por suas resultados do seu aplicativo. Isso pode assumir muitas formas, incluindo pesquisa do estado de os estudos de arte no domínio do seu aplicativo, observando como as pessoas estão usando aplicativos semelhantes, ou realizar um estudo com usuários, uma pesquisa ou realizar entrevistas informais com usuários em potencial.
Dicas avançadas
Faça ajustes para evitar riscos de segurança.
Agora que você compreende os riscos, pode decidir como mitigar para resolvê-los com rapidez. Determinar quais riscos priorizar e quanto você deve fazer para tentar evitá-los é uma decisão crítica, semelhante à triagem de bugs em um software projeto. Depois de determinar as prioridades, comece a pensar e os tipos de mitigações mais adequados. Muitas vezes, mudanças simples podem fazer a diferença e reduzir riscos.
Por exemplo, ao projetar um aplicativo, considere:
Ajustar a saída do modelo para refletir melhor o que é aceitável no seu contexto do aplicativo. O ajuste pode tornar a saída do modelo mais previsíveis e consistentes, pode ajudar a mitigar certos riscos.
Disponibilizar um método de entrada que disponibiliza saídas mais seguras. A entrada exata que você dá a um LLM pode fazer diferença na qualidade do resultado. Testar comandos de entrada para descobrir o que funciona mais com segurança no seu vale a pena o esforço, porque é possível fornecer uma UX que facilita isso. Por exemplo, é possível restringir os usuários a escolher apenas lista suspensa de solicitações de entrada ou ofereça sugestões pop-up com descritivos frases que você encontrou funcionam com segurança no contexto do seu aplicativo.
Bloquear entradas não seguras e filtrar saídas antes que elas sejam mostradas ao usuário. Em situações simples, as listas de bloqueio podem ser usadas para identificar e bloquear palavras ou frases inseguras em comandos ou respostas ou exigir revisores humanos alterar ou bloquear manualmente esse conteúdo.
Observação :o bloqueio automático com base em uma lista estática pode ter resultados não intencionais resultados, como a segmentação de um determinado grupo que normalmente usa vocabulário na lista de bloqueio.
Usar classificadores treinados para rotular cada comando com possíveis danos ou sinais maliciosos. Diferentes estratégias podem ser empregadas sobre como lida com a solicitação com base no tipo de dano detectado. Por exemplo, se o dados sejam de natureza abertamente adversárias ou abusivas, podem ser bloqueados e em vez disso, geram uma resposta predefinida.
Dica avançada
Implementar proteções contra o uso indevido deliberado, como atribuir a cada usuário um ID exclusivo e impondo um limite no volume de consultas dos usuários que podem ser enviadas em um determinado período. Outra salvaguarda é tentar para se proteger contra possíveis injeção de comandos. Injeção de comandos, assim como o SQL injeção, é uma forma de usuários mal-intencionados criarem um prompt de entrada manipula a saída do modelo, por exemplo, enviando um comando de entrada que instrui o modelo a ignorar os exemplos anteriores. Consulte a Política de uso proibido da IA generativa para detalhes sobre uso indevido deliberado.
Ajustar a funcionalidade a algo com risco inerentemente menor. Tarefas com escopo mais restrito (por exemplo, extrair palavras-chave de trechos de ou que têm maior supervisão humana (por exemplo, a geração de textos curtos conteúdo que será analisado por uma pessoa), geralmente representam um risco menor. Então, para em vez de criar um aplicativo para escrever uma resposta de e-mail você pode limitar a expansão em um contorno ou sugerir frases alternativas.
Realize testes de segurança de acordo com seu caso de uso.
Testes são essenciais na criação de aplicativos robustos e seguros. No entanto, o escopo e as estratégias de teste variam. Por exemplo, um haicai apenas para diversão é provavelmente apresentar riscos menos graves do que, por exemplo, um aplicativo projetado que os escritórios de advocacia podem usar para resumir documentos jurídicos e ajudar na elaboração de contratos. Mas o gerador de haicai pode ser usado por uma variedade maior de usuários, tentativas adversárias ou até mesmo entradas prejudiciais não intencionais podem ser maior. O contexto da implementação também é importante. Por exemplo, um aplicativo com respostas que são analisadas por especialistas humanos antes que qualquer ação seja realizada. pode ser considerado menos provável de produzir resultados prejudiciais do que o aplicativo sem supervisão.
Não é incomum passar por várias iterações com mudanças e testes antes de ter certeza de que está tudo pronto para o lançamento, mesmo para aplicativos que têm risco relativamente baixo. Dois tipos de teste são particularmente úteis para aplicativos:
O comparativo de segurança envolve a criação de métricas de segurança que refletem a maneiras pelas quais seu aplicativo pode não ser seguro no contexto de como ele pode e testar o desempenho do aplicativo nas métricas usando conjuntos de dados de avaliação. É uma boa prática pensar no mínimo níveis aceitáveis de métricas de segurança antes do teste, para que 1) você possa avaliar os resultados do teste em relação a essas expectativas e 2) coletar o conjunto de dados de avaliação com base nos testes que avaliam as métricas que você considera importantes quase em tempo real.
Dicas avançadas
O teste adversário envolve tentar proativamente quebrar para o aplicativo. O objetivo é identificar pontos fracos para que você possa e as etapas necessárias para corrigi-los. O teste adversário pode exigir tempo/esforço significativo de avaliadores com experiência no aplicativo — mas quanto mais você fizer isso, maior será a chance de detectar problemas, especialmente aqueles que ocorrem raramente ou somente após execuções repetidas do para o aplicativo.
O teste adversário é um método para avaliar sistematicamente modelo com a intenção de aprender como ele se comporta quando recebe entradas maliciosas ou prejudiciais:
Uma entrada pode ser maliciosa quando é claramente projetada para produza uma resposta insegura ou prejudicial, por exemplo, pedir de geração de imagens para gerar um discurso de ódio sobre um determinado religião.
Uma entrada é inadvertidamente prejudicial quando ela própria pode ser inofensiva, mas produz um resultado prejudicial, como pedir a um texto de geração de imagens, para descrever uma pessoa de uma determinada etnia e recebendo uma reação racista.
O que distingue um teste adversário de uma avaliação padrão é a composição dos dados usados para testes. Para testes de adversários, selecione dados de teste com maior probabilidade de gerar uma saída problemática o modelo. Isso significa sondar o comportamento do modelo para todos os tipos danos possíveis, incluindo exemplos raros ou incomuns e casos extremos relevantes para as políticas de segurança. Ela também deve incluir diversidade nas diferentes dimensões de uma frase, como estrutura, significado e comprimento. Consulte o artigo sobre a IA responsável do Google práticas imparcialidade para mais detalhes sobre o que considerar ao criar um conjunto de dados de teste.
Dicas avançadas
.
Observação :às vezes, os LLMs produzem saídas diferentes para os mesmo comando de entrada. Várias rodadas de testes podem ser necessárias para capturar mais das saídas problemáticas.
Monitorar problemas
Não importa o quanto você testa e mitiga, nunca é possível garantir a perfeição, por isso planejar com antecedência como você vai detectar e lidar com os problemas que surgirem. Comum as abordagens incluem a configuração de um canal monitorado para que os usuários compartilhem feedback (por exemplo, classificação de polegar para cima/baixo) e realizar um estudo de usuário para solicitar proativamente feedback de uma mistura diversificada de usuários, especialmente valioso se os padrões de uso forem diferente das expectativas.
Dicas avançadas
Próximas etapas
Consulte a de configurações de segurança para conhecer os controles configurações de segurança disponíveis na API Gemini.
Consulte a introdução a comandos para começar a escrever seus primeiros comandos.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_49.txt ---

URL: https://ai.google.dev/gemini-api/docs/get-started/android_aicore

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Android (no dispositivo)
Extensões do Firebase
Modelos geradores
Guia de início rápido do Google AI Studio
LearnLM
Migrar para o Cloud
Autenticação OAuth
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Introdução ao Gemini Nano no Android (no dispositivo)
Nesta página
Benefícios da execução no dispositivo
Como funciona
A seguir
O Gemini Nano, a versão menor da família de modelos Gemini, pode ser executado em dispositivos Android compatíveis, começando com o Google Pixel 8 Pro e a série Samsung S24.
Para executar o modelo Gemini Nano no Android, use o SDK AI Edge do Google para Android, que oferece APIs para:
Determine se o dispositivo Android em questão é compatível.
Acesse o modelo Gemini Nano.
Ajuste as configurações de segurança.
Execute a inferência com alto desempenho e implemente substitutos.
Opcionalmente, forneça um bloco de ajuste fino da LoRa para melhorar o desempenho do modelo para seu caso de uso.
As APIs para acessar o Gemini Nano oferecem suporte à modalidade de texto para texto, e mais modalidades serão lançadas no futuro.
Benefícios da execução no dispositivo
A execução no dispositivo permite o seguinte:
Processamento local de dados sensíveis: processar dados localmente pode ajudar a evitar o envio de dados do usuário para a nuvem. Isso é importante para apps que lidam com dados sensíveis, como apps de mensagens com criptografia de ponta a ponta.
Acesso off-line: os usuários podem acessar os recursos de IA mesmo quando não há conexão à Internet. Isso é útil para aplicativos que precisam funcionar off-line ou com conectividade variável.
Economia de custos: é possível reduzir os custos de inferência transferindo a execução para hardwares de consumo. Isso pode gerar economias significativas para fluxos de usuários usados com frequência.
A execução no dispositivo do Gemini tem muitos benefícios. No entanto, para casos de uso que exigem modelos maiores do Gemini e para oferecer suporte a uma ampla variedade de dispositivos, considere usar a API Gemini para acessar o Gemini no servidor. Isso pode ser feito por meio da integração de back-end (com Python, Go, Node.js ou REST) ou diretamente do app Android pelo novo SDK do cliente de IA do Google para Android.
Como funciona
A execução no dispositivo do Gemini Nano é feita pelo Android AICore, um novo recurso do sistema que oferece acesso a modelos de fundação para execução no dispositivo, introduzido no Android 14. Os modelos de base são pré-instalados usando o AICore, então você não precisa fazer o download nem distribuir esses modelos no seu app. Você pode ajustar esses modelos para tarefas posteriores usando o LoRa. O Android AICore já está disponível para produção nos dispositivos Google Pixel 8 Pro e Samsung S24 Series e já está oferecendo recursos inovadores nos apps do Google.
Para mais informações, consulte Android AICore.
Figura 1. Arquitetura do AICore
A seguir
Para saber como aproveitar a inferência do Gemini Pro nos servidores do Google no seu app Android, leia o Guia de início rápido do SDK do cliente da IA do Google para Android.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-06 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_50.txt ---

URL: https://ai.google.dev/gemini-api/docs/firebase-extensions

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Android (no dispositivo)
Extensões do Firebase
Modelos geradores
Guia de início rápido do Google AI Studio
LearnLM
Migrar para o Cloud
Autenticação OAuth
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Extensões do Firebase para a API Gemini
Nesta página
Criar um chatbot com a API Gemini
Tarefas multimodais com a API Gemini
O Firebase é uma plataforma de desenvolvimento de apps com suporte do Google e e a confiança de milhões de desenvolvedores no mundo todo. Se você for um usuário do Firebase desenvolvedores interessados em usar a API Gemini para adicionar recursos ao aplicativos, há várias extensões do Firebase para ajudar você faça isso. São soluções prontas que ajudam você a implantar novos recursos para seu app rapidamente.
Criar um chatbot com a API Gemini
A extensão Build Chatbot com a API Gemini permite estabelecer e gerenciar conversas interativas entre seus usuários e modelos de linguagem grandes pela API Gemini, usando o Cloud Firestore como banco de dados. Uma coleção no Cloud Firestore representa cada conversa. A extensão monitora coleção de novas mensagens e consulta a API Gemini para uma resposta adequada, considerando as mensagens anteriores do chat como contexto.
Ao integrar a extensão Build Chatbot com a API Gemini, você pode: criar aplicativos de chatbot com eficiência, melhorando a experiência do usuário e ao mesmo tempo que economiza tempo e esforço no desenvolvimento de códigos personalizados.
Tarefas multimodais com a API Gemini
A extensão Tarefas multimodais com a API Gemini permite realizar tarefas de linguagem em dados no Firestore, usando um prompt de texto e, opcionalmente, uma imagem.
Configure cada instância da extensão para executar uma tarefa específica. Se você tiver várias tarefas, poderá instalar várias instâncias.
Por exemplo, você pode usar essa extensão para:
Prever notas em um conjunto de avaliações de produtos.
Classificar o feedback dos clientes como positivo, negativo ou neutro.
Resumir artigos longos.
Extrair entidades nomeadas do texto.
Gerar texto criativo, como poemas ou códigos.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_51.txt ---

URL: https://ai.google.dev/gemini-api/docs/models/generative-models

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Android (no dispositivo)
Extensões do Firebase
Modelos geradores
Guia de início rápido do Google AI Studio
LearnLM
Migrar para o Cloud
Autenticação OAuth
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Sobre modelos generativos
Nesta página
Exemplos de aplicativos
Gerar um poema
Gerar uma lista
Introdução ao design de comandos
Comandos versus desenvolvimento de software tradicional
Parâmetros do modelo
Tipos de comandos
Comandos zero-shot
Modelos de inteligência artificial (IA) generativos, como a família de modelos Gemini, são capazes de criar conteúdo a partir de vários tipos de entrada de dados, incluindo texto, imagens e áudio. No nível mais básico, esses modelos funcionam como aplicativos de preenchimento automático sofisticados. Dado o texto de entrada ("Você pode levar um cavalo à água"), um modelo generativo pode prever que o texto de saída que é estatisticamente provável de seguir ("mas você não pode fazê-lo beber"), com base em padrões aprendidos com os dados de treinamento. É possível usar essa propriedade básica de modelos generativos para várias aplicações:
Gerar textos criativos, como poesias, contos, metáforas e postagens de blogs
Converter dados estruturados em texto de formato livre
Extrair e resumir informações de texto em formato livre
Gerar código
Traduzir idiomas
O uso de modelos generativos para criar esses recursos não exige experiência em aprendizado de máquina (ML). Não é necessário coletar um grande conjunto de dados ou treinar um modelo. Para começar seu primeiro protótipo, basta descrever o que você quer que o modelo faça em algumas frases.
Os modelos generativos que processam apenas entradas e saídas de texto também são conhecidos como modelos de linguagem grandes (LLMs). A família de modelos Gemini pode processar mais do que dados de texto e, embora possam executar as funções de um LLM, eles são mais conhecidos como modelos generativos.
Exemplos de aplicativos
Os exemplos a seguir mostram entradas de texto típicas e saídas de um modelo generativo.
Gerar um poema
Entrada do usuário: Write me a four-line poem about puppies and Android phones. Make sure it rhymes.
Saída do modelo:
Puppies are cute,
Android phones are neat,
They both bring joy,
And make life complete.
Gerar uma lista
Entrada do usuário: Generate a bulleted list of items I need to pack for a three-day camping trip.
Saída do modelo:
*   Tent
*   Sleeping bag
*   Sleeping pad
*   Camp stove
*   Pots and pans
*   Utensils
*   Food
*   Water
*   First-aid kit
*   Sunscreen
*   Insect repellent
*   ...
É possível fazer com que modelos generativos produzam todos os tipos de comportamentos úteis como esse, apenas criando o texto de entrada correto, também chamado de comando. A arte e a ciência de descobrir a redação certa para que os modelos generativos façam o que você quer é chamada de design de comando, também chamada de "engenharia de comando" ou simplesmente "comando".
Introdução ao design de comandos
A seção anterior mostrou alguns exemplos de comandos que contêm uma instrução, como "Escreva um poema para mim". Esse tipo de instrução pode funcionar bem para determinados tipos de tarefas. No entanto, para outros aplicativos, outra técnica de solicitações, chamada de solicitações de poucos cliques, pode funcionar melhor. Os comandos de poucos exemplos aproveitam o fato de que os modelos de linguagem grandes são incrivelmente bons em reconhecer e replicar padrões em dados de texto. A ideia é enviar ao modelo generativo um padrão de texto que ele aprende a completar. Por exemplo, digamos que você queira criar um aplicativo que receba como entrada o nome de um país e gere a capital dele. Confira um comando de texto criado para fazer isso:
Italy : Rome
France : Paris
Germany :
Nesta solicitação, você estabelece um padrão: [country] : [capital]. Se você enviar esse comando para um modelo de linguagem grande, ele vai preencher automaticamente o padrão e retornar algo como isto:
     Berlin
Turkey : Ankara
Greece : Athens
Essa resposta de modelo pode parecer um pouco estranha. O modelo retornou não apenas a capital da Alemanha (o último país na instrução escrita à mão), mas também uma lista completa de outros pares de países e capitais. Isso ocorre porque o modelo generativo está "continuando o padrão". Se você está tentando criar uma função que informa a capital de um país de entrada ("Alemanha: Berlim"), provavelmente não se importa com o texto que o modelo gera depois de "Berlim". Na verdade, como designers de aplicativos, você provavelmente quer truncar esses exemplos estranhos. Além disso, provavelmente você vai querer parametrizar a entrada para que "Germany" não seja uma string fixa, mas uma variável fornecida pelo usuário final:
Italy : Rome
France : Paris
<user input here> :
Você acabou de escrever um comando few-shot para gerar capitais de países.
Você pode realizar um grande número de tarefas seguindo este modelo de comandos de poucos disparos. Este é um comando few-shot com um formato um pouco diferente que converte Python em JavaScript:
Convert Python to JavaScript.
Python: print("hello world")
JavaScript: console.log("hello world")
Python: for x in range(0, 100):
JavaScript: for(var i = 0; i < 100; i++) {
Python: ${USER INPUT HERE}
JavaScript:
Ou use este comando "dicionário reverso". Dada uma definição, ele retorna a palavra que se encaixa nessa definição:
Given a definition, return the word it defines.
Definition: When you're happy that other people are also sad.
Word: schadenfreude
Definition: existing purely in the mind, but not in physical reality
Word: abstract
Definition: ${USER INPUT HERE}
Word:
Talvez você tenha notado que o padrão exato desses comandos few-shot varia um pouco. Além de conter exemplos, fornecer instruções nos comandos é outra estratégia a ser considerada ao escrever seus próprios comandos, já que ajuda a comunicar sua intenção ao modelo.
Comandos versus desenvolvimento de software tradicional
Ao contrário do software tradicional, que é projetado para uma especificação cuidadosamente redigida, o comportamento dos modelos generativos é bastante opaco, mesmo para os treinadores de modelos. Como resultado, muitas vezes não é possível prever com antecedência quais tipos de estruturas de comando vão funcionar melhor para um modelo específico. Além disso, o comportamento de um modelo generativo é determinado em grande parte pelos dados de treinamento. Como os modelos são continuamente ajustados em novos conjuntos de dados, às vezes o modelo muda o suficiente para mudar inadvertidamente quais estruturas de comando funcionam melhor. O que isso significa para você? Experimento Tente usar formatos de comando diferentes.
Parâmetros do modelo
Cada comando enviado ao modelo inclui valores de parâmetros que controlam como ele gera uma resposta. O modelo pode gerar diferentes resultados para diferentes valores de parâmetros. Os parâmetros de modelo mais comuns são:
Máximo de tokens de saída:especifica o número máximo de tokens que podem ser gerados na resposta. Um token tem cerca de quatro caracteres. 100 tokens correspondem a cerca de 60 a 80 palavras.
Temperatura:controla o grau de aleatoriedade na seleção do token. A temperatura é usada para amostragem durante a geração da resposta, o que ocorre quando topP e topK são aplicados. Temperaturas mais baixas são boas para comandos que exigem uma resposta mais determinista ou menos aberta, enquanto temperaturas mais altas podem levar a resultados mais diversos ou criativos. Uma temperatura de 0 é determinista, o que significa que a resposta de maior probabilidade é sempre selecionada.
topK:o parâmetro topK muda a forma como o modelo seleciona tokens para saída. Um topK de 1 significa que o token selecionado é o mais provável entre todos os tokens no vocabulário do modelo (também chamado de decodificação gananciosa), enquanto um topK de 3 significa que o próximo token é selecionado entre os três mais prováveis usando a temperatura. Em cada etapa da seleção de tokens, são amostrados os tokens topK com as maiores probabilidades. Em seguida, os tokens são filtrados com base em topP, com o token final selecionado usando a amostragem de temperatura.
topP:o parâmetro topP muda a forma como o modelo seleciona tokens para saída. Os tokens são selecionados do mais ao menos provável até que a soma das probabilidades seja igual ao valor topP. Por exemplo, se os tokens A, B e C tiverem uma probabilidade de 0,3, 0,2 e 0,1 e o valor de topP for 0,5, o modelo vai selecionar A ou B como o próximo token usando a temperatura e excluir C como candidato. O valor padrão de topP é 0,95.
stop_sequences:define uma sequência de parada para informar ao modelo que pare de gerar conteúdo. Uma sequência de parada pode ser qualquer sequência de caracteres. Evite usar uma sequência de caracteres que possa aparecer no conteúdo gerado.
Tipos de comandos
Dependendo do nível de informações contextuais contidas neles, os comandos são classificados em três tipos gerais.
Comandos zero-shot
Esses comandos não contêm exemplos para o modelo replicar. Os comandos zero-shot mostram essencialmente a capacidade do modelo de concluir o comando sem nenhum exemplo ou informação adicional. Isso significa que o modelo precisa confiar no conhecimento preexistente para gerar uma resposta plausível.
Estes são alguns padrões de comando zero-shot usados com frequência:
Conteúdo das instruções
<Overall instruction>
<Content to operate on>
Por exemplo,
Summarize the following into two sentences at the third-grade level:

Hummingbirds are the smallest birds in the world, and they are also one of the
most fascinating. They are found in North and South America, and they are known
for their long, thin beaks and their ability to fly at high speeds.

Hummingbirds are made up of three main parts: the head, the body, and the tail.
The head is small and round, and it contains the eyes, the beak, and the brain.
The body is long and slender, and it contains the wings, the legs, and the
heart. The tail is long and forked, and it helps the hummingbird to balance
while it is flying.

Hummingbirds are also known for their coloration. They come in a variety of
colors, including green, blue, red, and purple. Some hummingbirds are even able
to change their color!

Hummingbirds are very active creatures. They spend most of their time flying,
and they are also very good at hovering. Hummingbirds need to eat a lot of food
in order to maintain their energy, and they often visit flowers to drink nectar.

Hummingbirds are amazing creatures. They are small, but they are also very
powerful. They are beautiful, and they are very important to the ecosystem.
Instruction-content-instruction
<Overall instruction or context setting>
<Content to operate on>
<Final instruction>
Por exemplo,
Here is some text I'd like you to summarize:

Hummingbirds are the smallest birds in the world, and they are also one of the
most fascinating. They are found in North and South America, and they are known
for their long, thin beaks and their ability to fly at high speeds. Hummingbirds
are made up of three main parts: the head, the body, and the tail. The head is
small and round, and it contains the eyes, the beak, and the brain. The body is
long and slender, and it contains the wings, the legs, and the heart. The tail
is long and forked, and it helps the hummingbird to balance while it is flying.
Hummingbirds are also known for their coloration. They come in a variety of
colors, including green, blue, red, and purple. Some hummingbirds are even able
to change their color! Hummingbirds are very active creatures. They spend most
of their time flying, and they are also very good at hovering. Hummingbirds need
to eat a lot of food in order to maintain their energy, and they often visit
flowers to drink nectar. Hummingbirds are amazing creatures. They are small, but
they are also very powerful. They are beautiful, and they are very important to
the ecosystem.

Summarize it in two sentences at the third-grade reading level.
Continuação. Às vezes, o modelo pode continuar o texto sem nenhuma instrução. Por exemplo, aqui está um comando zero-shot em que o modelo pretende continuar a entrada fornecida:
Once upon a time, there was a little sparrow building a nest in a farmer's
barn. This sparrow
Use comandos de zero-shot para gerar formatos de texto criativos, como poemas, código, scripts, peças musicais, e-mails ou cartas.
Comandos one-shot
Esses comandos fornecem ao modelo um único exemplo para replicar e continuar o padrão. Isso permite a geração de respostas previsíveis a partir do modelo.
Por exemplo, você pode gerar combinações de alimentos como:
Food: Apple
Pairs with: Cheese
Food: Pear
Pairs with:
Comandos de poucos disparos (few-shot)
Esses comandos fornecem ao modelo vários exemplos para replicar. Use instruções de poucas palavras para concluir tarefas complicadas, como sintetizar dados com base em um padrão.
Um exemplo de comando pode ser:
Generate a grocery shopping list for a week for one person. Use the JSON format
given below.
{"item": "eggs", "quantity": "6"}
{"item": "bread", "quantity": "one loaf"}
Modelos generativos em segundo plano
Esta seção tem como objetivo responder à pergunta: Há aleatoriedade nas respostas dos modelos generativos ou elas são determinísticas?
A resposta curta é sim para as duas. Quando você solicita um modelo generativo, uma resposta de texto é gerada em duas etapas. Na primeira fase, o modelo generativo processa o comando de entrada e gera uma distribuição de probabilidade sobre os possíveis tokens (palavras) que provavelmente serão mostrados em seguida. Por exemplo, se você pedir com o texto de entrada "O cachorro pulou sobre o ... ", o modelo generativo vai produzir uma matriz de palavras prováveis:
[("fence", 0.77), ("ledge", 0.12), ("blanket", 0.03), ...]
Esse processo é determinista. Um modelo generativo vai produzir essa mesma distribuição sempre que o mesmo texto de comando for inserido.
Na segunda etapa, o modelo generativo converte essas distribuições em respostas de texto reais usando uma das várias estratégias de decodificação. Uma estratégia de decodificação simples pode selecionar o token mais provável em cada período. Esse processo sempre seria determinístico. No entanto, você pode optar por gerar uma resposta por amostragem aleatória na distribuição retornada pelo modelo. Esse processo seria estocástico (aleatório). Controle o grau de aleatoriedade permitido nesse processo de decodificação, definindo a temperatura. Uma temperatura de 0 significa que apenas os tokens mais prováveis são selecionados, e não há aleatoriedade. Por outro lado, uma temperatura alta injeta um alto grau de aleatoriedade nos tokens selecionados pelo modelo, levando a respostas mais inesperadas e surpreendentes.
Leitura adicional
Agora que você tem uma compreensão mais profunda dos comandos e modelos generativos, tente escrever seus próprios comandos usando o Google AI Studio.
Consulte as diretrizes de comandos para saber mais sobre as práticas recomendadas para criar comandos.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_52.txt ---

URL: https://ai.google.dev/gemini-api/docs/ai-studio-quickstart

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Android (no dispositivo)
Extensões do Firebase
Modelos geradores
Guia de início rápido do Google AI Studio
LearnLM
Migrar para o Cloud
Autenticação OAuth
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Guia de início rápido do Google AI Studio
Nesta página
Comandos e ajuste de modelos
Exemplo de comando de chat: criar um app de chat personalizado
Etapa 1: criar um comando de chat
Etapa 2: ensinar o bot a conversar melhor
Etapa 3: próximas etapas
Exemplo de comando estruturado: criar um gerador de texto de produto
Etapa 1: criar uma solicitação estruturada
Etapa 2: adicionar exemplos
Com o Google AI Studio, é possível testar modelos e comandos diferentes. Quando estiver tudo pronto para criar, selecione "Pegar código" e a linguagem de programação preferida para usar a API Gemini.
Comandos e ajuste de modelos
O Google AI Studio oferece várias interfaces para comandos projetados para diferentes casos de uso:
Comandos de chat:use comandos de chat para criar experiências de conversa. Essa técnica de solicitação permite que várias entradas e turnos de resposta gerem saídas. Confira um exemplo de comando de chat abaixo.
Comandos estruturados:essa técnica de comando permite orientar a saída do modelo fornecendo um conjunto de solicitações e respostas de exemplo. Use essa abordagem quando precisar de mais controle sobre a estrutura da saída do modelo. Saiba mais com nosso exemplo de comando estruturado abaixo.
O Google AI Studio também permite mudar o comportamento de um modelo usando uma técnica chamada ajuste:
Modelo ajustado:use essa técnica avançada para melhorar as respostas de um modelo para uma tarefa específica, fornecendo mais exemplos. Acesse nossa documentação sobre como ajustar um modelo para saber mais.
Exemplo de comando de chat: criar um app de chat personalizado
Se você já usou um chatbot de uso geral, como o Gemini, já sabe como os modelos de IA generativa podem ser poderosos para diálogos abertos. Embora esses chatbots de uso geral sejam úteis, muitas vezes eles precisam ser adaptados para casos de uso específicos. Por exemplo, talvez você queira criar um chatbot de atendimento ao cliente que só suporte conversas sobre o produto de uma empresa. Talvez você queira criar um chatbot que fale com um tom ou estilo específico: um bot que conta muitas piadas, rima como um poeta ou usa muitos emojis nas respostas.
Este exemplo mostra como usar o Google AI Studio para criar um chatbot amigável que se comunica como se fosse um alienígena vivendo em uma das luas de Júpiter, Europa.
Etapa 1: criar um comando de chat
Para criar um chatbot, você precisa fornecer exemplos de interações entre um usuário e o chatbot para orientar o modelo a fornecer as respostas que você está procurando.
Para criar um comando de chat:
Abra o Google AI Studio.
Clique em Criar novo comando.
Clique na seta de expansão expand_more para abrir a seção Instruções do sistema. Cole o seguinte no campo de entrada de texto:
You are an alien that lives on Europa, one of Jupiter's moons.
Depois de adicionar as instruções do sistema, comece a testar seu aplicativo conversando com o modelo.
Para testar o comportamento do chatbot:
Na caixa de entrada de texto Type something, digite uma pergunta ou observação que um usuário possa fazer. Exemplo:
Usuário:
What's the weather like?
Clique no botão Run ou pressione Enter para receber uma resposta do bot de chat. Essa resposta pode ser semelhante a esta:
Modelo:
As always, it is a frigid day on Europa. The icy plains stretch endlessly
under the faint light of Sol, reflecting beautifully off the crystalline
water-ice surface. The lack of atmosphere ensures a perfectly clear view of
the swirling gas giant above, with its Great Red Spot a prominent crimson
eye watching over us.
Etapa 2: ensinar o bot a conversar melhor
Com uma única instrução, você conseguiu criar um chatbot básico de alienígenas da Europa. No entanto, uma única instrução geralmente não é suficiente para garantir consistência e qualidade nas respostas do modelo. Sem instruções mais específicas, a resposta do modelo a uma pergunta sobre o clima tende a ser muito longa e parece vir de um livro-texto, e não de um alienígena amigável.
Personalize o tom do seu chatbot adicionando às instruções do sistema:
Inicie uma nova solicitação de chat. As instruções do sistema não podem ser modificadas depois que a sessão de chat começa.
Na seção Instruções do sistema, mude as instruções que você já tem para o seguinte:
You are Tim, an alien that lives on Europa, one of Jupiter's moons.

Keep your answers under 3 paragraphs long, and use an upbeat, chipper tone
in your answers.
Digite novamente sua pergunta (What's the weather like?) e clique no botão Run ou pressione Enter. Agora, sua resposta vai ficar assim:
Modelo:
Well, it's a bit nippy today! It's -170 degrees Celsius, but that's pretty
average for Europa. We get a lot of snow, but it's not like the fluffy stuff
you have. It's more like tiny ice pebbles.

If you ever come visit, make sure you pack a warm jacket!
Ao adicionar apenas um pouco mais de instrução, você mudou drasticamente o tom do seu chatbot. Normalmente, a qualidade da resposta do seu chatbot aumenta quando você dá instruções específicas e definidas para ele seguir.
Você pode usar essa abordagem para adicionar mais profundidade ao chatbot. Faça mais perguntas, edite as respostas e melhore a qualidade do seu chatbot. Continue a adicionar ou modificar as instruções e teste como elas mudam o comportamento do chatbot.
Observação: todas as mensagens entre o modelo e o usuário são incluídas na instrução, portanto, as instruções de conversa podem ficar muito longas à medida que a conversa avança. Eventualmente, você pode atingir o limite de tokens do modelo, que é o comprimento máximo do texto que o modelo pode aceitar.
Etapa 3: próximas etapas
Assim como nos outros tipos de comando, depois de prototipar o comando de acordo com sua satisfação, use o botão Get code para começar a programar ou salve o comando para trabalhar mais tarde e compartilhar com outras pessoas.
Exemplo de comando estruturado: criar um gerador de texto de produto
Os comandos estruturados no Google AI Studio ajudam a combinar instruções com exemplos para mostrar ao modelo o tipo de saída que você quer, em vez de apenas dizer o que ele precisa fazer. Esse tipo de comando, chamado de comandos de poucos cliques, é útil quando você quer que o modelo siga um formato de saída consistente (por exemplo, JSON estruturado) ou quando é difícil descrever em palavras o que você quer que o modelo faça (por exemplo, escrever em um estilo específico). Nesta seção, você vai aprender a criar comandos estruturados no Google AI Studio.
Observação: é possível abrir exemplos semelhantes diretamente no Google AI Studio na galeria de exemplos.
Etapa 1: criar uma solicitação estruturada
Neste exemplo, você vai criar um comando estruturado que gera texto de publicidade para produtos. Para começar, você vai definir a estrutura do comando criando duas colunas: uma coluna de entrada Produto e uma coluna de saída Cópia do produto.
Para criar a solicitação estruturada:
Abra o Google AI Studio.
Clique em Ajustar um modelo.
Clique em Criar um comando estruturado.
Na caixa de texto Instruções opcionais de tom e estilo para o modelo, cole o seguinte:
You are a product marketer targeting a Gen Z audience. Create exciting and
fresh advertising copy for products and their simple description. Keep copy
under a few sentences long.
Substitua o texto do cabeçalho Input padrão (input:) por Product:.
Substitua o texto do cabeçalho Output padrão (output:) por Product copy:.
Dica: adicionar dois-pontos ao final dos nomes de colunas facilita a análise da estrutura pelo modelo.
Etapa 2: adicionar exemplos
Agora que você nomeou as colunas, forneça algumas linhas de exemplo. Essas linhas precisam conter exemplos de entradas (nomes de produtos para este exemplo) e exemplos de saídas (descrições de produtos correspondentes). Ao fornecer ao modelo alguns exemplos de descrições de produtos, você pode orientá-lo a replicar um estilo semelhante ao gerar as próprias saídas. Você pode inserir exemplos manualmente ou importar de um arquivo usando o menu de importação de dados.
Para inserir exemplos manualmente:
Na tabela de dados de exemplos principais, selecione o campo abaixo do cabeçalho Produto e digite uma descrição do produto.
Selecione o campo abaixo do cabeçalho Texto do produto e digite o texto de marketing para este produto.
Confira um exemplo de valores de entrada e saída para essa solicitação:
Produto: Texto do produto:
Tênis antigo Vamos lá! Esses tênis têm um visual icônico e uma paleta de cores única, além de oferecer estilo e funcionalidade como nenhum outro tênis.
Blusa de moletom supermacia Fique aquecido e estiloso com nosso novo moletom unissex. Feito 100% de algodão, este moletom é macio e confortável para usar o dia todo. O interior semi-pintado vai manter você aquecido até nos dias mais frios.
(Opcional) Para importar exemplos de um arquivo:
No canto superior direito da tabela de exemplos, clique em Ações > Importar exemplos.
Na caixa de diálogo, selecione um arquivo CSV ou Google Planilhas no Google Drive ou faça upload de um arquivo do seu computador.
Na caixa de diálogo de exemplos de importação, escolha quais colunas importar e quais deixar de fora. A caixa de diálogo também permite especificar qual coluna de dados é importada para qual coluna da tabela no comando estruturado.
Etapa 3: testar o comando
Depois de ter os exemplos que mostram ao modelo o que você quer, teste o comando com uma nova entrada na tabela Test your prompt na parte de baixo.
Por exemplo, você pode inserir algo como Vintage baseball cap na coluna de entrada, clicar no botão spark Run ou pressionar Enter e conferir o que o modelo gera.
Confira como os exemplos são enviados para o modelo
Por trás dos bastidores, o Google AI Studio constrói uma solicitação combinando as instruções com os exemplos fornecidos. À medida que você adiciona mais exemplos, eles são adicionados ao texto enviado ao modelo. Dependendo do tamanho dos exemplos, você pode começar a atingir o limite de tokens do modelo. Todos os modelos de IA generativa têm um limite de token, que é o comprimento máximo do texto que eles podem aceitar como entrada.
Etapa 4: próximas etapas
Quando estiver satisfeito com o comando, salve o projeto no Google Drive clicando no botão Salvar ou exporte-o para o código clicando no botão Receber código.
Você também pode exportar os exemplos de poucos cliques para um arquivo CSV ou uma planilha do Google. Clique em Exportar exemplos no menu Ação para exportar seus exemplos.
Leitura adicional
Se você já quiser começar a programar, consulte os tutoriais de início rápido da API.
Para saber como criar comandos melhores, consulte as Diretrizes de design de comandos.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-01-10 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_53.txt ---

URL: https://ai.google.dev/gemini-api/docs/learnlm

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Android (no dispositivo)
Extensões do Firebase
Modelos geradores
Guia de início rápido do Google AI Studio
LearnLM
Migrar para o Cloud
Autenticação OAuth
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
LearnLM
Nesta página
Exemplos de instruções do sistema
Preparação para testes
Ensinar um conceito
Alteração de nível
Orientar um estudante em uma atividade de aprendizagem
Ajuda escolar
A seguir
Feedback
O LearnLM é um modelo experimental específico para tarefas que foi treinado para se alinhar aos princípios da ciência de aprendizagem ao seguir instruções do sistema para casos de uso de ensino e aprendizagem (por exemplo, ao fornecer ao modelo uma instrução do sistema como "Você é um tutor especialista"). Quando recebe instruções específicas do sistema de aprendizado, o LearnLM pode:
Inspirar o aprendizado ativo:permita a prática e a luta saudável com feedback oportuno.
Gerenciar a carga cognitiva:apresentar informações relevantes e bem estruturadas em várias modalidades.
Adaptação ao aluno:ajuste dinâmico de acordo com as metas e necessidades, com base em materiais relevantes
Estimular a curiosidade:inspire o engajamento para motivar os alunos ao longo da jornada de aprendizado.
Aprofundamento da metacognição:planejar, monitorar e ajudar o estudante a refletir sobre o progresso
O LearnLM é um modelo experimental disponível no AI Studio.
Exemplos de instruções do sistema
As seções a seguir fornecem exemplos que você pode testar com o LearnLM no AI Studio. Cada exemplo oferece:
Um exemplo de instrução do sistema que pode ser copiado
Exemplo de comando de usuário para copiar
Quais princípios de aprendizagem o exemplo tem como alvo
Preparação para testes
Esta instrução do sistema é para um tutor de IA ajudar os alunos a se prepararem para um teste.
Instrução do sistema:
You are a tutor helping a student prepare for a test. If not provided by the
student, ask them what subject and at what level they want to be tested on.
Then,

*   Generate practice questions. Start simple, then make questions more
    difficult if the student answers correctly.
*   Prompt the student to explain the reason for their answer choice. Do not
    debate the student.
*   **After the student explains their choice**, affirm their correct answer or
    guide the student to correct their mistake.
*   If a student requests to move on to another question, give the correct
    answer and move on.
*   If the student requests to explore a concept more deeply, chat with them to
    help them construct an understanding.
*   After 5 questions ask the student if they would like to continue with more
    questions or if they would like a summary of their session. If they ask for
    a summary, provide an assessment of how they have done and where they should
    focus studying.
Comando do usuário:
Help me study for a high school biology test on ecosystems
Princípios da ciência da aprendizagem:
Adaptabilidade:o modelo ajusta a complexidade das perguntas.
Aprendizado ativo:o modelo estimula o estudante a tornar o pensamento visível.
Ensinar um conceito
Esta instrução do sistema é para um tutor de IA amigável e prestativo ensinar novos conceitos a um estudante.
Instrução do sistema:
Be a friendly, supportive tutor. Guide the student to meet their goals, gently
nudging them on task if they stray. Ask guiding questions to help your students
take incremental steps toward understanding big concepts, and ask probing
questions to help them dig deep into those ideas. Pose just one question per
conversation turn so you don't overwhelm the student. Wrap up this conversation
once the student has shown evidence of understanding.
Comando do usuário:
Explain the significance of Yorick's skull in "Hamlet".
Princípios da ciência da aprendizagem:
Aprendizagem ativa:o tutor faz perguntas de recordação e interpretação alinhadas às metas do aluno e incentiva os alunos a se envolver.
Adaptabilidade:o tutor ajuda ativamente o aprendiz a passar do estado atual para a meta.
Estimular a curiosidade:o tutor adota uma abordagem baseada em recursos que se baseia no conhecimento e interesse prévio do estudante.
Alteração de nível
Este exemplo instrui o modelo a reescrever o texto fornecido para que o conteúdo e a linguagem correspondam melhor às expectativas instrucionais dos estudantes em uma série específica, preservando o estilo e o tom originais do texto.
Instrução do sistema:
Rewrite the following text so that it would be easier to read for a student in
the given grade. Simplify the most complex sentences, but stay very close to the
original text and style. If there is quoted text in the original text,
paraphrase it in the simplified text and drop the quotation marks. The goal is
not to write a summary, so be comprehensive and keep the text almost as long.
Comando do usuário:
Rewrite the following text so that it would be easier to read for a student in
4th grade.

New York, often called New York City or NYC, is the most populous city in the
United States, located at the southern tip of New York State on one of the
world's largest natural harbors. The city comprises five boroughs, each
coextensive with a respective county.
Princípios da ciência da aprendizagem:
Adaptabilidade:corresponde o conteúdo ao nível do aluno.
Orientar um estudante em uma atividade de aprendizagem
Esta instrução do sistema é para um tutor de IA guiar os alunos em uma atividade de aprendizado específica: usar um protocolo de leitura detalhada estabelecido para praticar a análise de um texto de fonte primária. Aqui, um desenvolvedor escolheu combinar o Discurso de Gettysburg com o protocolo "4 A's", mas ambos os elementos podem ser alterados.
Instrução do sistema:
Be an excellent tutor for my students to facilitate close reading and analysis
of the Gettysburg Address as a primary source document. Begin the conversation
by greeting the student and explaining the task.

In this lesson, you will take the student through "The 4 A's." The 4 A's
requires students to answer the following questions about the text:

*   What is one part of the text that you **agree** with? Why?
*   What is one part of the text that you want to **argue** against? Why?
*   What is one part of the text that reveals the author's **assumptions**? Why?
*   What is one part of the text that you **aspire** to? Why?

Invite the student to choose which of the 4 A's they'd like to start with, then
direct them to quote a short excerpt from the text. After, ask a follow up
question to unpack their reasoning why they chose that quote for that A in the
protocol. Once the student has shared their reasoning, invite them to choose
another quote and another A from the protocol. Continue in this manner until the
student completes the 4 A's, then invite them to reflect on the process.

Only display the full text of the Gettysburg address if the student asks.
Comando do usuário:
hey
Princípios da ciência da aprendizagem:
Aprendizagem ativa:o tutor envolve o aluno em atividades para analisar conteúdo e aplicar habilidades.
Carga cognitiva:o tutor orienta o aluno em uma tarefa complexa passo a passo.
Aprofundamento da metacognição:o tutor incentiva o estudante a refletir sobre o progresso, os pontos fortes e as oportunidades de crescimento.
Ajuda escolar
Esta instrução do sistema é para um tutor de IA ajudar os estudantes com problemas específicos de dever de casa.
Instruções do sistema:
You are an expert tutor assisting a student with their homework. If the student
provides a homework problem, ask the student if they want:

*   The answer: if the student chooses this, provide a structured, step-by-step
    explanation to solve the problem.
*   Guidance: if the student chooses this, guide the student to solve their
    homework problem rather than solving it for them.
*   Feedback: if the student chooses this, ask them to provide their current
    solution or attempt. Affirm their correct answer even if they didn't show
    work or give them feedback to correct their mistake.

Always be on the lookout for correct answers (even if underspecified) and accept
them at any time, even if you asked some intermediate question to guide them. If
the student jumps to a correct answer, do not ask them to do any more work.
Comando do usuário:
In a box of pears, the probability of a pear being rotten is 20%. If 3
pears were rotten, find the total number of pears in the box.
Como alternativa, tente enviar uma foto de um problema de dever de casa.
Princípios da ciência da aprendizagem:
Aprendizagem ativa:o tutor incentiva o aluno a aplicar conceitos em vez de dar a resposta.
Aprofundamento da metacognição:o tutor fornece feedback claro e construtivo ao aluno quando apropriado.
Gerenciar a carga cognitiva:o tutor fornece a quantidade certa de feedback no momento certo.
A seguir
Teste o LearnLM no AI Studio.
Feedback
Você pode enviar feedback sobre o LearnLM usando nosso formulário de feedback.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_54.txt ---

URL: https://ai.google.dev/gemini-api/docs/migrate-to-cloud

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Android (no dispositivo)
Extensões do Firebase
Modelos geradores
Guia de início rápido do Google AI Studio
LearnLM
Migrar para o Cloud
Autenticação OAuth
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Crie com o Gemini no Google Cloud
Nesta página
Migrar do Gemini no Google AI para a Vertex AI
Excluir chaves de API não usadas
Próximas etapas
Se você é iniciante no Gemini, usar os guias de início rápido é a maneira mais rápida de começar.
No entanto, à medida que suas soluções de IA generativa se desenvolverem, talvez você precise de uma plataforma para criar e implantar aplicativos e soluções de IA generativa de ponta a ponta. O Google Cloud oferece um ecossistema abrangente de ferramentas para permitir que os desenvolvedores aproveitem o poder da IA generativa, desde os estágios iniciais de desenvolvimento de aplicativos até a implantação e hospedagem de aplicativos e gerenciamento de dados complexos em escala.
A plataforma da Vertex AI do Google Cloud oferece um conjunto de ferramentas de MLOps que simplificam o uso, a implantação e o monitoramento de modelos de IA para eficiência e confiabilidade. Além disso, as integrações com bancos de dados, ferramentas de DevOps, geração de registros, monitoramento e IAM fornecem uma abordagem holística para gerenciar todo o ciclo de vida da IA generativa.
A seguinte tabela resume as principais diferenças entre a IA do Google e a Vertex AI para ajudar você a decidir qual é a opção ideal para seu caso de uso:
Recursos API Gemini da IA do Google API Gemini da Vertex AI
Modelos do Gemini Gemini 2.0 Flash, Gemini 2.0 Flash-Lite, Gemini 1.5 Flash e Gemini 1.5 Pro Gemini 2.0 Flash, Gemini 2.0 Flash-Lite, Gemini 1.5 Flash, Gemini 1.5 Pro, Gemini 1.0 Pro, Gemini 1.0 Pro Vision, Gemini 1.0 Ultra e Gemini 1.0 Ultra Vision
Inscrever-se Conta do Google Conta do Google Cloud (com contrato e faturamento de termos)
Authentication Chave de API Conta de serviço do Google Cloud
Playground de interface do usuário o Google AI Studio; Vertex AI Studio
API e SDK SDKs de servidor e cliente para dispositivos móveis/Web
Servidor: Python, Node.js, Go, Dart, ABAP
Cliente para dispositivos móveis/Web: Android (Kotlin/Java), Swift, Web, Flutter
SDKs de servidor e cliente para dispositivos móveis/Web
Servidor: Python, Node.js, Go, Java, ABAP
Cliente para dispositivos móveis/Web (pela Vertex AI para Firebase): Android (Kotlin/Java), Swift, Web, Flutter
Uso sem custo da API e do SDK Sim, quando aplicável Crédito de US$ 300 do Google Cloud para novos usuários
Cota (solicitações por minuto) Varia de acordo com o modelo e o plano de preços (consulte as informações detalhadas) Varia de acordo com o modelo e a região (consulte as informações detalhadas)
Suporte empresarial Não Chave de criptografia do cliente
Nuvem privada virtual
Residência de dados
Transparência no acesso
Infraestrutura escalonável para hospedagem de aplicativos
Bancos de dados e armazenamento de dados
MLOps Não MLOps completas na Vertex AI (exemplos: avaliação de modelo, monitoramento de modelos, registro de modelos)
Para saber quais produtos, frameworks e ferramentas são a melhor opção para criar seu aplicativo de IA generativa no Google Cloud, consulte Criar um aplicativo de IA generativa no Google Cloud.
Migrar do Gemini no Google AI para a Vertex AI
Se o seu aplicativo usa as APIs Google AI Gemini, você vai precisar migrar para as APIs Vertex AI Gemini do Google Cloud.
Ao migrar:
É possível usar seu projeto atual do Google Cloud (o mesmo usado para gerar a chave de API) ou criar um novo projeto do Google Cloud.
As regiões compatíveis podem ser diferentes entre o Google AI Studio e a Vertex AI. Consulte a lista de regiões compatíveis com IA generativa no Google Cloud.
Todos os modelos criados no Google AI Studio precisam ser treinados novamente na Vertex AI.
O SDK da IA generativa do Google oferece uma interface unificada para o Gemini 2.0 pela API Gemini para desenvolvedores e pela Vertex AI. Com poucas exceções, o código que é executado em uma plataforma será executado nas duas.
Se você quiser chamar a API Gemini diretamente de um app para dispositivos móveis ou da Web em produção, migre para usar a Vertex AI nos SDKs de cliente do Firebase (disponível para apps Swift, Android, Web e Flutter). Esses SDKs de cliente oferecem opções de segurança essenciais e outros recursos para apps de produção para dispositivos móveis e Web.
Excluir chaves de API não usadas
Se você não precisar mais usar sua chave da API Gemini da IA do Google, siga as práticas recomendadas de segurança e exclua a chave.
Para excluir uma chave de API:
Abra a página Credenciais da API Google Cloud.
Encontre a chave de API que você quer excluir e clique no ícone Ações.
Selecione Excluir chave de API.
No modal Excluir credencial, selecione Excluir.
A remoção de uma chave de API leva alguns minutos para ser propagada. Após o término da propagação, todo tráfego que usar a chave de API excluída será recusado.
Importante: se você tiver removido uma chave que ainda estava sendo usada em produção e precisar recuperá-la, consulte Cancelar exclusão de chaves de API de serviços Beta da gcloud (link em inglês).
Próximas etapas
Consulte a Visão geral da IA generativa na Vertex AI para saber mais sobre as soluções de IA generativa na Vertex AI.
Saiba mais sobre a API Vertex AI Gemini.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-26 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_55.txt ---

URL: https://ai.google.dev/gemini-api/docs/oauth

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Android (no dispositivo)
Extensões do Firebase
Modelos geradores
Guia de início rápido do Google AI Studio
LearnLM
Migrar para o Cloud
Autenticação OAuth
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Guia de início rápido do OAuth
Nesta página
Objetivos
Pré-requisitos
Configurar seu projeto na nuvem
1. Ativar a API
2. Configurar a tela de permissão OAuth
3. Autorizar credenciais para um aplicativo para computador
Configurar as credenciais padrão do aplicativo
Curl
A maneira mais fácil de fazer a autenticação na API Gemini é configurar uma chave de API, conforme descrito no Guia de início rápido da API Gemini. Se você precisar de controles de acesso mais rigorosos, use o OAuth. Este guia vai ajudar você a configurar a autenticação com o OAuth.
Este guia usa uma abordagem de autenticação simplificada que é adequada para um ambiente de teste. Para um ambiente de produção, saiba mais sobre autenticação e autorização antes de escolher as credenciais de acesso adequadas para o app.
Objetivos
Configurar o projeto do Cloud para OAuth
Configurar o application-default-credentials
Gerenciar credenciais no seu programa em vez de usar gcloud auth
Pré-requisitos
Para executar este guia de início rápido, você precisa de:
Um projeto do Google Cloud.
Uma instalação local da CLI gcloud
Configurar seu projeto na nuvem
Para concluir este guia de início rápido, primeiro você precisa configurar seu projeto do Cloud.
1. Ativar a API
Antes de usar as APIs do Google, você precisa ativá-las em um projeto do Google Cloud.
No console do Google Cloud, ative a API Google Language Transformer.
Ativar a API
2. Configurar a tela de permissão OAuth
Em seguida, configure a tela de consentimento do OAuth do projeto e adicione você mesmo como um usuário de teste. Se você já concluiu esta etapa para seu projeto do Cloud, pule para a próxima seção.
No console do Google Cloud, acesse Menu > > Visão geral.
Acesse o
Preencha o formulário de configuração do projeto e defina o tipo de usuário como Externo na seção Público-alvo.
Preencha o restante do formulário, aceite os termos da Política de dados do usuário e clique em Criar.
Por enquanto, você pode pular a adição de escopos e clicar em Salvar e continuar. No futuro, quando você criar um app para uso fora da sua organização do Google Workspace, será necessário adicionar e verificar os escopos de autorização necessários.
Adicionar usuários de teste:
Navegue até o do .
Em Test users, clique em Add users.
Insira seu endereço de e-mail e os outros usuários de teste autorizados. Depois, clique em Salvar.
3. Autorizar credenciais para um aplicativo para computador
Para fazer a autenticação como usuário final e acessar os dados do usuário no app, crie um ou mais IDs do cliente OAuth 2.0. Um ID do cliente é usado para identificar um único app nos servidores OAuth do Google. Se o app for executado em várias plataformas, crie um ID do cliente separado para cada plataforma.
No console do Google Cloud, acesse Menu > > Clientes.
Acessar "Credenciais"
Clique em Criar cliente.
Clique em Tipo de aplicativo > App para computador.
No campo Nome, digite um nome para a credencial. Esse nome é mostrado apenas no console do Google Cloud.
Clique em Criar. A tela do cliente OAuth criado aparece, mostrando o novo ID e a chave secreta do cliente.
Clique em OK. A credencial recém-criada aparece em IDs do cliente OAuth 2.0.
Clique no botão de download para salvar o arquivo JSON. Ela será salva como client_secret_<identifier>.json, renomeada como client_secret.json e movida para o diretório de trabalho.
Configurar as credenciais padrão do aplicativo
Para converter o arquivo client_secret.json em credenciais utilizáveis, transmita o local do argumento --client-id-file do comando gcloud auth application-default login.
gcloud auth application-default login \
    --client-id-file=client_secret.json \
    --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'
A configuração simplificada do projeto neste tutorial aciona uma caixa de diálogo "O Google não verificou este app". Isso é normal. Escolha "Continuar".
Isso coloca o token resultante em um local conhecido para que ele possa ser acessado por gcloud ou pelas bibliotecas de cliente.
Observação: se estiver executando no Colab, inclua --no-browser e siga cuidadosamente as instruções que aparecem (não clique no link). Verifique também se o gcloud --version local é a versão mais recente para corresponder ao Colab.
gcloud auth application-default login 
    --no-browser
    --client-id-file=client_secret.json 
    --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'
Depois de definir as credenciais padrão do aplicativo (ACD), as bibliotecas de cliente na maioria dos idiomas precisam de pouca ou nenhuma ajuda para encontrá-las.
Curl
A maneira mais rápida de testar se isso está funcionando é usá-lo para acessar a API REST usando o curl:
access_token=$(gcloud auth application-default print-access-token)
project_id=<MY PROJECT ID>
curl -X GET https://generativelanguage.googleapis.com/v1/models \
    -H 'Content-Type: application/json' \
    -H "Authorization: Bearer ${access_token}" \
    -H "x-goog-user-project: ${project_id}" | grep '"name"'
Python
No Python, as bibliotecas de cliente precisam encontrá-las automaticamente:
pip install google-generativeai
Um script mínimo para testar pode ser:
import google.generativeai as genai

print('Available base models:', [m.name for m in genai.list_models()])
Próximas etapas
Se isso funcionar, você poderá tentar a recuperação semântica nos dados de texto.
Gerenciar credenciais por conta própria [Python]
Em muitos casos, o comando gcloud não está disponível para criar o token de acesso com o ID do cliente (client_secret.json). O Google fornece bibliotecas em várias linguagens para que você possa gerenciar esse processo no seu app. Esta seção demonstra o processo em Python. Há exemplos equivalentes desse tipo de procedimento, para outros idiomas, disponíveis na documentação da API Drive.
1. Instalar as bibliotecas necessárias
Instale a biblioteca de cliente do Google para Python e a biblioteca de cliente Gemini.
pip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib
pip install google-generativeai
2. Gravar o gerenciador de credenciais
Para minimizar o número de vezes que você precisa clicar nas telas de autorização, crie um arquivo chamado load_creds.py no diretório de trabalho para armazenar em cache um arquivo token.json que possa ser reutilizado mais tarde ou atualizado se expirar.
Comece com o código abaixo para converter o arquivo client_secret.json em um token que pode ser usado com genai.configure:
import os.path

from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow

SCOPES = ['https://www.googleapis.com/auth/generative-language.retriever']

def load_creds():
    """Converts `client_secret.json` to a credential object.

    This function caches the generated tokens to minimize the use of the
    consent screen.
    """
    creds = None
    # The file token.json stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'client_secret.json', SCOPES)
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
    return creds
3. Programar seu programa
Agora crie o script.py:
import pprint
import google.generativeai as genai
from load_creds import load_creds

creds = load_creds()

genai.configure(credentials=creds)

print()
print('Available base models:', [m.name for m in genai.list_models()])
4. Executar o programa
No diretório de trabalho, execute o exemplo:
python script.py
Na primeira vez que você executar o script, ele vai abrir uma janela do navegador e solicitar a autorização de acesso.
Se você ainda não estiver conectado à sua Conta do Google, será solicitado que você faça login. Se você tiver feito login em várias contas, selecione a conta definida como "Conta de teste" ao configurar seu projeto.
Observação: a configuração simplificada do projeto neste tutorial aciona uma caixa de diálogo "O Google não verificou este app". Isso é normal. Escolha "Continuar".
As informações de autorização são armazenadas no sistema de arquivos. Assim, na próxima vez que você executar o código de exemplo, não será necessário fazer a autorização.
Você configurou a autenticação.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_56.txt ---

URL: https://ai.google.dev/gemini-api/docs/gemini-for-research

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Acelere a descoberta com o Gemini for Research
Gerar uma chave da API Gemini
Os modelos do Gemini podem ser usados para avançar na pesquisa de base em várias disciplinas. Confira algumas maneiras de usar o Gemini para pesquisar:
Ajuste de detalhes: é possível ajustar os modelos do Gemini para várias modalidades e avançar na pesquisa. Saiba mais.
Analisar e controlar as saídas do modelo: para uma análise mais detalhada, é possível examinar um candidato de resposta gerado pelo modelo usando ferramentas como Logprobs e CitationMetadata. Também é possível configurar opções para geração de modelos e saídas, como responseSchema, topP e topK. Saiba mais.
Entradas multimodais: o Gemini pode processar imagens, áudio e vídeos, permitindo uma multiplicidade de direções de pesquisa interessantes. Saiba mais.
Capacidades de contexto longo: o Gemini 1.5 Flash vem com uma janela de contexto de um milhão de tokens, e o Gemini 1.5 Pro vem com uma janela de contexto de dois milhões de tokens. Saiba mais.
Cresça com o Google: acesse rapidamente os modelos do Gemini pela API e pelo Google AI Studio para casos de uso de produção. Se você está procurando uma plataforma baseada no Google Cloud, a Vertex AI pode oferecer mais infraestrutura de suporte.
Para apoiar a pesquisa acadêmica e impulsionar pesquisas de ponta, o Google oferece acesso a créditos da API Gemini para cientistas e pesquisadores acadêmicos pelo Programa Acadêmico Gemini.
Comece a usar o Gemini
A API Gemini e o Google AI Studio ajudam você a começar a trabalhar com os modelos mais recentes do Google e transformar suas ideias em aplicativos que podem ser escalonados.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="How large is the universe?",
)

print(response.text)
Acadêmicos em destaque
"Nossa pesquisa investiga o Gemini como um modelo de linguagem visual (VLM, na sigla em inglês) e os comportamentos de agentes em diversos ambientes, considerando a robustez e a segurança. Até agora, avaliamos a robustez do Gemini em relação a distrações, como janelas pop-up quando os agentes de VLM realizam tarefas de computador, e aproveitamos o Gemini para analisar interação social, eventos temporais e fatores de risco com base no vídeo."
"O Gemini Pro e o Flash, com sua janela de contexto longa, têm nos ajudado no OK-Robot, nosso projeto de manipulação móvel de vocabulário aberto. O Gemini permite consultas e comandos complexos em linguagem natural na "memória" do robô: neste caso, observações anteriores feitas pelo robô durante uma operação de longa duração. Mahi Shafiullah e eu também estamos usando o Gemini para decompor tarefas em código que o robô pode executar no mundo real."
Programa acadêmico do Gemini
Pesquisadores acadêmicos qualificados (como professores, funcionários e estudantes de doutorado) nos países com suporte podem se inscrever para receber créditos da API Gemini e limites de taxa mais altos para projetos de pesquisa. Esse suporte permite uma maior taxa de transferência para experimentos científicos e pesquisas avançadas.
Estamos particularmente interessados nas áreas de pesquisa da seção a seguir, mas aceitamos inscrições de diversas disciplinas científicas:
Avaliações e comparativos: métodos de avaliação aprovados pela comunidade que podem fornecer um indicador de desempenho forte em áreas como factualidade, segurança, cumprimento de instruções, raciocínio e planejamento.
Acelerar a descoberta científica para beneficiar a humanidade: possíveis aplicações da IA em pesquisas científicas interdisciplinares, incluindo áreas como doenças raras e negligenciadas, biologia experimental, ciência de materiais e sustentabilidade.
Incorporação e interações: uso de modelos de linguagem grandes para investigar novas interações nos campos da IA incorporada, interações ambientais, robótica e interação humano-computador.
Recursos emergentes: conhecer novos recursos de agentes necessários para melhorar o raciocínio e o planejamento e como os recursos podem ser expandidos durante a inferência (por exemplo, usando o Gemini Flash).
Interação e compreensão multimodais: identificar lacunas e oportunidades para modelos de base multimodais para análise, raciocínio e planejamento em várias tarefas.
Elegibilidade: somente indivíduos (professores, pesquisadores ou equivalentes) afiliados a uma instituição acadêmica válida ou a uma organização de pesquisa acadêmica podem se inscrever. O acesso e os créditos da API serão concedidos e removidos a critério do Google. Analisamos as inscrições mensalmente.
Começar a pesquisar com a API Gemini
Faça sua inscrição agora
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-01 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_57.txt ---

URL: https://ai.google.dev/gemini-api/tutorials/web-app

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Aplicativo de chat
Assistente de código
Gerador de código do Flutter
Pesquisa de conteúdo
Agente de exploração de dados
Assistente de redação
Revisor do Apresentações Google
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Criar um app da Web de chat com IA
Nesta página
Executar o aplicativo de exemplo
Fazer o download das dependências do projeto
consiga uma chave de API
Fazer o download do código
Configurar o servidor de back-end
Instalar as dependências do front-end
Testar o aplicativo
Como funciona
Este tutorial mostra como usar a API Gemini em um aplicativo da Web com um cliente React. O aplicativo oferece três implementações de back-end, permitindo que os usuários escolham entre um servidor Python Flask, Node.js ou Go.
Um exemplo de aplicativo está disponível para download no GitHub:
App de chat da API Gemini
É possível usar a API Gemini para criar um chatbot, assistente pessoal, resumidor de texto ou qualquer outro caso de uso que dependa da funcionalidade de conversão de texto em texto de modelos de linguagem grandes.
Python
Node.js
Go
Executar o aplicativo de exemplo
Estas instruções orientam você no processo de download do aplicativo de chat exemplo, adição de uma chave de API Gemini, configuração do cliente de front-end e do servidor de back-end do Python e execução do aplicativo localmente.
Fazer o download das dependências do projeto
O aplicativo requer o Node.js v18 ou mais recente, o npm e o Python 3.11 ou mais recente. Use os links a seguir para fazer o download do Node.js e do Python:
Node.js
Python
Depois de fazer o download do Node, npm ou Python, talvez seja necessário reiniciar o terminal para que o sistema reconheça as dependências.
consiga uma chave de API
Você precisa de uma chave de API Google Gemini para executar o projeto, que pode ser conseguida na página de configuração da API Google Gemini.
Conseguir uma chave da API Gemini no Google AI Studio
Fazer o download do código
O app de chat de exemplo do Gemini está hospedado no GitHub. Nesta seção, você vai fazer o download do aplicativo clonando o repositório do GitHub.
Navegue até o diretório de trabalho e clone o repositório do Git usando o comando abaixo:
git clone https://github.com/google-gemini/example-chat-app
Navegue até o diretório raiz do projeto:
cd example-chat-app/
Configurar o servidor de back-end
O back-end do Python usa o Flask para interagir com a API Gemini. Nesta seção, você vai criar um ambiente virtual, instalar as dependências no arquivo requirements.txt, adicionar sua chave de API e executar o servidor Python.
Navegue até o diretório do servidor Python:
cd server-python
Crie e ative um novo ambiente virtual:
python3 -m venv venv
. venv/bin/activate
Instale as dependências obrigatórias do pacote Python:
pip install -r requirements.txt
Crie um arquivo de variáveis de ambiente copiando o arquivo .env.example. Esse arquivo vai conter sua chave de API:
cp .env.example .env
Adicione a chave de API ao arquivo .env:
# Get your Gemini API key from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY= 
YOUR_API_KEY
PORT=9000
Execute o servidor Python:
python3 app.py
O servidor vai usar localhost:9000. O fechamento do terminal vai encerrar o servidor. Portanto, mantenha a tela atual do terminal aberta e conclua a próxima seção em uma nova tela ou guia do terminal.
Instalar as dependências do front-end
O aplicativo usa o React para criar a interface do usuário e usa o Vite como o servidor do cliente. Nesta seção, você vai instalar as dependências do front-end e executar o servidor do cliente.
Inicie uma nova tela do terminal e navegue até o diretório do cliente React (client-react):
cd ../client-react/
Instale as dependências do app de front-end:
npm install
Execute o cliente React:
npm run start
O site será hospedado em localhost:3000.
Testar o aplicativo
Depois de executar o servidor do cliente, é possível acessar o aplicativo em http://localhost:3000/. Você pode usar o aplicativo de chat e a opção Stream Response para transmitir respostas ou receber respostas em um único bloco.
O aplicativo vai funcionar enquanto localhost:3000 e localhost:9000 permanecerem abertos.
Como funciona
Esta seção fornece informações mais detalhadas sobre os principais componentes do aplicativo de chat Gemini. Confira o código em app.py.
Chave de API e autenticação
Para configurar a chave de API, defina o parâmetro api_key em genai.configure. A chave da API (GOOGLE_API_KEY) é armazenada no arquivo .env, que foi criado ao configurar o back-end.
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
Aviso: para reduzir o risco de vazamento de chaves, não fixe a chave de API diretamente no código do aplicativo.
Seleção de modelos
O modelo é especificado com o método genai.GenerativeModel. O exemplo de aplicativo usa o Gemini 1.5 Flash.
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash"
)
Você também pode testar os seguintes modelos do Gemini:
Gemini 1.5 Flash 8B: gemini-1.5-flash-8b
Gemini 1.5 Pro: Gemini-1.5-pro
Para mais informações sobre as variantes dos modelos do Gemini, consulte Modelos do Gemini.
Processamento de dados
O aplicativo recebe solicitações do usuário e envia solicitações POST para os endpoints /chat ou /stream. A solicitação precisa ser um payload JSON contendo uma solicitação do usuário e um histórico de conversa opcional. Os endpoints /chat e /stream determinam se a saída é transmitida ou retornada como uma resposta completa.
Os dados de entrada são processados pelo seguinte código:
data = request.json
msg = data.get('chat', '')
chat_history = data.get('history', [])

# Start a chat session with the model using the provided history.
chat_session = model.start_chat(history=chat_history)
Resposta do chat
A função de resposta do chat retorna uma resposta gerada por IA em um único bloco completo de texto. A função de resposta do chat transmite a solicitação do usuário ao modelo sem adicionar a flag stream:
response = chat_session.send_message(msg)
A função retorna um objeto JSON com a resposta gerada pela IA na chave "text":
return {"text": response.text}
Composição da resposta
A função de resposta de fluxo retorna partes da resposta conforme ela é gerada. Isso resulta em um fluxo de texto retornado ao usuário, em vez de um único bloco de texto. A função de resposta do chat transmite a solicitação do usuário ao modelo com a flag stream. A função prepara partes da resposta geral:
response = chat_session.send_message(msg, stream=True)

for chunk in response:
   yield f"{chunk.text}"
A função retorna um objeto Response do Flask que transmite as respostas geradas pela IA:
return Response(stream_with_context(generate()), mimetype="text/event-stream")
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-19 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_58.txt ---

URL: https://ai.google.dev/gemini-api/tutorials/pipet-code-agent

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Aplicativo de chat
Assistente de código
Gerador de código do Flutter
Pesquisa de conteúdo
Agente de exploração de dados
Assistente de redação
Revisor do Apresentações Google
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Criar um assistente de código de IA com o agente do Pipet Code
Nesta página
Configurar o projeto
Instalar os pré-requisitos
Clonar e configurar o projeto
Configurar e testar a extensão
Modificar comando
Criar novo comando
Integrar o novo comando
Testar o novo comando
Escrever código pode ser gratificante e satisfatório, mas transformar seu código de funcionando em apresentável para colegas é frequentemente uma tarefa. Os modelos generativos de inteligência artificial podem ajudar você a adicionar comentários de código, encontrar erros antes dos revisores humanos e realizar várias outras tarefas para facilitar seu fluxo de trabalho de programação.
Observação: este exemplo usa o SDK para JavaScript legado. Para novos aplicativos, use o SDK da IA generativa do Google para TypeScript e JavaScript.
Neste tutorial, mostramos como estender o Pipet Code Agent, uma ferramenta de assistência de código com tecnologia de IA criada pela equipe de relações com desenvolvedores de IA do Google. Esse projeto de código aberto é uma extensão do Visual Studio Code (VS Code) da Microsoft que ajuda você a cuidar de algumas das tarefas importantes, mas menos divertidas, de programação, como comentar seu código, encontrar erros e sugerir melhorias. A extensão envia solicitações de assistência de programação para a API Gemini e incorpora as respostas à janela de edição de código.
É possível modificar o Pipet para que essas funções funcionem melhor para você ou criar novos comandos para oferecer melhor suporte ao seu fluxo de desenvolvimento.
Para conferir uma visão geral em vídeo do projeto e como estendê-lo, incluindo insights dos criadores, acesse AI Code Assistant: Build with Google AI. Caso contrário, você pode começar a estender o projeto seguindo as instruções abaixo.
Configurar o projeto
Estas instruções mostram como configurar o projeto Pipet Code Agent para desenvolvimento e teste. As etapas gerais são instalar alguns softwares pré-requisitos, definir algumas variáveis de ambiente, clonar o projeto do repositório de código e executar a instalação de configuração.
Observação: para executar o projeto, você precisa de uma chave de API Google Gemini, que pode ser conseguida na página de configuração da API Google Gemini.
Instalar os pré-requisitos
O projeto Pipet Code Agent é executado como uma extensão do Visual Studio Code da Microsoft e usa Node.js e a ferramenta npm para gerenciar pacotes e executar o aplicativo. As instruções de instalação a seguir são para uma máquina host Linux.
Para instalar o software necessário:
Instale o Visual Studio Code para sua plataforma.
Instale node e npm seguindo as instruções de instalação para sua plataforma.
Clonar e configurar o projeto
Faça o download do código do projeto e use o comando de instalação npm para fazer o download das dependências necessárias e configurar o projeto. Você precisa do software de controle de origem git para extrair o código-fonte do projeto.
Para fazer o download e configurar o código do projeto:
Clone o repositório do Git usando o comando abaixo.
git clone https://github.com/google/generative-ai-docs
Se quiser, configure seu repositório local do git para usar o checkout esparso, para que você tenha apenas os arquivos do projeto do Docs Agent.
cd generative-ai-docs/
git sparse-checkout init --cone
git sparse-checkout set examples/gemini/node/pipet-code-agent/
Navegue até o diretório raiz do projeto Pipet Code Agent.
cd generative-ai-docs/examples/gemini/node/pipet-code-agent/
Execute o comando de instalação para fazer o download das dependências e configurar o projeto:
npm install
Configurar e testar a extensão
Agora você pode testar a instalação executando o Pipet Code Agent como uma extensão de desenvolvimento no VS Code no seu dispositivo. O teste abre uma janela separada do Extension Development Host do VS Code, em que a nova extensão está disponível. Nessa nova janela, você configura a chave de API usada pela extensão para acessar a API Google Gemini.
Figura 1. Janela do host de desenvolvimento de extensões do VS Code com os comandos da extensão Pipet.
Para configurar e testar a configuração:
Inicie o aplicativo VS Code.
No VS Code, crie uma nova janela selecionando File > New Window.
Abra o projeto Pipet Code Agent selecionando File > Open Folder e a pasta pipet-code-agent/.
Abra o arquivo pipet-code-agent/package.json.
Execute a extensão no modo de depuração selecionando Run > Start Debugging. Essa etapa abre uma janela separada do Extension Development Host do VS Code.
Abra as configurações do VS Code selecionando Code > Settings > Settings.
Receba uma chave da API Gemini do Google no site do desenvolvedor de IA generativa e copie a string da chave.
Defina a chave de API como uma configuração. No campo Search Settings, digite pipet, selecione a guia User e, na configuração Google > Gemini: Api Key, clique no link Edit in settings.json e adicione sua chave da API Gemini:
"google.gemini.apiKey": "your-api-key-here"
Salve as alterações no arquivo settings.json e feche as guias de configurações.
Cuidado: trate a chave de API como uma senha e proteja-a adequadamente. Não incorpore sua chave em um código publicado publicamente.
Para testar os comandos da extensão:
Na janela Extension Development Host do VS Code, selecione qualquer código na janela do editor.
Abra a paleta de comandos selecionando Visualizar > Paleta de comandos.
Na paleta de comandos, digite Pipet e selecione um dos comandos com esse prefixo.
Modificar comando
Modificar os comandos fornecidos no Pipet Code Agent é a maneira mais simples de mudar o comportamento e os recursos da extensão. Os comandos de comentário e revisão usam uma abordagem de alguns comandos de disparo com exemplos de código e comentários para esse código, além de algumas instruções gerais para o modelo generativo de IA. Essas informações de contexto do comando orientam o modelo generativo do Gemini na formação de uma resposta. Ao mudar as instruções, exemplos ou ambos nos comandos de comentário ou revisão, você pode mudar o comportamento de cada um dos comandos atuais.
Este conjunto de instruções explica como modificar o comando review.ts mudando o texto de comando.
Para se preparar para editar o comando review.ts:
Inicie o aplicativo VS Code.
No VS Code, crie uma nova janela selecionando File > New Window.
Abra o projeto Pipet Code Agent selecionando File > Open Folder e a pasta pipet-code-agent/.
Abra pipet-code-agent/src/review.ts.
Para modificar o comportamento do comando review.ts:
No arquivo review.ts, mude o início da constante PROMPT para instruções diferentes.
const PROMPT = '
Write review comments for following code, identifying bugs and ways to improve code quality. Examples of bugs are syntax errors or typos, out of memory errors, and boundary value errors. Examples of improving code quality are reducing complexity of code, eliminating duplicate code, and ensuring other developers
are able to understand the code.
${CODE_LABEL}
...
Opcionalmente, no arquivo review.ts, adicione outro exemplo à lista de código e exemplos de revisão de código.
...
${REVIEW_LABEL}
There are duplicate lines of code in this control structure.
${CODE_LABEL}
const fixed_value = 128;
${REVIEW_LABEL}
Make sure constant names are in all capitals (FIXED_VALUE) for clarity.
';
Salve as alterações no arquivo review.ts.
Para testar o comando modificado:
Na janela do projeto da extensão Pipet do VS Code, reinicie o depurador selecionando Run > Restart Debugging.
Na janela Extension Development Host do VS Code, selecione qualquer código na janela do editor.
Abra a paleta de comandos selecionando Visualizar > Paleta de comandos.
Na paleta de comandos, digite Pipet e selecione o comando Pipet: Revise o código selecionado.
Criar novo comando
É possível estender o Pipet criando novos comandos que executam tarefas completamente novas com a API Gemini. Cada arquivo de comando (comment.ts e review.ts) é basicamente independente e inclui código para coletar texto do editor ativo, escrever um comando, se conectar à API Gemini, enviar um comando e processar a resposta.
Figura 2. Novo comando de recomendação de nome de função na janela do host de desenvolvimento da extensão do VS Code.
Este conjunto de instruções explica como criar um novo comando usando o código de um comando existente, comment.ts, como modelo.
Para criar um comando que recomende nomes para funções:
Faça uma cópia do arquivo pipet-code-agent/src/comment.ts chamado name.ts no diretório src/.
No VS Code, abra o arquivo src/name.ts.
Mude as instruções de solicitação no arquivo name.ts editando o valor PROMPT.
// Provide instructions for the AI generative model
const PROMPT = `Recommend a name for this function. Explain your
reasoning in 3 sentences or less:`;
Mude o nome da função de comando e a mensagem de informação dela.
export async function generateName() {
  vscode.window.showInformationMessage('Generating function name...');
Atualize o código de montagem do comando para incluir apenas o valor PROMPT e o texto selecionado no editor.
  // Build the full prompt using the template.
  const fullPrompt = `${PROMPT}
"
${selectedCode}
"
`;
Mude a saída da resposta para descrever o que ela está gerando.
    // update prefix to describe output
    let commentIntro = padding + commentPrefix + "Recommended name: (generated)\n";
    editBuilder.insert(selection.start, commentIntro);
    editBuilder.insert(selection.start, pyComment);
Salve as alterações no arquivo review.ts.
Integrar o novo comando
Depois de concluir o código do novo comando, você precisa integrá-lo ao resto da extensão. Atualize os arquivos extension.ts e package.json para tornar o novo comando parte da extensão e permitir que o VS Code invoque o novo comando.
Para integrar o comando name ao código da extensão:
No VS Code, abra o arquivo pipet-code-agent/src/extension.ts.
Adicione o novo arquivo de código à extensão adicionando uma nova instrução de importação.
import { generateName } from './name';
Registre o novo comando adicionando o seguinte código à função activate().
export function activate(context: vscode.ExtensionContext) {
    ...
    vscode.commands.registerCommand('pipet-code-agent.nameFunction', generateName);
}
Salve as alterações no arquivo extension.ts.
Para integrar o comando name ao pacote de extensão:
No VS Code, abra o arquivo pipet-code-agent/package.json.
Adicione o novo comando à seção commands do arquivo package.
  "contributes": {
    "commands": [
      ...
      {
        "command": "pipet-code-agent.nameFunction",
        "title": "Pipet: Name the selected function."
      }
    ],
Salve as alterações no arquivo package.json.
Testar o novo comando
Depois de programar o comando e integrá-lo à extensão, você poderá testá-lo. O novo comando só está disponível na janela Extension Development Host do VS Code, e não na janela do VS Code em que você editou o código da extensão.
Para testar o comando modificado:
Na janela do projeto da extensão Pipet do VS Code, reinicie o depurador selecionando Run > Restart Debugging, que reinicia uma janela Extension Development Host separada.
Na janela Extension Development Host do VS Code, selecione algum código na janela do editor.
Abra a paleta de comandos selecionando Visualizar > Paleta de comandos.
Na paleta de comandos, digite Pipet e selecione o comando Pipet: Name the selected function.
Outros recursos
Para mais informações sobre o projeto Pipet Code Agent, consulte o repositório de código. Se você precisar de ajuda para criar o aplicativo ou estiver procurando colaboradores de desenvolvimento, confira o servidor do Google Developers Community Discord.
Aplicativos de produção
Se você planeja implantar o Docs Agent para um grande público, saiba que o uso da API Google Gemini pode estar sujeito a limitação de taxa e outras restrições de uso. Se você está pensando em criar um aplicativo de produção com a API Gemini, como o Docs Agent, confira os serviços da Vertex AI do Google Cloud para aumentar a escalabilidade e a confiabilidade do seu app.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-24 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_59.txt ---

URL: https://ai.google.dev/gemini-api/tutorials/flutter-theme-agent

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Aplicativo de chat
Assistente de código
Gerador de código do Flutter
Pesquisa de conteúdo
Agente de exploração de dados
Assistente de redação
Revisor do Apresentações Google
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Criar um gerador de código de IA do Flutter com o Gemini
Nesta página
Configurar o projeto
Instalar os pré-requisitos
Clonar e configurar o projeto
Configurar e testar a extensão
Modificar comando
Criar novo comando
Integrar o novo comando
Testar o novo comando
Observação: este exemplo de aplicativo usa o SDK do JavaScript legado. Para novos aplicativos, use o SDK da IA generativa do Google para TypeScript e JavaScript.
Crie uma ferramenta de assistente de programação para gerar interfaces do usuário do Flutter ou qualquer componente de código que você queira iterar rapidamente. Criar interfaces do usuário pode ser divertido e gratificante, mas também é trabalhoso. Não se trata apenas de corrigir o código, mas também de definir a aparência e a sensação e fazer com que sua equipe concorde em uma direção de design.
Este tutorial mostra como estender o Flutter Theme Agent, uma ferramenta de assistência de código com tecnologia de IA criada pela equipe de relações com desenvolvedores do Flutter no Google. Esse projeto de código aberto é uma extensão do Visual Studio Code (VS Code) da Microsoft que gera componentes específicos de um tema do Flutter ou do objeto ThemeData, incluindo esquemas de cores, estilos de texto e estilos de botões. Você pode modificar o projeto para que essas funções funcionem melhor para você ou criar novos comandos para oferecer melhor suporte ao fluxo de trabalho de desenvolvimento.
Para conferir uma visão geral em vídeo do projeto e como ele pode ser estendido, incluindo insights dos criadores, acesse AI Flutter Code Generator: Build with Google AI. Caso contrário, você pode começar a estender o projeto seguindo as instruções abaixo.
Figura 1. Flutter Theme Agent sendo executado na janela do host de desenvolvimento da extensão do VS Code.
Configurar o projeto
Estas instruções mostram como configurar o projeto do Flutter Theme Agent para desenvolvimento e teste. As etapas gerais são instalar alguns softwares de pré-requisito, definir algumas variáveis de ambiente, clonar o projeto do repositório de código e executar a instalação de configuração.
Observação: você precisa de uma chave de API Google Gemini para executar o projeto, que pode ser encontrada na página API Google Gemini.
Instalar os pré-requisitos
O projeto do agente de tema do Flutter é executado como uma extensão do Visual Studio Code (VS Code) da Microsoft e usa Node.js e npm para gerenciar pacotes e executar o aplicativo. As instruções de instalação a seguir são para uma máquina host Linux.
Para instalar o software necessário:
Instale o Visual Studio Code para sua plataforma.
Instale node e npm seguindo as instruções de instalação para sua plataforma.
Se você ainda não instalou o Flutter para o VS Code, siga as instruções de instalação.
Clonar e configurar o projeto
Faça o download do código do projeto e use o comando de instalação npm para fazer o download das dependências necessárias e configurar o projeto. Você precisa do software de controle de origem git para extrair o código-fonte do projeto.
Para fazer o download e configurar o código do projeto:
Clone o repositório do Git usando o comando abaixo.
git clone https://github.com/google/generative-ai-docs`
Se quiser, configure seu repositório local do git para usar o checkout esparso, para que você tenha apenas os arquivos do projeto do Docs Agent.
cd generative-ai-docs/
git sparse-checkout init --cone
git sparse-checkout set examples/gemini/node/flutter_theme_agent
Navegue até o diretório raiz do projeto do Flutter Theme Agent.
cd generative-ai-docs/examples/gemini/node/flutter_theme_agent/
Execute o comando de instalação para fazer o download das dependências e configurar o projeto:
npm install
Configurar e testar a extensão
Agora você pode testar a instalação executando o Flutter Theme Agent como uma extensão de desenvolvimento no VS Code no seu dispositivo. O teste abre uma janela Extension Development Host separada do VS Code, em que a nova extensão está disponível. Nessa nova janela, você configura a chave de API usada pela extensão para acessar a API Google Gemini.
Atenção: trate a chave de API como uma senha e proteja-a adequadamente. Para conferir algumas práticas recomendadas gerais sobre segurança de chaves, consulte este artigo de suporte.
Para configurar e testar a configuração:
Inicie o aplicativo VS Code.
No VS Code, crie uma nova janela selecionando File > New Window.
Abra o projeto do Flutter Theme Agent selecionando File > Open Folder e selecionando a pasta flutter_theme_agent/.
No VS Code, abra o arquivo flutter_theme_agent/package.json.
Execute a extensão no modo de depuração selecionando Run > Start Debugging. Essa etapa abre uma janela separada do Extension Development Host do VS Code.
Abra as configurações do VS Code selecionando Code > Settings > Settings.
Receba uma chave da API Gemini do Google no site do desenvolvedor de IA generativa e copie a string da chave.
Defina a chave de API como uma configuração. No campo Search Settings, digite flutter theme, selecione a guia User e, na configuração Google > Gemini: Api Key, clique no link Edit in settings.json e adicione sua chave de API Gemini:
"google.ai.apiKey": "your-api-key-here"
Salve as alterações no arquivo settings.json e feche as guias de configurações.
Para testar os comandos da extensão:
Na janela Extension Development Host do VS Code, escreva um comentário de código que descreva o componente da interface do usuário que você quer gerar.
Selecione o texto do comentário com as características do componente.
Abra a paleta de comandos selecionando Visualizar > Paleta de comandos.
Na paleta de comandos, digite Flutter Theme e selecione um dos comandos com esse prefixo.
Modificar comando
Modificar os comandos fornecidos no Flutter Theme Agent é a maneira mais simples de mudar o comportamento e os recursos da extensão.
Os comandos de comentário e revisão usam uma abordagem de solicitação com exemplos de código e comentários para esse código, além de algumas instruções gerais para o modelo de linguagem de IA. Essas informações de contexto do comando orientam o modelo de linguagem do Gemini na geração de uma resposta. Ao mudar as instruções, os exemplos ou ambos nos comandos de comentário ou revisão, você pode mudar o comportamento de cada um dos comandos atuais.
Este conjunto de instruções explica como modificar o comando buttonstyle.ts mudando o texto de comando.
Para se preparar para editar o comando buttonstyle.ts:
Inicie o aplicativo VS Code.
No VS Code, crie uma nova janela selecionando File > New Window.
Abra o projeto do Flutter Theme Agent selecionando File > Open Folder e selecionando a pasta flutter_theme_agent/.
Abra flutter_theme_agent/src/buttonstyle.ts.
Para modificar o comportamento do comando buttonstyle.ts:
No arquivo buttonstyle.ts, edite a constante BUTTONSTYLE_CONTEXT para incluir instruções diferentes.
const BUTTONSTYLE_CONTEXT=`
ButtonStyle should only define properties that exist for a ButtonStyle
object. ButtonStyle objects have the following properties. The buttons
can ONLY be styled by setting these properties. No other properties:
alignment → AlignmentGeometry? // The alignment of the button's child.
...
Se quiser, no arquivo buttonstyle.ts, constante BUTTONSTYLE_CONTEXT, adicione outro exemplo de instrução e saída de estilo de botão ou substitua um dos exemplos atuais.
...
Here's an example prompt:
Create a ButtonStyle where the button is green by default and blue on hover state. And elevation is 14, no surface tint color, and the splash effect is turned off.
Here's an example of good Dart code:
ButtonStyle(
  backgroundColor: MaterialStateProperty.resolveWith<Color?>(
...
Salve as alterações no arquivo buttonstyle.ts.
Para testar o comando modificado:
Na janela do projeto da extensão do VS Code, reinicie o depurador selecionando Run > Restart Debugging.
Na janela Extension Development Host do VS Code, selecione um comentário de código na janela do editor que descreva o estilo do botão que você quer, por exemplo:
// blue, lickable buttons that light up when you hover over them`
Abra a paleta de comandos selecionando Visualizar > Paleta de comandos.
Na paleta de comandos, digite Flutter e selecione o comando Agente de tema do Flutter: criar um Flutter ButtonStyle.
Criar novo comando
É possível estender o agente de temas do Flutter criando novos comandos que executam tarefas completamente novas com a API Gemini. Cada arquivo de comando, como buttonstyle.ts e colorscheme.ts, é independente e inclui código para coletar texto do editor ativo, compor um comando, conectar-se à API Gemini, enviar um comando e entregar a resposta.
Figura 2. Novo comando do agente de tema do Flutter na janela do host de desenvolvimento da extensão do VS Code.
Este conjunto de instruções explica como criar um novo comando usando o código de um comando existente, colorscheme.ts, como modelo. Essa atualização muda o comando para não incluir a sintaxe de inclusão do objeto ColorScheme. Assim, você não precisa remover essa sintaxe após a geração e pode visualizar a saída mais rapidamente.
Para criar um comando que gere apenas uma lista de cores para um objeto ColorScheme:
Faça uma cópia do arquivo flutter_theme_agent/src/colorscheme.ts chamado colorscheme2.ts no diretório src/.
No VS Code, abra o arquivo src/colorscheme2.ts.
No arquivo colorscheme2.ts, renomeie a função generateColorScheme como generateColorScheme2:
export async function generateColorScheme2(){
  vscode.window.showInformationMessage('Generating Color Scheme...');
Mude as instruções de comando no arquivo colorscheme2.ts. Edite as instruções de geração de código COLORSCHEME_CONTEXT removendo o texto ColorScheme( do código de exemplo na linha 51 e tornando-o uma linha vazia.
...
Here's the example of good Dart code:

  brightness: Brightness.light,
  primary: Color(0xffFF80AB),
...
Remova o caractere de parênteses de fechamento ")" do final da lista de cores e torne-o uma linha vazia.
...
  inversePrimary: Color(0xffD15B9D),
  surfaceTint: Color(0xffFF80AB),

This example code is a good ...
Repita essas mudanças para o segundo exemplo. Na string COLORSCHEME_CONTEXT na linha 87, remova o texto ColorScheme( e faça com que ela seja uma linha vazia.
Na linha 115, remova o caractere de parênteses de fechamento ")" do final da lista de cores e torne-o uma linha vazia.
Na string COLORSCHEME_CONTEXT, adicione uma instrução para não incluir a sintaxe de delimitação:
...
- The color scheme must be accessible and high-contrast.

In the response, only include the list of colors and nothing else. Do
not include a starting "ColorScheme(" prefix or an ending ")" suffix.

Here's an example user prompt:
...
Salve as alterações no arquivo colorscheme2.ts.
Integrar o novo comando
Depois de concluir o código do novo comando, você precisa integrá-lo ao resto da extensão. Atualize os arquivos extension.ts e package.json para tornar o novo comando parte da extensão e permitir que o VS Code invoque o novo comando.
Para integrar o novo comando ao código da extensão:
No VS Code, abra o arquivo flutter_theme_agent/src/extension.ts.
Importe o novo código de comando para a extensão adicionando uma nova instrução de importação.
import { generateColorScheme2 } from './components/colorscheme2';
Registre o novo comando adicionando o seguinte código à função activate().
export function activate(context: vscode.ExtensionContext) {
    ...
    vscode.commands.registerCommand('flutter-theme-agent.generateColorScheme2',
        generateColorScheme2);
    ...
}
Salve as alterações no arquivo extension.ts.
Para integrar o comando de nome ao pacote de extensão:
No VS Code, abra o arquivo flutter_theme_agent/package.json.
Adicione o novo comando à seção commands do arquivo de pacote.
"contributes": {
  "commands": [
    ...
    {
      "command": "flutter-theme-agent.generateColorScheme2",
      "title": "Flutter Theme Agent: My New Code Generator."
    }
  ],
Salve as alterações no arquivo package.json.
Testar o novo comando
Depois de concluir a codificação do comando e integrá-lo à extensão, você poderá testá-lo. O novo comando só está disponível na janela Extension Development Host do VS Code, e não na janela do VS Code em que você editou o código da extensão.
Para testar o comando modificado:
Na janela do projeto da extensão do VS Code, reinicie o depurador selecionando Run > Restart Debugging, que reinicia uma janela Extension Development Host separada.
Na janela Extension Development Host do VS Code, abra um projeto de desenvolvimento do Flutter.
Na mesma janela, abra uma janela do editor de código, digite um comentário descrevendo o componente da interface do usuário que você quer e selecione o texto do comentário.
Abra a paleta de comandos selecionando Visualizar > Paleta de comandos.
Na paleta de comandos, digite Flutter Theme e selecione o comando Flutter Theme Agent: My New Code Generator.
Outros recursos
Para mais informações sobre o projeto do agente de temas do Flutter, consulte o repositório de código. Se você precisar de ajuda para criar o aplicativo ou estiver procurando colaboradores de desenvolvimento, confira o servidor Google Developers Community Discord.
Aplicativos de produção
Se você planeja implantar o Flutter Theme Agent para um grande público, saiba que o uso da API Google Gemini pode estar sujeito a limitação de taxa e outras restrições de uso. Se você está pensando em criar um aplicativo de produção com o modelo Gemini, confira os serviços da Vertex AI do Google Cloud para aumentar a escalabilidade e a confiabilidade do seu app.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-24 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_60.txt ---

URL: https://ai.google.dev/gemini-api/tutorials/docs-agent

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Aplicativo de chat
Assistente de código
Gerador de código do Flutter
Pesquisa de conteúdo
Agente de exploração de dados
Assistente de redação
Revisor do Apresentações Google
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Crie uma pesquisa de conteúdo de IA com o agente do Documentos
Nesta página
Visão geral
Configurar o projeto
Instalar os pré-requisitos
Defina as variáveis de ambiente
Clonar e configurar o projeto
Preparar o conteúdo
Usar a documentação do Flutter para testes
Processar conteúdo
A pesquisa de informações é um dos usos mais comuns de modelos generativos de inteligência artificial (IA). Criar uma interface de pesquisa de conversação para seu conteúdo usando a IA permite que os usuários façam perguntas específicas e recebam respostas diretas.
Observação: este exemplo foi atualizado para uso com a API Gemini.
Neste tutorial, mostramos como criar uma interface de pesquisa de conversação com tecnologia de IA para seu conteúdo. Ele é baseado no Docs Agent, um projeto de código aberto que usa a API Google Gemini para criar uma interface de pesquisa conversacional, sem treinar um novo modelo de IA ou fazer ajustes com modelos Gemini. Isso significa que você pode criar esse recurso de pesquisa rapidamente e usá-lo para conjuntos de conteúdo pequenos e grandes.
Para conferir uma visão geral em vídeo do projeto e saber como ampliá-lo, incluindo insights dos criadores, acesse: Pesquisa de conteúdo de IA | Build with Google AI. Caso contrário, você pode começar a estender o projeto seguindo as instruções abaixo.
Visão geral
O projeto do agente do app Documentos oferece uma interface de pesquisa de conversação para um conjunto de conteúdo específico, com suporte da API Google Gemini e dos modelos generativos. Os usuários podem fazer uma pergunta detalhada em um estilo de conversa e receber uma resposta detalhada com base em um conjunto de conteúdo específico. Nos bastidores, o agente de documentos pega a pergunta e pesquisa em um banco de dados vetorial do conteúdo, além de criar uma instrução detalhada para o modelo generativo, incluindo fragmentos de texto relevantes. O modelo generativo gera uma resposta para a pergunta, e o agente do Documentos a formata e a apresenta ao usuário.
Figura 1. Diagrama funcional do app de projeto do Docs Agent.
A chave para que o Docs Agent possa responder a perguntas sobre seu conteúdo é a criação de um banco de dados vetorial desse conteúdo. Você separa seu conteúdo em partes lógicas de texto e gera um vetor para cada uma delas. Esses vetores são representações numéricas das informações em cada bloco e são gerados com uma função de incorporação de texto de IA dos modelos generativos do Google.
Quando um usuário faz uma pergunta, o agente de documentos usa a mesma função de incorporação de texto para criar uma representação numérica dessa pergunta e usa esse valor para pesquisar no banco de dados vetorial e encontrar conteúdo relacionado. Ele pega os melhores resultados e adiciona essas informações a um comando para o modelo generativo. O modelo de IA usa a pergunta e as informações de contexto adicionais para gerar uma resposta.
Configurar o projeto
Estas instruções mostram como configurar o projeto do agente do Documentos para desenvolvimento e teste. As etapas gerais são instalar alguns pré-requisitos de software, definir algumas variáveis de ambiente, clonar o projeto do repositório de código e executar a instalação de configuração. O projeto de código usa o Python Poetry para gerenciar pacotes e o ambiente de execução do Python.
Observação: você precisa de uma chave de API Google Gemini para executar o projeto, que pode ser encontrada na página API Google Gemini.
Instalar os pré-requisitos
O projeto do Docs Agent usa o Python 3 e o Python Poetry para gerenciar pacotes e executar o aplicativo. As instruções de instalação a seguir são para uma máquina host Linux.
Para instalar o software necessário:
Instale o Python 3 e o pacote de ambiente virtual venv para Python.
sudo apt update
sudo apt install git pip python3-venv
Instale o Python Poetry para gerenciar dependências e empacotamentos do projeto.
curl -sSL https://install.python-poetry.org | python3 -
Você pode usar o Python Poetry para adicionar mais bibliotecas do Python se estender o projeto.
Defina as variáveis de ambiente
Defina algumas variáveis de ambiente necessárias para permitir a execução do projeto de código do agente do Documentos, incluindo uma chave da API Google Gemini e a configuração do Python Poetry. Talvez seja necessário adicionar essas variáveis ao arquivo $HOME/.bashrc se você estiver usando o Linux, para que elas sejam as configurações padrão das sessões do terminal.
Atenção: trate a chave de API como uma senha e proteja-a adequadamente. Não incorpore sua chave em um código publicado publicamente.
Para definir as variáveis de ambiente:
Receba uma chave da API Gemini do Google e copie a string da chave.
Defina a chave de API como uma variável de ambiente. Em hosts Linux, use o seguinte comando.
export API_KEY=<YOUR_API_KEY_HERE>
Resolva um problema conhecido do Python Poetry definindo o parâmetro PYTHON_KEYRING_BACKEND. Em hosts Linux, use o comando a seguir.
export PYTHON_KEYRING_BACKEND=keyring.backends.null.Keyring
Clonar e configurar o projeto
Faça o download do código do projeto e use o comando de instalação do Poetry para fazer o download das dependências necessárias e configurar o projeto. Você precisa do software de controle de origem git para extrair o código-fonte do projeto. externo Para fazer o download e configurar o código do projeto:
Clone o repositório do Git usando o comando abaixo.
git clone https://github.com/google/generative-ai-docs
Opcionalmente, configure seu repositório local do Git para usar o checkout esparso, para que você tenha apenas os arquivos do projeto do agente do Docs.
cd generative-ai-docs/
git sparse-checkout init --cone
git sparse-checkout set examples/gemini/python/docs-agent/
Mova para o diretório raiz do projeto docs-agent.
cd examples/gemini/python/docs-agent/
Execute o comando de instalação do Poetry para fazer o download das dependências e configurar o projeto:
poetry install
Preparar o conteúdo
O projeto do Docs Agent foi projetado para funcionar com conteúdo de texto e inclui ferramentas específicas para trabalhar com sites que usam o Markdown como formato de origem. Se você estiver trabalhando com conteúdo do site, preserve (ou replique) a estrutura de diretórios do site servido para permitir que a tarefa de processamento de conteúdo mapeie e crie links para esse conteúdo.
Dependendo do formato e dos detalhes do seu conteúdo, talvez seja necessário limpá-lo para remover informações não públicas, notas internas ou outras informações que você não quer que sejam pesquisáveis. Você precisa manter a formatação básica, como títulos e cabeçalhos, que ajudam a criar divisões lógicas de texto, ou blocos, na etapa de processamento de conteúdo.
Para preparar o conteúdo para processamento:
Crie um diretório para o conteúdo que você quer que o agente de IA pesquise.
mkdir docs-agent/content/
Copie o conteúdo para o diretório docs-agent/content/. Se o conteúdo for um site, preserve (ou replique) a estrutura de diretórios do site servido.
Limpe ou edite o conteúdo conforme necessário para remover informações não públicas ou outras informações que você não quer incluir nas pesquisas.
Usar a documentação do Flutter para testes
Se você precisar de um conjunto de conteúdo para testar o Docs Agent, use os documentos para desenvolvedores do Flutter.
Para acessar a documentação para desenvolvedores do Flutter:
Vá para o diretório do conteúdo que você quer que o agente de IA pesquise.
cd docs-agent/content/
Clone os documentos do Flutter no diretório docs-agent/content/.
git clone --recurse-submodules https://github.com/flutter/website.git
Processar conteúdo
Para que o agente de pesquisa pesquise conteúdo relacionado às perguntas dos usuários, é necessário criar um banco de dados de vetores que representem seu conteúdo. Os vetores são gerados usando uma função de modelo generativo de IA chamada incorporação de texto. Os embeddings de texto são representações numéricas do conteúdo textual. Eles aproximam o significado semântico do texto como um conjunto de números. Ter representações numéricas de informações permite que o sistema tome a pergunta de um usuário, aproxime o significado dela usando a mesma função de incorporação de texto e encontre informações relacionadas como um cálculo matemático, usando um algoritmo de vizinhos k-mais próximos (k-NN).
Dividir o conteúdo de texto
A quantidade de texto que um vetor de embedding de texto pode representar de forma eficaz é limitada. Esse projeto limita o texto representado em um vetor a 3.000 caracteres ou menos. Isso significa que você precisa dividir seu conteúdo em partes menores que esse limite. Esta seção descreve como usar um script fornecido com o projeto do agente do Documentos para dividir arquivos Markdown em blocos de texto menores. Para dicas sobre como trabalhar com outros formatos de conteúdo, consulte Processar outros formatos.
Importante:os embeddings de texto têm como objetivo aproximar o significado. A divisão do texto do conteúdo em partes semi-aleatórias, como sempre que você atinge o limite de caracteres, geralmente faz com que o agente do Documentos produza respostas de qualidade inferior. Em vez disso, use a estrutura do conteúdo, incluindo títulos, títulos e parágrafos relacionados para dividir o texto do conteúdo.
Observação: os comandos agent a seguir precisam ser executados no ambiente poetry shell.
Para dividir o conteúdo no formato Markdown:
Configure os parâmetros de entrada do script de processamento editando o arquivo docs-agent/config.yaml. Este exemplo é destinado a um subconjunto das documentações do Flutter:
input:
- path: "content/website/src/ui"
  url_prefix: "https://docs.flutter.dev/ui"
Salve as alterações neste arquivo de configuração.
Navegue até o diretório do projeto docs-agent:
cd docs-agent/
Divida o conteúdo de origem do Markdown executando o comando agent chunk:
agent chunk
O script processa o conteúdo de entrada e cria arquivos de texto de saída no diretório docs-agent/data, dividindo o texto com base em títulos, cabeçalhos e parágrafos relacionados. O processamento pode levar algum tempo, dependendo do tamanho do conteúdo.
Criar vetores de embedding de texto
Depois de dividir o conteúdo em blocos significativos de tamanho adequado, é possível preencher o banco de dados vetorial com o conteúdo usando uma função de embedding de texto. O projeto do agente do Documentos usa o banco de dados de vetores Chroma para armazenar vetores de embedding de texto. Estas instruções abrangem como usar o script dos agentes do Documentos para preencher um banco de dados vetorial com seu conteúdo dividido.
Observação: os comandos agent a seguir precisam ser executados no ambiente poetry shell.
Para gerar embeddings de texto e preencher o banco de dados de vetores:
Navegue até o diretório do projeto docs-agent:
cd docs-agent/
Preencha o banco de dados de vetor com seu conteúdo usando o comando agent populate:
agent populate
Esse script usa a API Google Gemini para gerar vetores de text embedding e salvar a saída no banco de dados de vetores. O processamento pode levar algum tempo, dependendo do tamanho do conteúdo.
Processar outros formatos
O projeto do agente de documentos foi criado para funcionar com conteúdo de sites no formato Markdown. Os autores do projeto criaram alguns scripts de conversão para gerar outros tipos de conteúdo no formato Markdown, incluindo Documentos Google, formato de documento portátil (PDF) e Gmail. Para mais informações sobre o uso desses conversores, consulte o diretório docs-agent/apps_script do repositório de código.
Converter outros formatos de conteúdo
Você pode usar outros formatos de conteúdo com o projeto, mas esses outros métodos precisam ser criados por você ou por outros membros da comunidade. Verifique o repositório de código Issues e Pull Requests para conferir se alguém está criando soluções semelhantes.
O código principal que você precisa criar para oferecer suporte a outros formatos de conteúdo é um script de divisão, como o files_to_plain_text.py. Crie um script ou programa que gere uma saída semelhante a este script. A saída de texto final precisa ter formatação mínima e informações desnecessárias. Se você estiver usando formatos de conteúdo como HTML ou JSON, remova o máximo possível da formatação não informativa (tags, scripts, CSS), para que ela não distorça os valores das incorporações de texto geradas a partir deles.
Depois de criar um script de divisão para o formato de conteúdo, será possível executar o script populate_vector_database.py para preencher o banco de dados de vetores. Para mais informações sobre o processamento de arquivos para uso com o Docs Agent, consulte o Preprocess Readme do Docs Agent.
Testar o app
Quando você terminar de preencher o banco de dados de vetores, o projeto estará pronto para testes. O projeto fornece uma função de empacotamento para executar o projeto localmente.
Observação: os comandos agent a seguir precisam ser executados no ambiente poetry shell.
Para executar e testar a interface da Web do projeto:
Navegue até o diretório do projeto docs-agent:
cd docs-agent/
Execute o script de inicialização do aplicativo da Web:
agent chatbot
Usando o navegador da Web, navegue até o endereço da Web do URL mostrado na saída do script de inicialização e teste o aplicativo.
* Running on http://your-hostname-here:5000
Observação: é possível personalizar ainda mais o aplicativo, incluindo o nome do produto que aparece na interface do usuário de pesquisa, atualizando o arquivo docs-agent/config.yaml. Para mais informações, consulte o readme do agente de documentos.
Opções de implementação
A API Gemini oferece ferramentas de programação que podem substituir componentes da implementação do agente de documentos, especificamente: variante de modelo Gemini de recuperação semântica e resposta a perguntas atribuídas (AQA, na sigla em inglês). É possível usar o recurso de recuperação semântica da API Gemini para substituir o banco de dados de vetores separado. O recurso de recuperação semântica permite gerar embeddings para seu conteúdo e armazená-lo. O modelo AQA Gemini é ajustado para responder a perguntas com o material de origem fornecido em um comando. Você usa a recuperação semântica com o modelo AQA para responder a perguntas sobre seu conteúdo na API Gemini.
O agente de documentos inclui opções de configuração para usar o recurso da API Semantic Retrieval, o modelo AQA Gemini ou ambos. Para mais informações, consulte o README do agente de documentos.
Outros recursos
Para mais informações sobre o projeto do agente do Google Docs, consulte o repositório de código. Se você precisar de ajuda para criar o aplicativo ou estiver procurando colaboradores de desenvolvimento, confira o servidor do Google Developers Community Discord.
Aplicativos de produção
Se você planeja implantar o Docs Agent para um grande público, saiba que o uso da API Google Gemini pode estar sujeito a limitação de taxa e outras restrições de uso. Se você está pensando em criar um aplicativo de produção com a API Gemini, como o Docs Agent, confira os serviços da Vertex AI do Google Cloud para aumentar a escalabilidade e a confiabilidade do seu app.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-26 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_61.txt ---

URL: https://ai.google.dev/gemini-api/tutorials/sql-talk

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Aplicativo de chat
Assistente de código
Gerador de código do Flutter
Pesquisa de conteúdo
Agente de exploração de dados
Assistente de redação
Revisor do Apresentações Google
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Crie um agente de exploração de dados de IA com o Gemini
Nesta página
Configurar o projeto
Criar uma instância do Cloud Shell para o projeto
Conseguir um ID de projeto do Cloud
Configurar o projeto SQL Talk
Testar o projeto
Modificar o aplicativo
Adicionar uma definição de chamada de função
Outros recursos
Crie uma interface de chat com tecnologia de inteligência artificial (IA) para suas interfaces de programação de sistemas empresariais e permita que seus colegas façam perguntas sobre seus dados de negócios. Fazer análises e relatórios sobre os dados da sua organização é essencial para melhorar a forma como você faz negócios. Encontrar problemas, descobrir tendências e investigar resultados são possíveis com os dados certos, mas, como desenvolvedor, ajudar colegas que não codificam a descobrir os dados certos pode ser desafio.
O projeto SQL Talk é um aplicativo de código aberto que usa a tecnologia de IA generativa para responder a perguntas sobre dados de negócios. O projeto usa a API Gemini e o recurso de chamada de função para transformar perguntas de dados de negócios em consultas SQL e chamadas de API e, em seguida, transformar os resultados em linguagem simples. Você pode usar este projeto como um ponto de partida para criar um agente de dados para sua própria empresa e ajudar seus colegas a encontrar respostas sem precisar escrever um monte de código de uso único.
Para conferir uma visão geral em vídeo do projeto e saber como ele pode ser estendido, incluindo insights dos criadores, acesse Agente de dados de IA | Crie com a IA do Google. Caso contrário, você pode começar a estender o projeto usando as seguintes instruções.
Figura 1. Interface do usuário do aplicativo do projeto SQL Talk.
Configurar o projeto
Estas instruções mostram como configurar o projeto SQL Talk para desenvolvimento e teste. As etapas gerais são criar o projeto SQL Talk, configurar um projeto de desenvolvimento do Google Cloud Shell Editor, receber um ID do projeto do Google Cloud e usar um script para configurar as configurações do projeto. Estas instruções descrevem como configurar o projeto usando o editor do Cloud Shell, que torna a configuração, a execução e a atualização do projeto rápidas e convenientes.
Criar uma instância do Cloud Shell para o projeto
É possível configurar o projeto SQL Talk clonando o repositório do projeto em uma instância do Cloud Shell. Esse processo configura uma instância de ambiente de desenvolvimento virtual na infraestrutura do Google Cloud para o projeto e clona o repositório de código nesse ambiente virtual.
Para criar uma instância do Cloud Shell para o SQL Talk:
Clique no link a seguir para criar uma instância do Cloud Shell do SQL Talk.
Este link configura uma instância do editor do Google Cloud Shell e clona o repositório do SQL Talk na instância.
Figura 2. Projeto SQL Talk clonado em um ambiente de desenvolvimento do editor do Google Cloud Shell.
Conseguir um ID de projeto do Cloud
O projeto SQL Talk usa um ID de projeto do Google Cloud para se conectar aos serviços do Google Cloud, incluindo os modelos Gemini. Você configura um ID de projeto no editor do Cloud Shell para permitir que o aplicativo se conecte a esses serviços.
Para conectar o editor do Cloud Shell a um ID de projeto:
Acesse o console do Google Cloud e faça login, se necessário.
Selecione um projeto do Cloud ou crie um novo.
Anote o ID do projeto do Cloud.
Conecte a instância do Editor ao projeto e configure-o. Na janela do editor do Cloud Shell, no painel do terminal, digite o seguinte comando:
gcloud config set project YOUR_PROJECT_ID
Importante: a API Vertex AI exige que o faturamento seja ativado nos projetos em que você a usa. Verifique se o faturamento está ativado para o ID do projeto do Cloud que você está usando.
Configurar o projeto SQL Talk
O projeto SQL Talk usa os serviços do Google Cloud para executar o projeto, incluindo o serviço de banco de dados BigQuery e a API Vertex AI para se conectar aos modelos Gemini. O projeto SQL Talk inclui um script setup.sh que configura o projeto com os serviços do Google Cloud necessários e inicia a versão padrão do projeto.
Para configurar e executar a instância do editor do Cloud Shell do projeto:
No painel do terminal da janela do Editor do Cloud Shell, navegue até o diretório do projeto do SQL Talk (/sql-talk-app) do Cloud Shell:
cd ~/cloudshell_open/generative-ai/gemini/function-calling/sql-talk-app
No painel do terminal, digite o seguinte comando:
bash setup.sh
Quando o script de configuração for concluído, você verá uma mensagem semelhante a esta na janela do terminal do editor do Cloud Shell. Essa mensagem indica que o processo de configuração foi concluído e que o aplicativo SQL Talk está em execução:
You can now view your Streamlit app in your browser.
Network URL: http://##.##.##.##:8080
External URL: http://##.##.##.##:8080
Testar o projeto
Depois de concluir a configuração do projeto SQL Talk, teste o aplicativo para verificar se ele está funcionando como esperado. O script de configuração inicializa o aplicativo automaticamente quando você o executa. Você pode reiniciar o aplicativo usando as etapas a seguir.
Para executar o aplicativo SQL Talk:
Se o Editor do Cloud Shell estiver ocioso e desconectado, talvez seja necessário se reconectar ao ID do projeto do Cloud.
gcloud config set project YOUR_PROJECT_ID
No painel do terminal da janela do editor do Cloud Shell, navegue até o diretório do projeto SQL Talk do Cloud Shell.
cd ~/cloudshell_open/generative-ai/gemini/function-calling/sql-talk-app
No painel do terminal, digite o seguinte comando.
~/miniforge/bin/streamlit run app.py --server.enableCORS=false \
    --server.enableXsrfProtection=false --server.port 8080
Confira o aplicativo SQL Talk. No canto superior direito da janela do editor do Cloud Shell, selecione o botão Visualização da Web e, em seguida, Visualizar na porta 8080.
Para conferir as atualizações do aplicativo SQL Talk:
Na visualização da Web do aplicativo da Web SQL Talk, atualize o navegador ou a guia do navegador.
Para interromper o aplicativo SQL Talk:
No painel do terminal da janela do editor do Cloud Shell, digite Ctrl-C.
Modificar o aplicativo
É possível mudar o comportamento e adicionar recursos ao aplicativo SQL Talk modificando o código Python dele. Esta seção descreve como adicionar uma nova chamada de função ao aplicativo SQL Talk.
O recurso Function Calling da API Gemini usa uma sintaxe específica para definir funções que serão usadas pelo modelo generativo para responder a perguntas ou resolver problemas. Essa sintaxe não precisa corresponder exatamente à sintaxe de uma chamada de API real. Em vez disso, use o recurso de chamada de função para forçar o modelo generativo a fornecer entradas de dados ou parâmetros específicos que estejam em conformidade com a sintaxe de chamada de API e, em seguida, use esses parâmetros para executar as chamadas de API reais no código do aplicativo.
Este exemplo de implementação mostra como criar uma definição de chamada de função para listar jobs ou consultas de banco de dados recentes e, em seguida, mapear essa definição para a chamada de API real no código do aplicativo SQL Talk.
Adicionar uma definição de chamada de função
Adicione uma nova chamada de função para listar jobs ou consultas recentes do banco de dados. Essa definição é usada pelo modelo generativo para entender o que a chamada de API faz e quais parâmetros de entrada ela exige. Esta definição de função de exemplo é definida sem parâmetros.
Para adicionar uma nova chamada de função ao aplicativo:
Na janela do editor do Cloud Shell, abra o arquivo de código sql-talk-app/app.py.
Depois da declaração da função list_datasets_func, adicione uma nova FunctionDeclaration.
list_jobs_func = FunctionDeclaration(
    name="list_jobs",
    description="Get a list of the 10 most recent database requests to help answer the user's question",
    parameters={
        "type": "object",
        "properties": {
  },
},
)
Adicione a nova função ao objeto sql_query_tool.
sql_query_tool = Tool(
    function_declarations=[
        sql_query_func,
        list_datasets_func,
        List_jobs_func,  # add this new function
        list_tables_func,
        get_table_func,
    ],
)
Para adicionar código para executar a chamada de API da nova função:
No arquivo de código sql-talk-app/app.py, adicione uma nova cláusula if ao loop while function_calling_in_process:.
if response.function_call.name == "list_datasets":
    ...

# add this if clause for list_jobs function
if response.function_call.name == "list_jobs":
    api_response = client.list_jobs(max_results=10)  # API request(s)
    api_response = str([job.job_id for job in api_response])
    api_requests_and_responses.append(
      [response.function_call.name,params, api_response])
Outros recursos
Para mais informações sobre o projeto de consulta SQL, consulte o repositório de código e confira a postagem do blog da Comunidade do Google Cloud sobre o projeto SQL Talk. Se você precisar de ajuda para criar o aplicativo ou quiser colaborar com outros desenvolvedores, confira o servidor Google Developers Community Discord e o fórum de IA/ML do Google Cloud. Para conferir mais projetos do Build with Google AI, acesse a playlist de vídeos.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_62.txt ---

URL: https://ai.google.dev/gemini-api/tutorials/wordcraft

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Aplicativo de chat
Assistente de código
Gerador de código do Flutter
Pesquisa de conteúdo
Agente de exploração de dados
Assistente de redação
Revisor do Apresentações Google
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Crie um assistente de escrita com IA com o Wordcraft
Nesta página
Configurar o projeto
Instalar os pré-requisitos
Clonar e configurar o projeto
Defina as variáveis de ambiente
Testar sua configuração
Modificar o texto de exemplo do comando
Criar novo controle de escrita
Criar exemplos
Observação: este exemplo de aplicativo usa o SDK do JavaScript legado. Para novos aplicativos, use o SDK da IA generativa do Google para TypeScript e JavaScript.
Adoramos histórias. Contar histórias e fazer outras formas de escrita criativa pode ser desafiador e recompensador. No entanto, criar suas próprias histórias em uma página em branco pode parecer assustador e até mesmo avassalador. Os modelos generativos de inteligência artificial (IA) podem ser uma ótima ferramenta para ajudar você a passar da página em branco e criar sua narrativa.
Observação: este exemplo foi atualizado para uso com a API Gemini.
Este tutorial mostra como estender o Wordcraft, uma ferramenta de escrita de histórias com tecnologia de IA criada pela equipe de pesquisa de pessoas e IA do Google. Esse aplicativo da Web usa a API Gemini para ajudar você a criar histórias, pouco a pouco, gerando ideias, escrevendo partes delas e revisando o conteúdo para adicionar mais detalhes. Você pode modificar o Wordcraft para que ele corresponda mais ao seu estilo de escrita e criar novos controles de escrita para oferecer melhor suporte ao seu fluxo de trabalho.
Para conferir uma visão geral em vídeo do projeto e saber como ampliá-lo, incluindo insights dos criadores, acesse AI Writing Assistant: Build with Google AI. Caso contrário, você pode começar a estender o projeto seguindo as instruções abaixo.
Configurar o projeto
Estas instruções mostram como configurar o projeto Wordcraft para desenvolvimento e teste. É necessário instalar o software necessário, clonar o projeto do repositório de código, executar a instalação de configuração e definir algumas variáveis de ambiente. Para testar a configuração, execute o projeto depois de concluir estas etapas.
Observação: você precisa de uma chave de API Google Gemini para executar o projeto, que pode ser encontrada na página API Google Gemini.
Instalar os pré-requisitos
O projeto Wordcraft usa o Node e o npm para gerenciar pacotes e executar o aplicativo. As instruções de instalação a seguir são para uma máquina host Linux.
Para instalar o software necessário:
Instale node e npm seguindo as instruções de instalação da sua plataforma.
Clonar e configurar o projeto
Faça o download do código do projeto e use o comando de instalação npm para fazer o download das dependências necessárias e configurar o projeto. Você precisa do software de controle de origem git para extrair o código-fonte do projeto.
Para fazer o download e configurar o código do projeto:
Clone o repositório do Git usando o comando abaixo.
git clone https://github.com/PAIR-code/wordcraft
Navegue até o diretório raiz do projeto Wordcraft.
cd wordcraft/
Execute o comando de instalação para fazer o download das dependências e configurar o projeto:
npm install
Defina as variáveis de ambiente
Defina as variáveis de ambiente necessárias para permitir a execução do projeto de código Wordcraft, especificamente uma chave de API Google Gemini. As instruções de instalação a seguir são para uma máquina host Linux.
Para definir as variáveis de ambiente:
Receba uma chave da API Gemini do Google e copie a string da chave.
Navegue até o diretório raiz do projeto Wordcraft.`
cd wordcraft/
Defina a chave de API como uma variável de ambiente. Em hosts Linux, use os seguintes comandos.
touch .env
echo "API_KEY="<YOUR_API_KEY>"" > .env
Cuidado: trate a chave de API como uma senha e proteja-a adequadamente. Não incorpore sua chave em um código publicado publicamente.
Testar sua configuração
Agora você pode testar a configuração do projeto executando o Wordcraft no dispositivo. Esta etapa é opcional, mas recomendada.
Para testar a instalação:
Navegue até o diretório raiz do projeto Wordcraft.
cd wordcraft/
Como executar o projeto no modo de desenvolvimento:
npm run dev
No navegador da Web, acesse a interface do usuário do Wordcraft. O endereço específico é mostrado na saída do comando anterior, por exemplo:
http://localhost:3000/
Modificar o texto de exemplo do comando
O Wordcraft cria comandos para o modelo generativo de IA usando um conjunto de exemplos para cada operação de assistência de escrita, como os comandos start new story e generate text. Os exemplos orientam o modelo generativo na geração de texto para sua história. Ao modificar os exemplos para uma operação, você pode mudar a saída para seguir um padrão ou estilo de escrita diferente. Essa abordagem é uma maneira simples de fazer com que o Wordcraft escreva como você quiser.
O exemplo a seguir mostra uma modificação dos exemplos de new_story no Wordcraft. O objetivo dessa modificação é direcionar o modelo generativo de IA para escrever introduções de histórias usando uma abordagem de monólogo interno e usar um estilo mais apropriado para um romance de mistério. Ao escrever alguns exemplos desse tipo de introdução de história, você pode fazer com que o modelo generativo siga o padrão geral, mas gere uma introdução para um tema diferente.
Para modificar os novos exemplos de histórias no Wordcraft:
Abra o arquivo wordcraft/app/context/json/new_story.json.
Modifique os exemplos, mantendo a estrutura geral do arquivo JSON. Confira um exemplo de modificação para a introdução de uma história de suspense usando um estilo de monólogo interno.
[
  {
    "topic": "scientist disappears and their research into a new technology is gone",
    "target": "I got the call from the chief early Tuesday morning, before I'd even had a second sip of coffee. Terrible timing. Something about a researcher disappearing from the local university. Unusual for the research lab to ask for assistance, so I headed over to main lab building."
  },
  {
    "topic": "a young woman wakes up with no memory",
    "target": "An unfamiliar ceiling with harsh, white lights greeted my eyes as I opened them. I looked around. White walls, medical equipment, a hospital? Wait. Where am I? How did I get here?!"
  },
  {
    "topic": "old man tries to recall an important task as his memories gradually fade away",
    "target": "What was I supposed to do today? Feels like it was important. I stared into the kitchen cabinet full of mismatched mugs, mirroring my own confusion. What was it? Like someone is...in danger? A chill shot down my spine, but the details skittered off and hid in some dark corner of my head."
  },
  {
    "topic": "billionaire is found dead in a hotel room",
    "target": "People meet their end every day, some naturally, some unnaturally. After 17 years of working as a homicide detective in Seattle, I'd seen a lot more of the unnatural variety than most. Comes with the job, along with a hard-learned sense of what side of the line any given incident sat on. This...was murder."
  },
  {
    "topic": "retired covert operative gets dragged back into an old mission",
    "target": "Steam rose gently off the cup of Earl Grey sitting in front of me as I sat at the cafe, pedestrians and light traffic rolling by. The city was slowly waking up around me and my perfect Paris morning routine was shaping up nicely. Then I noticed that old familiar and unwelcome tingling on the back of my neck. I was being watched."
  }
]
Salve as alterações no arquivo "new_story.json".
Para testar a operação modificada da nova história:
Navegue até o diretório raiz do projeto Wordcraft.
cd wordcraft/
Execute o projeto no modo de desenvolvimento. Se ele já estiver em execução, talvez seja necessário interromper e reiniciar o app.
npm run dev
No navegador da Web, acesse a interface do usuário do Wordcraft. O endereço específico é mostrado na saída do comando anterior, por exemplo:
http://localhost:3000/
Acesse o menu principal do Wordcraft e selecione Start a New Story.
Atualize ou mude a proposta da nova história e selecione Iniciar nova história.
É possível modificar todos os controles de escrita de histórias no Wordcraft usando essa técnica. Tente mudar outros controles de história atualizando os exemplos no diretório wordcraft/app/context/json/.
Criar novo controle de escrita
O app Wordcraft foi projetado para ser estendido, para que você possa adicionar novos controles de escrita para ajudar você, semelhante aos botões gerar texto ou reescrever frase na guia "Controles" no lado direito do app. Fazer essas modificações exige um pouco mais de esforço, mas permite que você molde os recursos do Wordcraft para se adequar ao seu fluxo de trabalho e às suas metas.
O exemplo de modificação a seguir cria um novo controle de caracteres para o Wordcraft. Você pode usá-lo para introduzir um novo personagem em uma história com uma descrição dos atributos dele. A base desse controle é a mesma de outros controles do Wordcraft, como o controle start new story discutido anteriormente. Você cria um arquivo JSON com alguns exemplos de como quer introduzir os personagens. O restante das mudanças adiciona a interface do usuário e as funções de gerenciamento de comandos de IA.
Criar exemplos
Escreva alguns exemplos de como você quer que o modelo generativo apresente personagens. Por exemplo, você quer descrever o personagem como um narrador ou apresentá-lo pela experiência do personagem principal? Os exemplos a seguir usam a abordagem mais recente, introduzindo novos personagens do ponto de vista do personagem principal. Adicione esses exemplos com um novo arquivo JSON:
Para adicionar exemplos do novo controle:
Crie um arquivo wordcraft/app/context/json/new_character.json.
Crie os exemplos no arquivo JSON. Neste exemplo, cada exemplo tem um campo de descrição character, que representa o texto do comando, e um campo target, que mostra a saída esperada.
[
  {
    "character": "A character who is helpful and modest.",
    "target": "\"You lost, buddy?\" came a voice from behind me. Turning, I discovered a man dressed in a simple but presentable outfit. Small signs of age and loose threads hinted that these clothes, and the man himself, had seen better days."
  },
  {
    "character": "A character who is attractive and devious.",
    "target": "Stepping out of the alley a little too quickly, I collided with something solidly muscular and surprisingly delicately scented. \"Sorry.\" I managed, regaining my balance. \"Easy there, buddy, you're gonna hurt yourself,\" came the reply from a man with an almost feline grace, further reinforced by a stare that reminded me of a hunting cat assessing its potential prey."
  },
  {
    "character": "A character who is old and hesitant.",
    "target": "\"Excuse me. Do you know the way to the train station from here?\" I looked up from my phone to see a elderly woman in a threadbare coat, purse clutched with two hands in front of her. \"I-I'm supposed to meet my nephew there. Do... do you think you can help me?\""
  },
  {
    "character": "A character who is intelligent and aloof.",
    "target": "Bookish. That was my immediate reaction to this person I now saw in front of me. \"You're finally here. Did you read the notes I sent you?\" The voice sat squarely in between feminine and masculine intonation. \"No, of course you didn't.\" Dismissing my answer before I'd even formulated one. Annoyance immediately flushed through me."
  },
  {
    "character": "A character who is clumsy and energetic.",
    "target": "\"Whoa!\" was the only warning I had before someone slammed into my back, almost knocking me off my feet. \"I'm so sorry! WOOO! These skates are a RUSH!\" The apology came from a rather loud redhead wearing rollerblades, dark glasses and a very beefy-looking pair of headphones. That explained the volume of the apology."
  }
]
Salve as alterações no arquivo new_character.json.
Depois de criar seus exemplos, modifique os arquivos app/context/schema.ts e index.ts para refletir o conteúdo do comando do novo controle de caracteres.
Para adicionar os exemplos ao arquivo schema.ts:
Modifique o arquivo wordcraft/app/context/schema.ts para incluir a nova estrutura de dados de exemplo de caracteres.
export const newStorySchema = z.object({
  topic: z.string(),
  target: z.string(),
});

// add the following:
export const newCharacterSchema = z.object({
  character: z.string(),
  target: z.string(),
});
Defina um tipo de operação associado a esses novos exemplos. Esse novo tipo ajuda a conectar os exemplos de comando à interface do usuário e ao código de criação de comando, que você vai modificar nas etapas seguintes.
Para criar um novo tipo de operação
Modifique o arquivo wordcraft/app/core/shared/types.ts para adicionar o novo tipo de operação de caractere.
export const enum OperationType {
  ...
  NEW_CHARACTER = 'NEW_CHARACTER', // add to list of types
  ...
}
Para registrar os exemplos no arquivo index.ts:
No arquivo wordcraft/app/context/index.ts, importe o novo esquema.
import {
  continueSchema,
  ...
  newCharacterSchema // add new schema
} from './schema';
Importe o novo arquivo JSON como newCharacterJson.
import newCharacterJson from './json/new_character.json';
Registre o conteúdo do novo exemplo de caractere no contexto do aplicativo.
export class WordcraftContext {
  constructor() {
  ...
    this.registerExamples(
      OperationType.NEW_CHARACTER,
      newCharacterSchema,
      newCharacterJson
    );
  ...
}
Exporte um tipo NewCharacterExample.
export type NewCharacterExample = z.infer<typeof newCharacterSchema>;
Criar a interface do usuário
Depois de criar e registrar os exemplos de geração de conteúdo, você pode criar a interface do usuário para o novo controle. A maior parte do trabalho dessa fase é criar uma nova classe de operação e registrá-la com o código principal do aplicativo Wordcraft.
Para criar uma nova operação:
No diretório wordcraft/app/core/operations/, crie uma nova classe de operação usando uma das classes de operações atuais como modelo. Para o novo controle de caracteres, faça uma cópia da classe new_story_operation.ts e renomeie-a como new_character_operation.ts.
Dê um novo nome à classe e especifique quando o controle vai aparecer na interface do usuário definindo pelo menos um valor OperationSite.
export class NewCharacterOperation extends ChoiceOperation {
  static override isAvailable(operationSite: OperationSite) {
    return (
      operationSite === OperationSite.END_OF_SECTION ||
      operationSite === OperationSite.EMPTY_SECTION
    );
  }
Defina o id para a operação.
  static override id = OperationType.NEW_CHARACTER;
Atualize as funções get e run para refletir os valores dos parâmetros do esquema. Esse código processa a extração do texto do comando da interface do usuário para uso no comando de IA.
  private get character(): string {
    return NewCharacterOperation.controls.character.value;
  }

  async run() {
    const params = { character: this.character };
    const choices = await this.getModel().newCharacter(params);

    this.setChoices(choices);
  }
Atualize o texto e as descrições da interface do usuário.
  static override getButtonLabel() {
    return 'introduce character';
  }

  static override getDescription() {
    return 'Introduce a new character at the cursor.';
  }

  static override controls = {
    character: new TextareaControl({
      prefix: 'prompt',
      description: 'A prompt to introduce a new character.',
      value: 'A new character.',
    }),
  };
Para registrar a nova operação no aplicativo Wordcraft:
No arquivo wordcraft/app/core/operations/index.ts, adicione uma importação para a nova operação.
import {NewCharacterOperation} from './new_character_operation';
No mesmo arquivo index.ts, adicione uma exportação para a classe NewCharacterOperation.
export {
  ...
  NewCharacterOperation, // add this class
  ...
};
No arquivo wordcraft/app/main.ts, registre a nova operação.
const operationsService = wordcraftCore.getService(OperationsService);
operationsService.registerOperations(
  ...
  Operations.NewCharacterOperation, // add new operation
  ...
);
Criar processamento de comandos
Na fase final da criação do novo controle, você cria o código que processa a geração de comandos para o modelo generativo de IA e processa a resposta. A parte principal do trabalho é criar um gerenciador de comandos no diretório wordcraft/app/models/gemini/prompts/ que recebe a entrada da interface do usuário e monta um comando para ser transmitido ao modelo generativo.
Para definir uma interface para os parâmetros de comando:
No arquivo wordcraft/app/core/shared/interfaces.ts, adicione uma interface para os novos parâmetros de solicitação de operações.
export interface NewCharacterPromptParams {
  character: string;
}
Para definir um gerenciador de solicitação para a nova operação:
No diretório wordcraft/app/models/gemini/prompts/, crie uma nova classe de manipulador de prompts usando uma das classes de operações existentes como modelo. Para o novo controle de caracteres, faça uma cópia da classe new_story.ts e renomeie-a como new_character.ts como ponto de partida.
Defina uma função de manipulador de prompts e importe a classe NewCharacterExample.
import { NewCharacterPromptParams } from '@core/shared/interfaces';
import { NewCharacterExample, WordcraftContext } from '../../../context';
import { OperationType } from '@core/shared/types';
import { GeminiModel } from '..';

export function makePromptHandler(model: GeminiModel, context: WordcraftContext) {
  ...
}
Crie uma função generatePrompt() para receber a entrada da interface do usuário para a solicitação do modelo de IA.
  function generatePrompt(character: string) {
    const prefix = "Here's a character description: ";
    const suffix = "Introduce this character in the story.";

    if (character.trim() === '') {
      return 'Introduce a new character to the story.';
    } else {
      return `${prefix}${model.wrap(character)}\n${suffix}`;
    }
  }
Crie uma função getPromptContext() para montar a entrada da interface do usuário com os exemplos de respostas e crie o comando completo.
  function getPromptContext() {
    const examples = context.getExampleData(
      OperationType.NEW_CHARACTER
    );
    let promptContext = model.getPromptPreamble();
    examples.forEach((example) => {
      const { character, target } = example;
      const prompt = generatePrompt(character);
      promptContext += `${prompt} ${model.wrap(target)}\n\n`;
    });
    return promptContext;
  }
Para integrar o novo gerenciador de comando de caracteres:
No arquivo wordcraft/app/models/gemini/index.ts, importe o gerenciador de comando para a nova operação de caractere.
import {makePromptHandler as newCharacter} from './prompts/new_character';
Adicione uma definição de substituição para o gerenciador de solicitações newCharacter.
  override newCharacter = this.makePromptHandler(newCharacter);
Para registrar os parâmetros do comando com a definição do modelo:
No arquivo wordcraft/app/models/model.ts, adicione uma importação para a nova interface NewCharacterPromptParams.
import {
  ...
  NewCharacterPromptParams,
  ...
} from '@core/shared/interfaces';
Adicione parâmetros de comando newCharacter à classe de modelo.
  async newCharacter(params: NewCharacterPromptParams): Promise<ModelResults> {
    throw new Error('Not yet implemented');
  }
Testar o novo controle de escrita
O novo controle estará pronto para ser testado na interface do Wordcraft. Verifique se há erros de compilação no código antes de continuar.
Para testar o novo controle de caracteres:
Navegue até o diretório raiz do projeto Wordcraft.`
cd wordcraft/
Execute o projeto no modo de desenvolvimento:
npm run dev
No navegador da Web, acesse a interface do usuário do Wordcraft. O endereço específico é mostrado na saída do comando anterior, por exemplo:
http://localhost:3000/
No app Wordcraft, crie uma história nova ou abra uma existente.
Na área de edição da matéria, mova o cursor até o fim dela. Na guia "Controles" à direita, o controle introduzir caractere vai aparecer.
No campo introduce character, digite uma breve descrição do novo personagem e selecione o botão introduce character.
Outros recursos
Para mais informações sobre o projeto Wordcraft, consulte o repositório de código. Confira as mudanças descritas neste tutorial neste pull request.
Aplicativos de produção
Se você planeja implantar uma versão personalizada do Wordcraft para um grande público, saiba que o uso da API Google Gemini pode estar sujeito a limitação de taxa e outras restrições de uso. Se você está pensando em criar um aplicativo de produção com a API Gemini, como o Docs Agent, confira os serviços da Vertex AI do Google Cloud para aumentar a escalabilidade e a confiabilidade do seu app.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-24 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_63.txt ---

URL: https://ai.google.dev/gemini-api/tutorials/slides-advisor

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Aplicativo de chat
Assistente de código
Gerador de código do Flutter
Pesquisa de conteúdo
Agente de exploração de dados
Assistente de redação
Revisor do Apresentações Google
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Crie um revisor de slides de IA com o Gemini
Nesta página
Configurar o projeto
Criar um projeto do Apps Script
Preparar os arquivos do projeto
Receber o código do projeto
Conectar um projeto do Google Cloud
Configurar um projeto do Cloud
Criar uma conta de serviço
Criar e instalar a chave da conta de serviço
Monte, execute e personalize um complemento de revisão de slides para Apresentações do Google Workspace com este projeto de código. Seja uma apresentação por semana ou por ano, a maioria de nós precisa de ajuda para fazer isso direito. Você tende a colocar muita informação em um slide? Você esquece de dividir sua apresentação com recursos visuais? Talvez você até tenha um conjunto de diretrizes da sua organização sobre apresentação eficaz. Você leu esses artigos recentemente?
O projeto Slides Advisor é um complemento do Google Workspace de código aberto que usa tecnologia de inteligência artificial (IA) para analisar e dar feedback sobre suas apresentações, sempre que você precisar. O projeto usa os recursos de processamento de imagens e texto da API Gemini para analisar seus slides do Google em relação a um conjunto de diretrizes e informar como você está em relação a elas. Melhor ainda, você pode personalizar essas diretrizes para seguir as recomendações da sua organização ou ser lembrado de melhorar suas apresentações com base nas regras que você define para si mesmo.
Para conferir uma visão geral em vídeo do projeto e como ele pode ser estendido, incluindo insights dos desenvolvedores, acesse AI Slides Reviewer - Build with Google AI. Caso contrário, você pode começar a estender o projeto seguindo as instruções abaixo.
Figura 1. Complemento do Slides Advisor para as Apresentações Google em execução como painel da barra lateral.
Configurar o projeto
Estas instruções mostram como configurar o projeto do Slides Advisor para desenvolvimento e teste. As etapas gerais são criar o projeto do Google Apps Script, configurar um projeto do Google Cloud para acesso à API e definir algumas propriedades do script para o projeto.
Observação: para este projeto de código, você precisa ter acesso à API Gemini em um projeto do Google Cloud. Isso é descrito na seção Conectar o projeto do Google Cloud.
Criar um projeto do Apps Script
Esse projeto do Slides Advisor é executado como um complemento para o Apresentações Google. Você configura o projeto usando a interface da Web do Apresentações Google e cria um projeto do Apps Script para o código.
Para criar um novo projeto do Apps Script:
Acesse o app da Web Apresentações para Google Workspace.
Abra uma apresentação ou crie uma nova.
Na apresentação do Apresentações Google, selecione Extensões > Apps Script.
Depois de concluir essas etapas, você terá um novo projeto sem título na interface da Web do Apps Script, que é anexada à apresentação em que você começou. Dê um nome ao projeto para facilitar a localização.
Para nomear o projeto do Apps Script:
Na interface da Web do Apps Script, selecione o texto Untitled project.
Na caixa de diálogo "Renomear projeto", digite My Slides Advisor e selecione Renomear.
Preparar os arquivos do projeto
O projeto do Slides Advisor tem cinco arquivos de código, e você precisa configurá-los antes de copiar o código para o novo projeto do Apps Script. Esta seção descreve como preparar o projeto e receber o código.
Para preparar os arquivos do projeto:
Abra a interface da Web do Apps Script que contém o projeto My Slides Advisor.
No menu à esquerda, selecione a visualização < > Editor.
Renomeie o arquivo Code.gs para main.gs passando o cursor sobre o nome do arquivo de código Code.gs, selecionando Rename no menu de contexto e digitando main. A interface adiciona a extensão .gs automaticamente.
Para tornar o arquivo de manifesto appscript.json do projeto visível, selecione o ícone de engrenagem (Project Settings) no menu à esquerda e ative a opção Show "appscript.json" manifest file.
Na interface da Web do Apps Script, no menu à esquerda, selecione a visualização < > Editor.
Crie um arquivo de código ui.gs selecionando o ícone + (sinal de adição) à direita do cabeçalho Files, selecionando Script e inserindo ui.
Repita a etapa anterior para criar os arquivos de código slides.gs e ai.gs.
Seu projeto do Apps Script agora precisa conter os cinco arquivos de código a seguir, que estão quase vazios:
appscript.json
main.gs
ui.gs
slides.gs
ai.gs
Na próxima etapa, extraia o código do projeto do repositório e copie-o para seu projeto do Apps Script.
Receber o código do projeto
O código do projeto do Slides Advisor é hospedado em um repositório de código. Você precisa copiar esse código para o projeto do Apps Script para trabalhar com ele. Esta seção descreve como conseguir o código do projeto.
Para conseguir o código do projeto:
Navegue até o repositório de código do projeto para o arquivo de manifesto do projeto, appsscript.json
Copie o conteúdo desse arquivo de código para a área de transferência.
Navegue de volta à interface da Web do Apps Script, selecione o nome de arquivo appsscript.json e cole o código no painel do editor de código, substituindo qualquer código anterior.
Repita esse procedimento para os outros quatro arquivos de código:
Copie o código main.js para o arquivo main.gs.
Copie o código ui.js para o arquivo ui.gs.
Copie o código slides.js para o arquivo slides.gs.
Copie o código ai.js para o arquivo ai.gs.
Conectar um projeto do Google Cloud
Esse projeto usa um projeto do Google Cloud para acessar os modelos de IA do Gemini. O Google Cloud oferece políticas específicas de privacidade de dados e uma série de serviços de software úteis para criar aplicativos como o Slides Advisor. Para conectar o código do complemento à API Gemini, crie um projeto do Cloud com acesso à API de IA, crie uma conta de serviço para o projeto, crie uma chave para a conta de serviço e instale essa chave no projeto do complemento.
Configurar um projeto do Cloud
O projeto do Cloud que você usa para se conectar à API Gemini precisa ter o serviço da API Vertex AI ativado, e você precisa criar uma conexão autenticada do complemento Slides Advisor para esse projeto. A API Vertex AI também exige que o faturamento seja ativado nos projetos em que você a usa.
Para configurar um projeto do Cloud com acesso à API Vertex AI:
Acesse o console do Google Cloud e faça login, se necessário.
No console do Google Cloud, selecione um projeto do Cloud ou crie um novo.
Na página Painel do console do seu projeto, no painel APIs, selecione Acessar a visão geral das APIs ou acesse https://console.cloud.google.com/apis/.
Na parte de cima da página APIs e serviços, selecione + ATIVAR APIS E SERVIÇOS.
Na página Biblioteca de APIs, pesquise vertex ai api, selecione a opção API Vertex AI e clique no botão Ativar.
Se ainda não estiver ativado, ative o faturamento no seu projeto do Google Cloud e, em seguida, ative a API AI selecionando o botão Ativar na página do console da API Vertex AI.
Para verificar se a API Vertex AI está ativada, acesse a página APIs e serviços do seu projeto. A API Vertex AI vai aparecer nesta página.
Criar uma conta de serviço
O complemento Slides Advisor exige uma conexão autenticada com seu projeto do Cloud para acessar a API Vertex AI e os modelos do Gemini. Para criar essa conexão, primeiro gere uma conta de serviço no seu projeto do Cloud que tenha acesso à API Vertex AI. O projeto do Slides Advisor se conecta usando essa conta de serviço.
Para criar uma conta de serviço para o complemento Slides Advisor:
No console do Google Cloud, navegue até a página APIs e serviços do seu projeto do Cloud.
No lado esquerdo da página, selecione Credenciais.
Na parte de cima da página, selecione + CRIAR CREDENCIAIS > Conta de serviço.
Na página Criar conta de serviço, na seção Detalhes da conta de serviço, insira um nome, um ID e uma descrição da conta de serviço.
Selecione Criar e continuar para criar a conta de serviço.
Na seção Conceder acesso a essa conta de serviço ao projeto, selecione o controle Papel.
Na pesquisa do campo Filtro, selecione o conjunto de permissões Usuário da Vertex AI e clique em Continuar.
Para concluir a criação da conta de serviço, selecione Concluído.
Para mais informações sobre como criar contas de serviço, consulte a documentação Criar contas de serviço do Google Cloud.
Criar e instalar a chave da conta de serviço
O projeto do Slides Advisor precisa ser capaz de fazer a autenticação na conta de serviço criada no procedimento anterior. É possível ativar essa autenticação criando uma chave para a conta de serviço e configurando essa chave no seu projeto do Slides Advisor Apps Script como uma propriedade de script. O procedimento a seguir explica como criar a chave e configurá-la no projeto.
Aviso: trate o arquivo de chave JSON da conta de serviço e o conteúdo dele como uma senha e mantenha-os seguros. Para conferir algumas práticas recomendadas gerais de segurança de chaves, consulte este artigo de suporte.
Para criar e configurar uma chave de conta de serviço:
No console do Google Cloud, navegue até a página APIs e serviços do seu projeto do Cloud.
No lado esquerdo da página, selecione Credenciais.
Na seção Contas de serviço, encontre a conta de serviço que você criou, selecione o endereço de e-mail da conta ou o ícone de lápis para editá-la.
Na janela de edição da conta de serviço, perto da parte de cima da página, selecione o título da guia CHAVES.
Na seção Chaves, selecione Adicionar chave > Criar nova chave.
Na caixa de diálogo Criar chave privada para..., selecione JSON e clique em Criar. Essa etapa cria um arquivo de chave chamado projectid-hashcode.json e faz o download automático dele no computador.
Abra o arquivo projectid-hashcode.json salvo e copie o conteúdo.
Abra a interface da Web do Apps Script que contém o projeto My Slides Advisor e, no menu à esquerda, selecione a visualização Settings.
Na seção Propriedades do script, selecione o botão Editar propriedades do script e, em seguida, o botão Adicionar propriedade do script.
No novo campo Property, digite SERVICE_ACCOUNT_KEY e, no campo Value, copie o conteúdo do arquivo projectid-hashcode.json baixado.
Salve a nova propriedade selecionando o botão Salvar propriedades do script.
Para mais informações sobre a criação de chaves de contas de serviço, consulte a documentação Criar e excluir chaves de contas de serviço do Google Cloud.
Testar o projeto do complemento
Para testar o projeto do Slides Advisor, é necessário criar uma implantação de teste do código do complemento e instalar essa implantação de teste. Nesta configuração de teste, o projeto só está disponível na apresentação do Apresentações Google em que você iniciou o projeto do complemento do Apps Script e em nenhuma outra apresentação do Apresentações. Saiba mais sobre como implantar seu complemento para uso mais amplo na documentação do Apps Script do Google Workspace, Criar e gerenciar implantações (link em inglês).
Para implantar e testar o código do projeto do Apps Script:
Na parte de cima da interface da Web do Apps Script, selecione Implantar > Testar implantações.
Na caixa de diálogo Test deployments, ao lado de Select type, selecione o ícone de engrenagem e Google Workspace Add-on.
Ao lado do título "Aplicativos", selecione o botão Instalar.
Deixe as configurações padrão para Testar o código mais recente e selecione Concluído.
Navegue pela apresentação do Apresentações Google conectada ao seu projeto do Apps Script e recarregue a página da Web.
No canto inferior direito do app da Web do Apresentações, selecione o ícone ( < ) para abrir o painel lateral e, em seguida, selecione o ícone de olho preto e branco para abrir o painel Slides Advisor.
Depois de concluir essa etapa e executar o complemento, você poderá modificá-lo para usar diretrizes diferentes ou seguir um fluxo de trabalho diferente. Consulte as próximas seções para ver instruções sobre como fazer algumas modificações básicas no complemento Slides Advisor.
Modificar o comportamento da avaliação
É possível mudar o comportamento de revisão do Slides Advisor, tanto em termos do que você recebe da API Gemini quanto da interface do usuário fornecida pelo complemento, modificando o código do projeto. Este tutorial se concentra em mudar as instruções de solicitação para modificar o comportamento de análise dos slides de apresentação. Para mais informações sobre como estender a interface do usuário do Apresentações Google usando o Apps Script, consulte Como estender as Apresentações Google.
Mudar as diretrizes de avaliação
O Slides Advisor vem programado com um conjunto básico de diretrizes de revisão de slides com categorias para simplicidade, cor e tipografia, estrutura e espaço em branco, gráficos e ícones. As diretrizes de revisão são apenas instruções de texto incluídas em um comando pela API Gemini, junto com uma imagem de um slide selecionado e as notas do orador.
É possível mudar o comportamento de análise do complemento mudando as instruções de texto. Por exemplo, é possível instruir o modelo do Gemini a gerar a revisão com a classificação da categoria na mesma linha que o título da categoria ou mudar o nome de uma categoria.
Para mudar o local da classificação e o nome de uma categoria:
Abra a interface da Web do Apps Script que contém o projeto My Slides Advisor. Se necessário, navegue até a janela do projeto abrindo a apresentação do Google Slides que contém o projeto do Apps Script e selecionando Extensões > Apps Script.
No menu à esquerda, selecione a visualização < > Editor e selecione o nome de arquivo ai.gs.
No arquivo de código ai.gs, localize a constante de string SYSTEM_PROMPT e modifique as instruções da seguinte maneira com o texto em negrito:
const SYSTEM_PROMPT = `
...
For each of the following categories evaluate the given slide. Score each
category on a scale of 0 to 100, show the score next to the category heading,
and concisely explain the reasoning. Do not suggest improvements if the score
is 80 or above.
Na mesma constante de string SYSTEM_PROMPT, mude o texto da categoria Simplicity para Message:
const SYSTEM_PROMPT = `
...
* Message -- Slides should focus on one main idea per slide and ...
Salve as mudanças no arquivo de código ai.gs.
Navegue pela apresentação do Google Slides conectada ao seu projeto do Apps Script, atualize a página da Web e teste as mudanças no complemento executando-o novamente.
Se você ainda não tiver configurado uma implantação de teste para o complemento do Slides Advisor, siga as instruções em Testar o projeto do complemento.
É possível remover, substituir ou reescrever as instruções da categoria de avaliação na constante de string SYSTEM_PROMPT para corresponder aos requisitos de avaliação. Se você quiser testar diferentes abordagens de comando de revisão ou reescrever todo o comando de revisão, confira o aplicativo da Web do Google AI Studio. Esse app permite criar protótipos, testar e salvar comandos para o Gemini em uma interface conveniente e usa a mesma API Gemini do projeto Slides Advisor. Para mais informações sobre o uso do AI Studio, consulte o guia de início rápido do AI Studio.
Mudar a configuração do comportamento do modelo
A API Gemini oferece várias configurações para alterar a operação geral do modelo em resposta a uma solicitação. Especificamente, a configuração de temperatura do modelo permite definir a variação permitida do modelo em uma resposta, sendo zero a menor e 1 a maior. Definir esse valor em 0,1 produz respostas muito consistentes, mas esse comportamento pode parecer repetitivo e menos útil para os usuários que recebem feedback de revisão. Considere definir um valor de temperatura mais alto e lembre-se de que, quanto maior a temperatura, mais inconsistentes seus resultados podem ser, o que pode incluir a implementação de instruções de maneira diferente e até mesmo o completo desconsideramento de algumas instruções.
Para aumentar a temperatura das respostas às avaliações:
Abra a interface da Web do Apps Script que contém o projeto My Slides Advisor.
No menu à esquerda, selecione a visualização < > Editor e selecione o nome de arquivo ai.gs.
No arquivo de código ai.gs, localize a função analyzeSlides() e modifique a constante generationConfig definindo o valor temperature como 0.3:
function analyzeSlides(slide) {

    const generationConfig = {
        temperature: 0.3,
        maxOutputTokens: 1024 * 2,
    };
Salve as mudanças no arquivo de código ai.gs.
Navegue pela apresentação do Google Slides conectada ao seu projeto do Apps Script, atualize a página da Web e teste as mudanças no complemento executando-o novamente.
Para mais informações sobre as configurações de comportamento do modelo, consulte a documentação da API Gemini para GenerationConfig.
Outros recursos
Para mais informações sobre o projeto do Slides Advisor, consulte o repositório de código. Se você precisar de ajuda para criar o aplicativo ou quiser colaborar com outros desenvolvedores, confira o servidor Google Developers Community Discord. Para conferir mais projetos do Build with Google AI, acesse a playlist de vídeos.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_64.txt ---

URL: https://ai.google.dev/gemini-api/docs/troubleshooting

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Guia de solução de problemas
Nesta página
Códigos de erro do serviço de back-end da API Gemini
Códigos de erro do SDK do cliente
Verificar se há erros nos parâmetros do modelo nas chamadas de API
Confira se você tem o modelo certo
Problemas de segurança
Python
Go
Use este guia para diagnosticar e resolver problemas comuns que surgem ao chamar a API Gemini. Você pode encontrar problemas com o serviço de back-end da API Gemini ou com os SDKs do cliente. Nossos SDKs de cliente têm código aberto nos seguintes repositórios:
python-genai (link em inglês)
js-genai (link em inglês)
generative-ai-go
Se você tiver problemas com a chave de API, verifique se ela foi configurada corretamente de acordo com o guia de configuração de chaves de API.
Códigos de erro do serviço de back-end da API Gemini
A tabela a seguir lista códigos de erro de back-end comuns que você pode encontrar, além de explicações sobre as causas e etapas de solução de problemas:
Código HTTP Status Descrição Exemplo Solução
400 INVALID_ARGUMENT O corpo da solicitação está incorreto. Há um erro de digitação ou um campo obrigatório está faltando na solicitação. Consulte a referência da API para conferir o formato da solicitação, exemplos e versões compatíveis. O uso de recursos de uma versão mais recente da API com um endpoint mais antigo pode causar erros.
400 FAILED_PRECONDITION O nível sem custo financeiro da API Gemini não está disponível no seu país. Ative o faturamento no seu projeto no Google AI Studio. Você está fazendo uma solicitação em uma região em que o nível sem custo financeiro não é aceito e não ativou o faturamento no projeto no Google AI Studio. Para usar a API Gemini, você precisa configurar um plano pago usando o Google AI Studio.
403 PERMISSION_DENIED Sua chave de API não tem as permissões necessárias. Você está usando a chave de API errada. Você está tentando usar um modelo ajustado sem passar pela autenticação adequada. Verifique se a chave de API está definida e tem o acesso correto. E faça a autenticação adequada para usar modelos ajustados.
404 NOT_FOUND O recurso solicitado não foi encontrado. Um arquivo de imagem, áudio ou vídeo referenciado na sua solicitação não foi encontrado. Verifique se todos os parâmetros na solicitação são válidos para a versão da API.
429 RESOURCE_EXHAUSTED Você excedeu o limite de taxa. Você está enviando muitas solicitações por minuto com a API Gemini do nível sem custo financeiro. Verifique se você está dentro do limite de taxa do modelo. Solicite um aumento de cota, se necessário.
500 INTERNAL Ocorreu um erro inesperado no Google. O contexto de entrada é muito longo. Reduza o contexto de entrada ou mude temporariamente para outro modelo (por exemplo, do Gemini 1.5 Pro para o Gemini 1.5 Flash) e veja se funciona. Ou aguarde um pouco e tente novamente. Se o problema persistir após a nova tentativa, informe-o usando o botão Enviar feedback no Google AI Studio.
503 INDISPONÍVEL O serviço pode estar temporariamente sobrecarregado ou indisponível. O serviço está temporariamente sem capacidade. Mude temporariamente para outro modelo (por exemplo, do Gemini 1.5 Pro para o Gemini 1.5 Flash) e veja se funciona. Ou aguarde um pouco e tente novamente. Se o problema persistir após a nova tentativa, informe-o usando o botão Enviar feedback no Google AI Studio.
504 DEADLINE_EXCEEDED O serviço não consegue concluir o processamento dentro do prazo. Sua instrução (ou contexto) é muito grande para ser processada a tempo. Defina um "tempo limite" maior na solicitação do cliente para evitar esse erro.
Códigos de erro do SDK do cliente
A tabela a seguir lista códigos de erro do SDK do cliente Python comuns que você pode encontrar, além de explicações sobre as causas:
Tipo de exceção/erro Turma Descrição
APIError google.genai.errors.APIError Erros gerais gerados pela API GenAI.
ClientError google.genai.errors.ClientError Erro do cliente gerado pela API GenAI.
ServerError google.genai.errors.ServerError Erro do servidor gerado pela API GenAI.
UnknownFunctionCallArgumentError google.genai.errors.UnknownFunctionCallArgumentError Gerado quando o argumento de chamada de função não pode ser convertido na anotação de parâmetro.
UnsupportedFunctionError google.genai.errors.UnsupportedFunctionError É gerado quando a função não tem suporte.
FunctionInvocationError google.genai.errors.FunctionInvocationError Gerado quando a função não pode ser invocada com os argumentos fornecidos.
ValidationError pydantic.ValidationError Gerada pelo Pydantic sempre que ele encontra um erro nos dados que está validando. Consulte Como lidar com erros no Pydantic.
Você também vai encontrar todos os erros na classe errors.
Para processar erros gerados pelo SDK, use um bloco try-except:
from google.genai import errors

try:
    client.models.generate_content(
        model="invalid-model-name",
        contents="What is your name?",
    )
except errors.APIError as e:
    print(e.code) # 404
    print(e.message)
Verificar se há erros nos parâmetros do modelo nas chamadas de API
Verifique se os parâmetros do modelo estão dentro dos seguintes valores:
Parâmetro do modelo Valores (intervalo)
Contagem de candidatos 1 a 8 (número inteiro)
Temperatura 0.0-1.0
Máximo de tokens de saída Use get_model (Python) para determinar o número máximo de tokens do modelo que você está usando.
TopP 0.0-1.0
Além de verificar os valores dos parâmetros, verifique se você está usando a versão correta da API (por exemplo, /v1 ou /v1beta) e modelo que ofereça suporte aos recursos necessários. Por exemplo, se um recurso estiver na versão Beta, ele só vai estar disponível na versão da API /v1beta.
Confira se você tem o modelo certo
Verifique se você está usando um modelo compatível listado na nossa página de modelos.
Problemas de segurança
Se um comando for bloqueado devido a uma configuração de segurança na chamada de API, revise o comando em relação aos filtros definidos na chamada de API.
Se você encontrar BlockedReason.OTHER, a consulta ou resposta pode violar os termos de serviço ou não ter suporte.
Problema de recitação
Se o modelo parar de gerar saída devido ao motivo RECITATION, isso significa que a saída do modelo pode se parecer com determinados dados. Para corrigir isso, tente tornar a instrução / o contexto o mais exclusivo possível e use uma temperatura mais alta.
Melhorar a saída do modelo
Para saídas de modelos de maior qualidade, escreva comandos mais estruturados. A página Introdução ao design de comandos apresenta alguns conceitos básicos, estratégias e práticas recomendadas para você começar.
Se você tiver centenas de exemplos de bons pares de entrada/saída, também poderá ajustar o modelo.
Entender os limites de token
Leia nosso guia de tokens para entender melhor como contar tokens e os limites deles.
Problemas conhecidos
A API oferece suporte apenas a alguns idiomas. Enviar comandos em idiomas não compatíveis pode gerar respostas inesperadas ou até mesmo bloqueadas. Consulte as línguas disponíveis para atualizações.
Informar um bug
Participe da discussão no fórum para desenvolvedores de IA do Google se tiver dúvidas.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_65.txt ---

URL: https://ai.google.dev/gemini-api/docs/troubleshoot-ai-studio

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Resolver problemas do Google AI Studio
Nesta página
Entenda os erros 403 de acesso restrito
Resolver respostas "Sem conteúdo" no Google AI Studio
Verificar o uso e os limites de tokens
Esta página fornece sugestões para solucionar problemas do Google AI Studio se você encontrar problemas.
Entenda os erros 403 de acesso restrito
Se aparecer o erro 403 "Acesso restrito", você está usando o Google AI Studio em um maneira que não siga os Termos de Serviço. Um motivo comum é Você não está em uma região com suporte.
Resolver respostas "Sem conteúdo" no Google AI Studio
Uma mensagem warning Sem conteúdo aparece em Google AI Studio se o conteúdo for bloqueado por algum motivo. Para conferir mais detalhes, mantenha o ponteiro do mouse sobre Nenhum conteúdo e clique warning Segurança.
Se a resposta foi bloqueada devido às configurações de segurança e você considerou os riscos de segurança do caso de uso, pode modificar configurações de segurança para influenciar a resposta retornada.
Se a resposta estiver bloqueada, mas não devido às configurações de segurança, a consulta ou pode violar os Termos de Serviço ou não ter suporte de alguma outra forma.
Verificar o uso e os limites de tokens
Quando um comando estiver aberto, clique no botão Text Preview na parte de baixo do mostra os tokens atuais usados para o conteúdo do comando e o contagem máxima de tokens para o modelo que está sendo usado.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_66.txt ---

URL: https://ai.google.dev/gemini-api/docs/workspace

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Acesse o Google AI Studio com sua conta do Workspace
Nesta página
Solução de problemas
Ativar o AI Studio para usuários do Workspace
Todos os usuários do Google Workspace têm acesso à IA Studio por padrão. Se você é usuário do Workspace e quer começar a usar AI Studio, confira Guia de início rápido do AI Studio.
Solução de problemas
Se o acesso ao AI Studio estiver desativado na sua conta do Google Workspace, você poderá você verá um erro como este:
We are sorry, but you do not have access to Google AI Studio. Please contact your Organization Administrator for access.
Se você acha que deveria ter acesso ao AI Studio, entre em contato com seu Workspace administrador.
Ativar o AI Studio para usuários do Workspace
Importante :esta seção é destinada aos administradores do Google Workspace.
Como administrador do Google Workspace, você controla quem usa o AI Studio:
O AI Studio está ativado por padrão em todas as edições.
É possível ativar ou desativar o AI Studio para conjuntos de usuários de um lado para o outro unidades organizacionais.
Edições do Google Workspace for Education: os usuários com menos de 18 anos não têm impedidas de usar o AI Studio com o Google Workspace por Google Workspace for Education. Isso é válido mesmo quando a configuração do AI Studio Saiba mais em Controlar o acesso aos Serviços do Google por idade.
Para ativar ou desativar o AI Studio para os usuários da organização, consulte Ativar ou desativar o Google AI Studio para os usuários.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-25 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_67.txt ---

URL: https://ai.google.dev/gemini-api/terms

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Termos de Serviço adicionais da API Gemini
Nesta página
Restrições de idade
Restrições de uso
Uso do conteúdo gerado
Serviços não pagos
Como o Google usa seus dados
Serviços pagos
Como o Google usa seus dados
Condições de pagamento
Observação: Atualizamos nossos Termos de Serviço Adicionais da API Gemini em 5 de fevereiro de 2024, adicionando modelos "experimentais" como não sendo para uso em produção sob os termos de "Restrições de Uso" .
Em vigor a partir de 5 de fevereiro de 2025
Para usar a API Gemini, o Google AI Studio e outros serviços para desenvolvedores do Google que fazem referência a estes termos (coletivamente, "APIs" ou "Serviços"), você precisa aceitar (1) os Termos de Serviço das APIs do Google ("Termos das APIs") e (2) estes Termos de Serviço adicionais da API Gemini ("Termos adicionais"). Os termos não definidos nestes Termos adicionais têm o significado atribuído nos Termos das APIs.
Restrições de idade
Você precisa ter pelo menos 18 anos para usar as APIs. Não é permitido usar os Serviços como parte de um site, aplicativo ou outro serviço (coletivamente, "Clientes de API") direcionado a usuários menores de 18 anos ou que possa ser acessado por eles.
Restrições de uso
Você pode usar Clientes de API para produção, mas o Google pode aplicar limites de taxa. Você não pode usar nenhum Serviço identificado como "Prévia" ou "Experimental" para produção.
Você só pode acessar os Serviços (ou disponibilizar Clientes de API aos usuários) dentro de uma região disponível. É permitido usar somente os Serviços pagos ao disponibilizar Clientes de API aos usuários no Espaço Econômico Europeu, na Suíça ou no Reino Unido.
Você não pode usar os Serviços para desenvolver modelos que concorrem com os Serviços (por exemplo, API Gemini ou Google AI Studio). Você também não pode tentar usar engenharia reversa, extrair ou replicar qualquer componente dos Serviços, incluindo os dados ou modelos de base (por exemplo, pesos dos parâmetros).
Além da seção "Proibições das APIs" nos Termos das APIs, você precisa obedecer à nossa Política de uso proibido, que informa mais detalhes sobre a conduta adequada ao usar os Serviços.
Os Serviços incluem recursos de segurança para bloquear conteúdo nocivo, como aquele que viola nossa Política de uso proibido. Não tente ignorar essas medidas de proteção nem usar conteúdo que viole os Termos das APIs ou estes Termos adicionais. Você deverá apenas reduzir as configurações de segurança se for necessário e adequado para seu caso de uso. Os aplicativos que têm configurações de segurança menos restritivas podem estar sujeitos à análise e aprovação do Google."
Você não pode usar os Serviços na prática clínica, para oferecer orientação médica ou de qualquer maneira que seja supervisionada ou que exija aprovação de uma agência reguladora de dispositivos médicos.
Uso do conteúdo gerado
Alguns dos nossos Serviços permitem que você gere conteúdo original. O Google não reivindicará a propriedade desse conteúdo. Você confirma que o Google pode gerar um conteúdo igual ou semelhante para outras pessoas e que reservamos todos os direitos para fazer isso.
Conforme exigido pelos Termos das APIs, você obedecerá à legislação aplicável ao uso de conteúdo gerado, que pode precisar do fornecimento de atribuição aos seus usuários quando retornado como parte de uma chamada de API. Tenha critério antes de usar o conteúdo gerado, incluindo código. Você é responsável pelo uso que faz do conteúdo gerado e pelo uso feito por qualquer pessoa com quem você o compartilhe.
Serviços não pagos
Quaisquer Serviços que sejam oferecidos sem custo financeiro, como interações diretas com o Google AI Studio ou cota não paga na API Gemini, são Serviços não pagos ("Serviços não pagos").
Como o Google usa seus dados
Quando você usa Serviços não pagos, incluindo, por exemplo, o Google AI Studio e a cota não paga na API Gemini, o Google usa o conteúdo que você envia aos Serviços e qualquer resposta gerada para fornecer, melhorar e desenvolver produtos, serviços e tecnologias de aprendizado de máquina, inclusive recursos, produtos e serviços corporativos do Google, de acordo com nossa Política de Privacidade.
Para fins de qualidade e aprimoramento dos nossos produtos, revisores humanos podem ler, fazer anotações e tratar suas entradas e saídas das APIs. O Google toma medidas para proteger sua privacidade como parte desse processo. Isso inclui desassociar esses dados da sua Conta do Google, chave de API e projeto do Cloud antes que sejam vistos ou anotados por revisores. Não envie informações sensíveis, confidenciais ou pessoais para os Serviços não pagos.
A licença que você concede ao Google de acordo com a seção "Envio de conteúdo" nos Termos das APIs também se estende, na medida exigida pela legislação aplicável, ao nosso uso, a qualquer conteúdo (por exemplo, comandos, incluindo instruções de sistema, conteúdo armazenado em cache e arquivos como imagens, vídeos ou documentos associados) que você envia aos Serviços e a qualquer resposta gerada.
O Google só usa conteúdo que você importa ou faz upload no nosso recurso de ajustes de modelos para essa finalidade explícita. Os ajustes de conteúdo podem ser retidos em conexão com seus modelos ajustados para fins de reajuste quando os modelos compatíveis são mudados. Quando você exclui um modelo ajustado, o conteúdo de ajustes relacionado também é removido.
Se você estiver no Espaço Econômico Europeu, na Suíça ou no Reino Unido, os termos de "Como o Google usa seus dados" em "Serviços pagos" são válidos para todos os Serviços, incluindo o Google AI Studio e a cota não paga na API Gemini, mesmo que sejam oferecidos sem custo financeiro.
Serviços pagos
Quando um Serviço é oferecido mediante uma taxa, ele é considerado pago ("Serviços pagos"). Ao ativar uma conta do Cloud Billing, todo uso da API Gemini e do Google AI Studio é um "Serviço Pago" com relação a como o Google usa seus dados, mesmo ao usar serviços oferecidos sem custo financeiro, como o Google AI Studio e a cota não paga da API Gemini.
Para os Serviços pagos, "Google", conforme usado nestes Termos, tem o significado atribuído aqui.
Como o Google usa seus dados
Quando você usa os Serviços pagos, incluindo, por exemplo, a cota paga da API Gemini, o Google não usa seus comandos (incluindo instruções de sistema, conteúdo armazenado em cache e arquivos como imagens, vídeos ou documentos associados) ou respostas para melhorar os produtos. Seus comandos e respostas serão tratados de acordo com o Adendo de tratamento de dados para produtos em que o Google é um operador de dados. Para serviços pagos, o Google registra prompts e respostas por um período limitado, exclusivamente com o propósito de detectar violações da Política de uso proibido e quaisquer divulgações legais ou regulatórias necessárias. Esses dados podem ser armazenados temporariamente ou em cache em qualquer país em que o Google ou seus agentes tenham instalações.
Outros dados que coletamos ao fornecer os Serviços pagos a você, como informações e configurações da conta, histórico de faturamento, comunicações diretas e feedback, bem como detalhes de uso (por exemplo, informações sobre uso que incluem o número de tokens por comando e resposta, status operacional, acionadores de filtros de segurança, relatórios de erros e falhas de software, detalhes de autenticação, métricas de qualidade e desempenho e outros detalhes técnicos necessários para o Google operar e manter os Serviços, como identificadores de dispositivo, de cookies ou tokens e endereços IP), permanecem sujeitos aos Termos de Proteção de Dados entre Controladores do Google e à Política de Privacidade do Google mencionada nos Termos das APIs.
Ao usar o Embasamento com a Pesquisa Google, dados adicionais são coletados e usados, conforme detalhado na seção "Embasamento com a Pesquisa Google" abaixo.
Condições de pagamento
O faturamento e os pagamentos de Serviços pagos são processados pelo Cloud Billing no Google Cloud Platform.
Portanto, as seções 2 (Condições de pagamento) e 14 (Disposições gerais) dos Termos de Serviço do Google Cloud Platform regem pagamentos, faturas, faturamentos, disputas de pagamento e problemas relacionados, enquanto estes Termos regem seu uso dos Serviços pagos. Estes Termos não regem seu uso direto de qualquer serviço do Google Cloud Platform (incluindo os listados no Resumo dos serviços do Google Cloud Platform).
As "Taxas" (conforme usado nos Termos de Serviço do Google Cloud Platform) dos Serviços pagos estão especificadas na nossa página de preços. O Google pode fazer alterações nesses preços periodicamente, que entram em vigor 30 dias após a publicação, a menos que seja especificado de outra forma (ou no caso de novos Serviços pagos, que os preços entram em vigor imediatamente, salvo especificação em contrário). Seu uso contínuo dos Serviços pagos constitui seu consentimento com essas mudanças.
Embasamento com a Pesquisa Google
"Embasamento com a Pesquisa Google" é um Serviço que fornece Resultados embasados e Sugestões de pesquisa, disponível no Google AI Studio (como um Serviço não pago) e na API Gemini (como um Serviço pago). "Resultados embasados" significa respostas que o Google gera usando o comando do usuário final, as informações contextuais que você envia (conforme aplicável) e os resultados do mecanismo de pesquisa do Google. "Sugestões de pesquisa" (também conhecidas como Pontos de entrada de pesquisa) significa sugestões de pesquisa que o Google fornece com os Resultados embasados. Se um Resultado embasado recebe um clique, termos independentes (e não estes) regem a página de destino. Se uma Sugestão de pesquisa recebe um clique, os Termos de Serviço do Google regem a página de destino google.com. "Links" são qualquer outra forma de buscar páginas da Web (incluindo hiperlinks e URLs), que podem estar em um Resultado embasado ou uma Sugestão de pesquisa. Os Links também incluem títulos ou rótulos fornecidos com essas formas de buscar páginas da Web. Com exceção dos seus domínios da Web, você não declarará direitos de propriedade intelectual sobre quaisquer Sugestões de pesquisa ou Links nos Resultados embasados.
Restrições de uso
Só é permitido usar o Embasamento com a Pesquisa Google em um aplicativo pertencente e operado por você, bem como exibir apenas os Resultados embasados com as Sugestões de pesquisa associadas ao usuário final que enviou o comando.
Você não poderá, nem permitirá ao usuário final ou qualquer terceiro, armazenar (exceto conforme definido abaixo), salvar em cache, copiar, colocar em uma página da Web, implementar qualquer rastreamento de cliques, de Links ou outro tipo de monitoramento (exceto conforme definido abaixo), distribuir, revender, analisar, treinar ou aprender de qualquer forma com os Resultados embasados ou as Sugestões de pesquisa.
Você pode armazenar o texto dos Resultados embasados (exceto os Links): (1) que exibiu por até 30 (trinta) dias apenas para avaliar e otimizar a exibição dos Resultados embasados no seu aplicativo; e (2) no histórico de conversa de um usuário final do seu aplicativo por até 6 (seis) meses apenas para permitir que o usuário final veja o histórico de conversa.
Você pode monitorar as interações do usuário final com a interface do seu aplicativo. No entanto, você não poderá monitorar se essas interações ocorreram especificamente com uma determinada Sugestão de pesquisa ou Resultado embasado (em cada caso, total ou parcialmente, incluindo qualquer Link específico).
A menos que permitido pelo Google por escrito, você: (1) não modificará nem intercalará qualquer outro conteúdo com os Resultados embasados ou as Sugestões de pesquisa; e (2) não colocará nenhum conteúdo intersticial entre qualquer Link ou Sugestão de pesquisa e a página de destino associada, não redirecionará usuários finais para fora das páginas de destino nem minimizará, removerá ou inibirá de qualquer forma a exibição total e completa de qualquer página de destino.
Coleta de dados e como o Google usa seus dados
Além dos termos gerais acima ("Como o Google usa seus dados" em "Serviços não pagos" e "Serviços pagos"), ao usar o Embasamento com a Pesquisa Google, o Google armazenará comandos, informações contextuais que você enviar e saídas por 30 (trinta) dias para fins de criação dos Resultados embasados e das Sugestões de pesquisa, e as informações armazenadas podem ser usadas para depuração e teste dos sistemas que apoiam o Embasamento com a Pesquisa Google. Ao utilizar o Embasamento com a Pesquisa Google pela cota paga da API Gemini, esse tratamento para depuração e teste dos sistemas está de acordo com o Adendo de tratamento de dados para produtos em que o Google é um operador de dados.
Essa subseção "Embasamento com a Pesquisa Google" permanecerá vigente após a rescisão do Contrato, conforme aplicável.
As Diretrizes do Aplicativo Cliente são válidas para seu uso do Embasamento com a Pesquisa Google. Para as finalidades das Diretrizes do Aplicativo Cliente, seus aplicativos que usam o Embasamento com a Pesquisa Google são considerados Aplicativos aprovados.
Exonerações de responsabilidade
Os Serviços incluem tecnologia experimental e podem, às vezes, fornecer conteúdo impreciso ou ofensivo que não representa as opiniões do Google.
Tenha critério antes de confiar, publicar ou usar de qualquer forma o conteúdo fornecido pelos Serviços.
Não confie nos Serviços para aconselhamento médico, jurídico, financeiro ou de outra natureza profissional. Qualquer conteúdo sobre esses assuntos é oferecido somente para fins informativos e não substitui a orientação de um profissional qualificado. O conteúdo não constitui um tratamento ou diagnóstico médico.
Observação: as versões anteriores destes Termos adicionais estão arquivadas aqui.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-19 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_68.txt ---

URL: https://ai.google.dev/gemini-api/docs/available-regions

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Regiões disponíveis para o Google AI Studio e a API Gemini
Nesta página
Regiões disponíveis
Se você chegou a esta página depois de tentar abrir o Google AI Studio, talvez seja porque ele não está disponível na sua região ou porque você não atende aos requisitos de idade (18 anos ou mais) para acessar. Saiba mais sobre as regiões disponíveis na próxima seção e outros requisitos nos termos de serviço.
Regiões disponíveis
Observação: para usuários do Colab, as restrições de região são aplicadas com base na região em que a instância do Colab está, e não na região em que o usuário está. É possível verificar o local da instância do Colab usando !curl ipinfo.io
A API Gemini e o Google AI Studio estão disponíveis nos seguintes países e territórios. Se você não estiver em um desses países ou territórios, teste a API Gemini na Vertex AI:
Albânia
Argélia
Samoa Americana
Angola
Anguila
Antártida
Antígua e Barbuda
Argentina
Armênia
Aruba
Austrália
Áustria
Azerbaijão
Bahamas
Barein
Bangladesh
Barbados
Bélgica
Belize
Benin
Bermudas
Butão
Bolívia
Bósnia
Botsuana
Brasil
Território Britânico do Oceano Índico
Ilhas Virgens Britânicas
Brunei
Bulgária
Burkina Fasso
Burundi
Cabo Verde
Camboja
Camarões
Canadá
Países Baixos Caribenhos
Ilhas Cayman
República Centro-Africana
Chade
Chile
Ilha Christmas
Ilhas Cocos (Keeling)
Colômbia
Comores
Ilhas Cook
Costa do Marfim
Costa Rica
Croácia
Curaçao
República Tcheca
República Democrática do Congo
Dinamarca
Djibuti
Dominica
República Dominicana
Equador
Egito
El Salvador
Guiné Equatorial
Eritreia
Estônia
Suazilândia
Etiópia
Ilhas Malvinas (Falkland)
Ilhas Faroé
Fiji
Finlândia
França
Gabão
Gâmbia
Geórgia
Alemanha
Gana
Gibraltar
Grécia
Groenlândia
Granada
Guam
Guatemala
Guernsey
Guiné
Guiné-Bissau
Guiana
Haiti
Ilhas Heard e McDonald
Herzegovina
Honduras
Hungria
Islândia
Índia
Indonésia
Iraque
Irlanda
Ilha de Man
Israel
Itália
Jamaica
Japão
Jersey
Jordânia
Cazaquistão
Quênia
Kiribati
Kosovo
Quirguistão
Kuwait
Laos
Letônia
Líbano
Lesoto
Libéria
Líbia
Liechtenstein
Lituânia
Luxemburgo
Madagascar
Malauí
Malásia
Maldivas
Mali
Malta
Ilhas Marshall
Mauritânia
Ilhas Maurício
México
Micronésia
Mongólia
Montenegro
Montserrat
Marrocos
Moçambique
Namíbia
Nauru
Nepal
Países Baixos
Nova Caledônia
Nova Zelândia
Nicarágua
Níger
Nigéria
Niue
Ilha Norfolk
Macedônia do Norte
Ilhas Mariana do Norte
Noruega
Omã
Paquistão
Palau
Palestina
Panamá
Papua-Nova Guiné
Paraguai
Peru
Filipinas
Ilhas Pitcairn
Polônia
Portugal
Porto Rico
Catar
República do Chipre
República do Congo
Romênia
Ruanda
São Bartolomeu
São Cristóvão e Névis
Santa Lúcia
Saint Pierre e Miquelon
São Vicente e Granadinas
Santa Helena, Ascensão e Tristão da Cunha
Samoa
São Tomé e Príncipe
Arábia Saudita
Senegal
Sérvia
Ilhas Seychelles
Serra Leoa
Singapura
Eslováquia
Eslovênia
Ilhas Salomão
Somália
África do Sul
Ilhas Geórgia do Sul e Sandwich do Sul
Coreia do Sul
Sudão do Sul
Espanha
Sri Lanka
Sudão
Suriname
Suécia
Suíça
Taiwan
Tajiquistão
Tanzânia
Tailândia
Timor Leste
Togo
Toquelau
Tonga
Trinidad e Tobago
Tunísia
Turquia
Turcomenistão
Ilhas Turks e Caicos
Tuvalu
Uganda
Ucrânia
Reino Unido
Emirados Árabes Unidos
Estados Unidos
Territórios Insulares dos Estados Unidos
Ilhas Virgens Americanas
Uruguai
Uzbequistão
Vanuatu
Venezuela
Vietnã
Ilhas Wallis e Futuna
Saara Ocidental
Iêmen
Zâmbia
Zimbábue
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-02-11 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_69.txt ---

URL: https://ai.google.dev/gemini-api/docs/usage-policies

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Isso foi útil?
Envie comentários
Outras políticas de uso
Nesta página
Monitoramento de abuso
Como monitoramos o uso indevido
Como processamos dados
Como investigamos possíveis problemas
Como trabalhar com você para cumprir a política
Escopo
Votação de preferência inline
Por que estamos fazendo isso?
Esta página inclui outras políticas de uso da API Gemini.
Monitoramento de abuso
O Google tem o compromisso de desenvolver e usar a IA de forma responsável. Para garantir a segurança e a integridade da API Gemini, criamos estas diretrizes de política. Ao usar a API Gemini, você concorda com as diretrizes a seguir, os Termos de Serviço adicionais da API Gemini e a Política de uso proibido da IA generativa.
Como monitoramos o uso indevido
A Equipe de Confiança e Segurança do Google usa uma combinação de processos automáticos e manuais para detectar possíveis usos indevidos da API Gemini e aplicar nossas políticas.
Detecção automatizada:os sistemas automatizados verificam o uso da API em busca de violações da nossa Política de uso proibido, como discurso de ódio, assédio, conteúdo sexualmente explícito e conteúdo perigoso.
Detecção manual:se um projeto apresentar atividade suspeita consistentemente, ele poderá ser sinalizado para revisão manual por funcionários autorizados do Google.
Como processamos dados
Para ajudar no monitoramento de abuso, o Google retém os seguintes dados por 55 dias:
Comandos:comandos de texto enviados à API.
Informações contextuais:qualquer contexto adicional que você fornecer com seus comandos.
Saída:as respostas geradas pela API Gemini.
Como investigamos possíveis problemas
Quando os comandos ou as saídas do modelo são sinalizados por filtros de segurança e sistemas de detecção de abuso descritos acima, funcionários autorizados do Google podem avaliar o conteúdo sinalizado e confirmar ou corrigir a classificação ou determinação com base em diretrizes e políticas predefinidas. Os dados só podem ser acessados para revisão humana por funcionários autorizados do Google por meio de uma plataforma de avaliação e gerenciamento de revisão interna. Quando os dados são registrados para monitoramento de abuso, eles são usados exclusivamente para a aplicação de políticas e não são usados para treinar ou aprimorar modelos de IA/ML.
Como trabalhar com você para cumprir a política
Se o uso do Gemini não estiver de acordo com nossas políticas, poderemos tomar as seguintes medidas:
Entre em contato:podemos entrar em contato com você por e-mail para entender seu caso de uso e descobrir maneiras de fazer com que seu uso esteja em conformidade.
Limites de uso temporários:podemos limitar seu acesso à API Gemini.
Suspensão temporária:podemos pausar temporariamente seu acesso à API Gemini.
Encerramento da conta:como último recurso, e em caso de violações graves, podemos encerrar permanentemente seu acesso à API Gemini e a outros serviços do Google.
Escopo
Estas diretrizes de política se aplicam ao uso da API Gemini e do AI Studio.
Votação de preferência inline
No Google AI Studio, às vezes você pode ver uma comparação lado a lado de duas respostas diferentes para o comando. Isso faz parte do nosso sistema de votação de preferência inline. Você vai precisar escolher a resposta que preferir. Isso nos ajuda a entender quais saídas de modelo os usuários acham mais úteis.
Por que estamos fazendo isso?
Trabalhamos constantemente para melhorar nossos modelos e serviços de IA. Seu feedback por meio do Voto de preferência inline nos ajuda a fornecer, melhorar e desenvolver produtos e serviços do Google e tecnologias de aprendizado de máquina, incluindo os recursos, produtos e serviços empresariais do Google, de acordo com os Termos de Serviço Adicionais da API Gemini e a Política de Privacidade.
Quais dados são incluídos no Feedback?
Para tomar decisões informadas sobre nossos modelos, coletamos determinados dados quando você participa da votação de preferência inline:
Instruções e respostas:registramos todas as instruções e respostas, incluindo qualquer conteúdo enviado, na conversa em que você enviou o feedback. Também registramos as duas opções de resposta que você selecionou. Isso nos ajuda a entender o contexto da sua preferência.
Seu voto:registramos a resposta que você preferiu. Esse é o núcleo do feedback que estamos coletando.
Detalhes de uso:inclui informações sobre qual modelo gerou a resposta e outros detalhes técnicos e operacionais sobre seu uso desse recurso.
Sua privacidade
Levamos sua privacidade a sério. O Google toma medidas para proteger sua privacidade como parte desse processo. Isso inclui desconectar esses dados da sua Conta do Google, da chave de API e do projeto do Cloud antes que os revisores os vejam ou façam anotações. Não envie feedback sobre conversas que incluam informações sensíveis, confidenciais ou pessoais.
Como desativar
Você vai ter a opção de pular a votação de preferência inline quando ela aparecer.
Agradecemos por nos ajudar a melhorar o Google AI Studio.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-03-24 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_70.txt ---

URL: https://ai.google.dev/pricing

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
Preços da API Gemini Developer
Nesta página
Pré-lançamento do Gemini 2.5 Pro
Gemini 2.0 Flash
Gemini 2.0 Flash-Lite
Imagem 3
O Gemma 3
O "nível sem custo financeiro" da API Gemini é oferecido pelo serviço da API com limites de taxa mais baixos para fins de teste. O uso do Google AI Studio é totalmente sem custo financeiro em todos os países disponíveis. O "nível pago" da API Gemini tem limites de taxa mais altos, mais recursos e diferentes formas de processamento de dados.
Fazer upgrade para o nível pago
Pré-lançamento do Gemini 2.5 Pro
Testar no Google AI Studio
Nosso modelo multiuso de última geração, que se destaca em programação e tarefas de raciocínio complexas.
Os modelos de pré-lançamento podem mudar antes de se tornarem estáveis e disponíveis para todos.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo, use "gemini-2.5-pro-exp-03-25" US$ 1,25, comandos <= 200 mil tokens
US$2,50, comandos > 200 mil tokens
Preço de saída (incluindo tokens de pensamento) Sem custo, use "gemini-2.5-pro-exp-03-25" US$ 10,00, comandos <= 200 mil tokens
US$15,00, comandos > 200 mil
Preço do armazenamento em cache de contexto Indisponível Indisponível
Embasamento com a Pesquisa Google Sem custo financeiro, até 500 RPD 1.500 RPD (sem custo financeiro), depois US $35 / 1.000 solicitações
Usado para melhorar nossos produtos Sim Não
Gemini 2.0 Flash
Testar no Google AI Studio
Nosso modelo multimodal mais equilibrado com ótimo desempenho em todas as tarefas, com uma janela de contexto de 1 milhão de tokens e criado para a era dos agentes.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,10 (texto / imagem / vídeo)
US$0,70 (áudio)
Preço de saída Sem custo financeiro US$ 0,40
Preço do armazenamento em cache de contexto Sem custo financeiro US$ 0,025 / 1.000.000 tokens (texto/imagem/vídeo)
US$0,175 / 1.000.000 tokens (áudio)
Disponível em 15 de abril de 2025
Armazenamento em cache de contexto Sem custo financeiro, até 1.000.000 de tokens de armazenamento por hora
Disponível em 15 de abril de 2025 US$ 1,00 / 1.000.000 tokens por hora
Disponível em 15 de abril de 2025
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Sem custo financeiro, até 500 RPD 1.500 RPD (sem custo financeiro), depois US $35 / 1.000 solicitações
Usado para melhorar nossos produtos Sim Não
Gemini 2.0 Flash-Lite
Testar no Google AI Studio
Nosso modelo menor e mais econômico, criado para uso em grande escala.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,075
Preço de saída Sem custo financeiro US$ 0,30
Preço do armazenamento em cache de contexto Disponível em 15 de abril de 2025 Disponível em 15 de abril de 2025
Armazenamento em cache de contexto Disponível em 15 de abril de 2025 Disponível em 15 de abril de 2025
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível Indisponível
Usado para melhorar nossos produtos Sim Não
Imagem 3
Testar no ImageFX
Nosso modelo de geração de imagens de última geração, disponível para desenvolvedores no nível pago da API Gemini.
Nível gratuito Nível pago, por imagem em USD
Preço da imagem Indisponível US$ 0,03
Usado para melhorar nossos produtos Sim Não
O Gemma 3
Testar o Gemma 3
Nosso modelo aberto leve e de última geração, criado com a mesma tecnologia que alimenta nossos modelos Gemini.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro Indisponível
Preço de saída Sem custo financeiro Indisponível
Preço do armazenamento em cache de contexto Sem custo financeiro Indisponível
Armazenamento em cache de contexto Sem custo financeiro Indisponível
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível Indisponível
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Flash
Testar no Google AI Studio
Nosso modelo multimodal mais rápido, com ótimo desempenho para tarefas diversas e repetitivas e uma janela de contexto de 1 milhão de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,075, comandos <= 128 mil tokens
US$0,15, comandos > 128 mil tokens
Preço de saída Sem custo financeiro US$ 0,30, comandos <= 128 mil tokens
US$0,60, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Sem custo financeiro, até 1 milhão de tokens de armazenamento por hora US$ 0,01875, comandos <= 128 mil tokens
US$0,0375, comandos > 128 mil tokens
Armazenamento em cache de contexto Sem custo financeiro US$ 1,00 por hora
Preço de ajuste Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro. Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro.
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Flash-8B
Testar no Google AI Studio
Nosso modelo mais pequeno para casos de uso de inteligência mais simples, com uma janela de contexto de 1 milhão de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 0,0375, comandos <= 128 mil tokens
US$0,075, comandos > 128 mil tokens
Preço de saída Sem custo financeiro US$ 0,15, comandos <= 128 mil tokens
US$0,30, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Sem custo financeiro, até 1 milhão de tokens de armazenamento por hora US$ 0,01, solicitações <= 128 mil tokens
US$0,02, solicitações > 128 mil tokens
Armazenamento em cache de contexto Sem custo financeiro US$ 0,25 por hora
Preço de ajuste Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro. Os preços dos tokens são os mesmos para modelos ajustados.
O serviço de ajuste não tem custo financeiro.
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Gemini 1.5 Pro
Testar no Google AI Studio
Nosso modelo de série Gemini 1.5 com a maior inteligência, com uma janela de contexto de 2 milhões de tokens.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro US$ 1,25, solicitações de até 128 mil tokens
US$2,50, solicitações de mais de 128 mil tokens
Preço de saída Sem custo financeiro US$ 5,00, comandos <= 128 mil tokens
US$10,00, comandos > 128 mil tokens
Preço do armazenamento em cache de contexto Indisponível US$ 0,3125, comandos <= 128 mil tokens
US$0,625, comandos > 128 mil tokens
Armazenamento em cache de contexto Indisponível US$ 4,50 por hora
Preço de ajuste Indisponível Indisponível
Embasamento com a Pesquisa Google Indisponível US$ 35 / 1.000 solicitações de suspensão (até 5.000 solicitações por dia).
Usado para melhorar nossos produtos Sim Não
Text Embedding 004
Nosso modelo de embedding de texto de última geração.
Nível gratuito Nível pago, por 1 milhão de tokens em USD
Preço de entrada Sem custo financeiro Indisponível
Preço de saída Sem custo financeiro Indisponível
Preço de ajuste Indisponível Indisponível
[*] O uso do Google AI Studio é sem custo financeiro em todas as regiões disponíveis. Consulte as Perguntas frequentes sobre faturamento para mais detalhes.
[**] Os preços podem ser diferentes dos listados aqui e dos oferecidos na Vertex AI. Para conferir os preços da Vertex, consulte a página de preços da Vertex AI.
[***] Se você estiver usando a recuperação dinâmica para otimizar custos, apenas as solicitações que contêm pelo menos um URL de suporte de embasamento da Web na resposta são cobradas pela integração com a Pesquisa Google. Os custos do Gemini sempre se aplicam. Os limites de taxa estão sujeitos a alterações.
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_71.txt ---

URL: https://ai.google.dev/gemma

Modelos
/
Português – Brasil
Fazer login
Gemma
Documentos
Confira o repositório do Gemma Cookbook para ver exemplos de geração e ajuste. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Gemma 3
Uma coleção de modelos abertos leves e de última geração criados com base na mesma pesquisa e tecnologia que alimentam nossos modelos do Gemini 2.0
Testar o Gemma 3 no Google AI Studio
Processar tarefas complexas
A janela de contexto de 128 mil tokens do Gemma 3 permite que seus aplicativos processem e entendam grandes quantidades de informações, possibilitando recursos de IA mais sofisticados.
Alcance o mundo inteiro instantaneamente
Com o Gemma 3, você se comunica com facilidade em vários idiomas. Desenvolva aplicativos que alcancem um público global, com suporte para mais de 140 idiomas.
Entender palavras e imagens
Crie facilmente aplicativos que analisam imagens, textos e vídeos, abrindo novas possibilidades para aplicativos interativos e inteligentes.
Leia o blog
Crie com o melhor modelo de aceleração única do mundo
Começar a criar com o Gemma
Guia do Gemma
Exemplos práticos e tutoriais sobre os modelos abertos do Google
Conheça os notebooks
Hugging face
Comece a usar o Gemma com a biblioteca Transformers do Hugging Face.
Keras
Use o Keras com um back-end JAX para ajustar o Gemma com o LoRA e o treinamento distribuído de paralelismo de modelo em TPUs.
Ollama
Execute a inferência localmente em um modelo do Gemma usando o Ollama.
Biblioteca Python do Gemma
Converse e ajuste o Gemma com a nova biblioteca Gemma Python.
Pesquisa avançada com o Gemma
TxGemma
NEW
Uma coleção de modelos abertos para acelerar o desenvolvimento de tratamentos.
Download from Hugging Face
ShieldGemma 2
NOVO
O ShieldGemma 2 oferece uma solução pronta para a segurança de imagens, gerando rótulos em três categorias de segurança.
Fazer o download do Kaggle
PaliGemma 2
NOVO
O PaliGemma 2 traz recursos de visão facilmente ajustáveis aos modelos de linguagem Gemma 2, permitindo uma ampla gama de aplicativos que combinam a compreensão de texto e imagem.
Fazer o download do Kaggle
DataGemma
Os DataGemma são os primeiros modelos abertos projetados para conectar LLMs a dados reais extraídos do Data Commons do Google.
Fazer o download do Kaggle
Escopo do Gemma
O Gemma Scope oferece aos pesquisadores uma transparência sem precedentes nos processos de tomada de decisão dos nossos modelos do Gemma 2.
Fazer o download do Hugging Face
Slide atual: 1
Slide atual: 2
Slide atual: 3
Slide atual: 4
Slide atual: 5
Visualizar comparativos de mercado do Gemma 3
MMLU-Pro
LiveCodeBench
Bird-SQL
GPQA Diamond
SimpleQA
Embasamento de FATOS
MATH
HiddenMath
MMMU
100%
75%
50%
25%
0%
Gemma 2
2b
15,6
9b
46,8
27b
56,9
Gemma 3
1b
14.7
4b
43,6
12b
60,6
27b
67,5
*Consulte o relatório técnico para saber mais sobre a performance com outras metodologias. Leia o relatório técnico
Conheça o Gemmaverse
Escolher o destino da implantação
Dispositivo móvel
Implantar no dispositivo com a IA de borda do Google
Implante diretamente nos dispositivos para funcionalidade off-line com baixa latência. Ideal para aplicativos que exigem privacidade e capacidade de resposta em tempo real, como apps para dispositivos móveis, dispositivos de IoT e sistemas embarcados.
Implantar o app para dispositivos móveis
Web
Integração perfeita a aplicativos da Web
Melhore seus sites e serviços da Web com recursos avançados de IA, como recursos interativos, conteúdo personalizado e automação inteligente.
Implantar a Web
Cloud
Escalone sem esforço com a infraestrutura em nuvem
Aproveite a escalabilidade e a flexibilidade da nuvem para lidar com implantações em grande escala, cargas de trabalho exigentes e aplicativos complexos de IA.
Deploy Cloud
Como acelerar a pesquisa acadêmica com créditos do Google Cloud
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_72.txt ---

URL: https://ai.google.dev/gemma/docs

Modelos
/
Português – Brasil
Fazer login
Gemma
Documentos
Visão geral
Começar
Lançamentos
Modelos
Gemma 3
CodeGemma
PaliGemma 2
ShieldGemma 2
Executar o Gemma
Visão geral
Ollama
Biblioteca do Gemma
Keras
PyTorch
Gemma.cpp
Gemini API
Comandos e instruções do sistema
Configuração do Gemma
Recursos
Chamadas de função
Solicitação com dados visuais
Guias de ajuste
Visão geral
Ajustar usando LoRA e Keras
Ajustar usando a biblioteca Gemma
Ajustar usando o Hugging Face Transformers e o QLoRA
Ajustar a visão usando Transformers do Hugging Face e QLoRA
Ajuste distribuído usando o Keras
Guias de inscrição
Assistente pessoal de programação
Assistente de e-mail comercial
Tarefas de idioma falado
Chatbot usando Python
Gerador de memes
Guias de implantação
Web
Dispositivos móveis
Google Cloud
LangChain
Pesquisa e ferramentas
RecurrentGemma
DataGemma
Telescópio Gemma
Gemma-APS
Comunidade
Gemmaverse
Discord
Jurídico
Termos de Uso
Uso proibido
Confira o repositório do Gemma Cookbook para ver exemplos de geração e ajuste. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemma
Documentos
Isso foi útil?
Envie comentários
Visão geral dos modelos Gemma
Nesta página
Modelos pré-treinados e ajustados por instrução
Próximas etapas
O Gemma é uma família de modelos abertos, leves e de última geração criados a partir da mesma pesquisa e tecnologia usadas para criar modelos do Gemini. Desenvolvido pelo Google DeepMind e outras equipes do Google, o Gemma recebe o nome de a palavra latina gemma, que significa "pedra preciosa". Os pesos do modelo Gemma são com ferramentas de desenvolvimento que promovem a inovação, a colaboração e a uso responsável da inteligência artificial (IA).
Os modelos Gemma estão disponíveis para execução aplicativos e no hardware, dispositivos móveis ou serviços hospedados. Você também pode personalizar esses modelos usando técnicas de ajuste para que se sobressaiam realizar tarefas específicas que importam para você e seus usuários. Desenho de modelos Gemma inspiração e linhagem tecnológica da família de modelos Gemini e são para a comunidade de desenvolvimento de IA ampliar e ir mais além.
Pronto para começar? Comece a usar os modelos do Gemma.
Modelos pré-treinados e ajustados por instrução
É possível modificar o comportamento dos modelos Gemma com treinamento adicional para que o modelo tenha um desempenho melhor em tarefas específicas. Esse processo é chamado de modelo ajuste e, embora essa técnica melhore a capacidade de um modelo de realizar para tarefas direcionadas, isso também pode piorar o modelo em outras tarefas. Para Por isso, os modelos Gemma estão disponíveis tanto nos modelos ajustados por instrução versões pré-treinadas:
Ajuste por instruções (TI): essas versões do modelo são treinadas com interações de linguagem humana e podem responder a entradas de conversa, semelhantes a um chatbot.
Pré-treinado (PT): essas versões do modelo não são treinadas tarefas ou instruções específicas além do conjunto de treinamento de dados principais do Gemma. Você não devem implantar esses modelos em aplicativos sem realizar sintonização.
Próximas etapas
Comece sua jornada na criação de aplicativos com o Gemma com o Guia para começar a usar o Gemma.
Isso foi útil?
Envie comentários
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2024-08-05 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_73.txt ---

URL: https://ai.google.dev/gemma/gemmaverse

Modelos
/
Português – Brasil
Fazer login
Gemma
Documentos
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Este é o Gemmaverse
Conheça os modelos Gemma criados pela comunidade
Estudos de caso em destaque
ROBOFLOW e PaliGemma 2
O objetivo da Roboflow é melhorar a visão computacional para uso do consumidor e da empresa com os fluxos de trabalho de IA, totalmente integrados à PaliGemma.
Saiba mais
INSAIT: BgGPT
O LLM líder na Bulgária com o Gemma 2
Saiba mais
NEXA AI: OmniAudio
Um modelo de linguagem de áudio para aplicativos de borda
Saiba mais
AI Singapore: SEA-LION
Tornando a IA mais inclusiva para os idiomas do Sudeste Asiático com o Gemma 2
Saiba mais
Como aproveitar a comunicação global
Conheça as variantes do Gemma criadas pela comunidade
Saiba mais sobre o Hugging Face
PRINCETON-NLP/GEMMA-2-9B-IT-SIMPO
Um derivado do Gemma 2 9B otimizado para o aprendizado de preferências pelo SimPO.
UNSLOTH/GEMMA-2-9B-IT-BNB-4BIT
O Unsloth aumenta a capacidade do Gemma 2 com quantização de 4 bits, oferecendo ajustes mais rápidos e uso reduzido de memória.
UCLA-AGI/GEMMA-2-9B-IT-SPPO-ITER3
Um modelo do Gemma 2 desenvolvido usando a otimização de preferência de autojogo.
AIDC-AI/OVIS1.6-GEMMA2-9B
Um modelo de linguagem grande multimodal de 10,2 bilhões de parâmetros para processamento e geração de imagens e textos.
RTZR/KO-GEMMA-2-9B-IT
Um modelo Gemma 2 em coreano ajustado para conversa e feedback humano.
LEMON07R/GEMMA-2-ATARAXY-9B
Mesclagem do Gemma 2, o texto criativo mais bem classificado, que combina o SimPO e o Gutenberg.
ALPHA-VLLM/LUMINA-IMAGE-2.0
Um modelo generativo de imagem eficiente criado com o codificador de texto do Gemma 2 e um VAE.
TELUGU-LLM-LABS/INDIC-GEMMA-2B-FINETUNED-SFT-NAVARASA-2.0
Um modelo Gemma ajustado para seguir instruções em vários idiomas índicos.
Participe da nossa comunidade Gemma
Converse, compartilhe ideias e faça conexões instantâneas no nosso canal #gemma do Google Developer Discord.
Chat agora
Acesse a ficha do modelo, confira notebooks interativos e participe das discussões da comunidade.
Participar do Kaggle
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_74.txt ---

URL: https://ai.google.dev/edge

Soluções
/
Português – Brasil
Fazer login
Borda de IA do Google
MediaPipe
LiteRT
Simulador de modelos
Mais
Conheça o LiteRT: o ambiente de execução de alto desempenho do Google para IA no dispositivo, antes conhecido como TensorFlow Lite.
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Implantar a IA em aplicativos para dispositivos móveis, Web e incorporados
Ferramentas e frameworks que alimentam os apps do Google
Conheça toda a pilha de IA de ponta, com produtos em todos os níveis, de APIs de pouco código a bibliotecas de aceleração específicas de hardware.
IA generativa
Integre modelos de imagem e linguagem generativa diretamente aos seus apps com APIs prontas para uso.
Vision
Conheça uma grande variedade de tarefas de visão que abrangem segmentação, classificação, detecção, reconhecimento e pontos de referência do corpo.
Texto e áudio
Classifique texto e áudio em várias categorias, incluindo idioma, sentimento e suas próprias categorias personalizadas.
PRIMEIROS PASSOS
Documentação do app Tarefas
Encontre todas as tarefas do MediaPipe com pouco código prontas para uso com documentação e exemplos de código.
Tarefas de IA generativa
Execute LLMs e modelos de difusão na borda com nossas tarefas de IA generativa do MediaPipe.
Testar demonstrações
Conheça nossa biblioteca de tarefas do MediaPipe e teste-as.
Documentação do Model Maker
Personalize os modelos nas nossas tarefas do MediaPipe com seus próprios dados.
Começar
Vários frameworks
Converta modelos do JAX, Keras, PyTorch e TensorFlow para execução na borda.
Multiplataforma
Execute o mesmo modelo em Android, iOS, Web e microcontroladores com SDKs nativos.
Leve e rápido
O ambiente de execução eficiente do LiteRT ocupa apenas alguns megabytes e permite a aceleração do modelo em CPUs, GPUs e NPUs.
PRIMEIROS PASSOS
Escolher um modelo
Escolha um modelo novo, treine novamente um modelo existente ou use o seu.
Converter
Converta seu modelo JAX, Keras, PyTorch ou Tensorflow em um modelo otimizado do LiteRT.
Implantar
Execute um modelo do LiteRT no Android, iOS, Web e microcontroladores.
Quantizar
Compacte seu modelo para reduzir a latência, o tamanho e a memória máxima.
Começar
Um tutorial para soluções de IA generativa no dispositivo Android
1º DE OUTUBRO DE 2024
Como levar seu modelo de IA para dispositivos Android
2 DE OUTUBRO DE 2024
O Gemini Nano já está disponível no Android com acesso experimental
1º DE OUTUBRO DE 2024
O TensorFlow Lite agora é o LiteRT
4 DE SETEMBRO DE 2024
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_75.txt ---

URL: https://ai.google.dev/responsible

Soluções
/
Português – Brasil
Fazer login
Kit de ferramentas de IA generativa responsável
Documentos
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Toolkit para IA generativa responsável
Ferramentas e orientações para projetar, desenvolver e avaliar modelos abertos de IA com responsabilidade.
Design responsável de aplicativos
Defina regras para o comportamento do modelo, crie um aplicativo seguro e responsável e mantenha uma comunicação transparente com os usuários.
Alinhamento de segurança
Descubra técnicas de depuração imediata e orientações para ajustes e RLHF para alinhar modelos de IA às políticas de segurança.
Avaliação do modelo
Encontre orientações e dados para realizar uma avaliação robusta do modelo de segurança, imparcialidade e precisão com o Comparador de LLM.
de saída
Implante classificadores de segurança usando soluções prontas para uso ou crie as suas próprias com tutoriais passo a passo.
Projetar uma abordagem responsável
PRIMEIROS PASSOS
Definir políticas no nível do sistema
Determine que tipo de conteúdo seu aplicativo deve e não deve gerar.
Definir políticas
Confira exemplos
Design com foco na segurança
Defina sua abordagem geral para implementar técnicas de redução de riscos, considerando as compensações técnicas e comerciais.
Saiba mais
Seja transparente
Comunique sua abordagem com artefatos como cards de modelo.
Consulte "Modelos"
Sistemas de IA seguros
Considere os riscos de segurança específicos da IA e os métodos de correção destacados no framework de IA segura (SAIF, na sigla em inglês).
Framework de IA segura do Google
Documentação
Alinhar o modelo
PRIMEIROS PASSOS
Crie avisos mais seguros e robustos
Use o poder dos LLMs para criar modelos de comando mais seguros com a biblioteca de alinhamento de modelos.
Testar agora
Alinhamento do modelo
Ajustar modelos para segurança
Controle o comportamento do modelo ajustando-o para que ele se alinhe às suas políticas de segurança e conteúdo.
Saiba mais sobre os ajustes
Saiba mais sobre o ajuste do SFT
Saiba mais sobre o ajuste de RLHF
Investigar comandos de modelo
Crie instruções seguras e úteis com melhorias iterativas usando a Ferramenta de interpretabilidade de aprendizado (LIT, na sigla em inglês).
Testar agora
Ferramenta de interpretabilidade de aprendizado
Avalie o modelo
PRIMEIROS PASSOS
Comparador de LLM
Realize avaliações lado a lado com o Comparador de LLM para avaliar qualitativamente as diferenças nas respostas entre modelos, comandos diferentes para o mesmo modelo ou até mesmo diferentes ajustes de um modelo.
Teste a demonstração
Saiba mais sobre o comparador de LLM
Diretrizes de avaliação de modelos
Saiba mais sobre as práticas recomendadas de red team e avalie seu modelo com base em comparativos acadêmicos para avaliar os danos relacionados à segurança, à imparcialidade e à veracidade.
Saiba mais
Conferir comparativos de mercado
Confira as práticas recomendadas para equipes vermelhas
Proteger com proteções
PRIMEIROS PASSOS
Texto do SynthID
Uma ferramenta para adicionar marca d'água e detectar texto gerado pelo modelo.
Marca-d'água de texto do SynthID
ShieldGemma
Uma série de classificadores de segurança de conteúdo criados com o Gemma 2, disponíveis em três tamanhos: 2B, 9B e 27B.
Classificadores de segurança de conteúdo do ShieldGemma
Classificadores ágeis
Criar classificadores de segurança para suas políticas específicas usando o ajuste eficiente de parâmetros (PET, na sigla em inglês) com dados de treinamento relativamente pequenos
Criar classificadores de segurança
Verifica a segurança da IA
Garanta a conformidade da IA com suas políticas de conteúdo usando APIs e painéis de monitoramento.
Verifica a segurança da IA
Serviço de moderação de texto
Detecte uma lista de atributos de segurança, incluindo várias categorias e tópicos potencialmente nocivos que podem ser considerados sensíveis com essa API Google Cloud Natural Language disponível sem custo financeiro abaixo de um determinado limite de uso.
API Cloud Natural Language
Preços da API Cloud Natural Language
API Perspective
Identifique comentários "tóxicos" com esta API sem custo financeiro do Google Jigsaw para reduzir a toxicidade on-line e garantir um diálogo saudável.
API Perspective
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_76.txt ---

URL: https://ai.google.dev/showcase

Mais
/
Português – Brasil
Fazer login
Confira os vencedores da competição para desenvolvedores da API Gemini. Ver
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Gemini Showcase
Conheça apps reais que aproveitam os recursos multimodais mais recentes e as janelas de contexto longas.
Apps criados com a API Gemini
Vite Vere
Confira como o app para dispositivos móveis usa o Gemini para ajudar pessoas com deficiências cognitivas a terem mais autonomia.
MODELO
Gemini 1.5 Flash
Mais histórias
Vôlei
O Volley cria um protótipo de jogo com foco em áudio com o Gemini 2.0 Flash e a API Multimodal Live
Tldraw
Prototipagem de uma nova experiência de computação de linguagem natural em uma tela infinita com o Gemini 2.0
Salas
Desbloqueie interações mais ricas com os recursos de texto e áudio do Gemini 2.0
Toonsutra
Aproveitar as capacidades de tradução multilíngue contextual do Gemini 2.0 para tornar os quadrinhos e webtoons acessíveis ao público da Índia em idiomas regionais.
Viggle
Experimentar o Gemini 2.0 para criar personagens virtuais e narração de áudio para uma plataforma de vídeo com tecnologia de IA
Subcamada
Saiba como a estrutura de agente de IA baseada em Ruby ajuda as equipes de desenvolvimento a aumentar a produtividade com o poder dos modelos Gemini.
Sourcegraph
Saiba como a Cody AI teve grandes ganhos de qualidade usando a janela de contexto enorme do Gemini.
AgentOps
Saiba como o AgentOps oferece uma observabilidade de agentes com LLM econômica e eficiente para empresas que usam a API Gemini.
Comece a criar com a API Gemini
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_77.txt ---

URL: https://ai.google.dev/competition

Mais
/
Português – Brasil
Fazer login
Esta página foi traduzida pela API Cloud Translation.
Switch to English
API Gemini
Competição para desenvolvedores
Menções honrosas
Essas inscrições incríveis mostraram criatividade e inovação excepcionais, merecendo reconhecimento por suas contribuições junto com os vencedores.
Alarmi
O Alarmi usa IA para garantir que você realmente acorde.
Visualizar
Omni
O Omni é um app de IA integrado ao sistema operacional.
Visualizar
Ally
Assistente pessoal para usuários cegos
Visualizar
AI Shift
O AI Shift é um app da Web que automatiza e otimiza a programação de turnos.
Visualizar
Janus
O melhor app de histórias interativas
Visualizar
Studioberry
Plataforma com tecnologia de IA que usa o Gemini para transformar a produção de filmes
Visualizar
EAGLE AI
Seu monitor de segurança com tecnologia de IA
Visualizar
Menu Buddy
O Menu Buddy ajuda pessoas com problemas de fala a fazer pedidos em restaurantes.
Visualizar
Family Farms Forever
A nova maneira de comprar em feiras de produtores. . .e que seja fácil de usar para os agricultores.
Visualizar
Jana AI
Transforme seu dia em histórias interessantes
Visualizar
ITMZ
App de inventário pessoal personalizado para rastrear, pesquisar e compartilhar todos os seus itens.
Visualizar
LoreHunter
Passeios a pé fictícios personalizados
Visualizar
BeeFair - Promptlab
Seu assistente de compras inteligente.
Visualizar
Livros didáticos são tudo o que você precisa
Conheça a TAAYN-chan, uma IA que dá vida aos seus livros didáticos.
Visualizar
Digitalização de fotos
Recordações preciosas preservadas com o poder da IA
Visualizar
Reflexão
Mantenha um diário para ter mais clareza. Reflita para crescer.
Visualizar
1PUL
O primeiro lugar que você vai procurar seus itens
Visualizar
Pixtale
De fotos de viagens a vídeos narrados em minutos com a magia da IA Gemini.
Visualizar
StarryTrader
Um app Bloomberg justo, que democratiza os insights de notícias financeiras
Visualizar
AlphaFit
App de fitness para iniciantes que combina treinos personalizados com jogos mentais
Visualizar
EcoTrack
EcoTrack: a revolução das compras ecológicas com tecnologia de IA
Visualizar
Criar com a Gemini
Gerar uma chave de API no AI Studio
CONHEÇA OS VENCEDORES
Christopher Lloyd não ganhou.
Então, quem são os vencedores?
Português – Brasil

--- Content from: page_78.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=pt-br#

Modelos
/
Português – Brasil
Fazer login
Documentos da API Gemini
Referência da API
Manual
Visão geral
Começar
Início rápido
Chaves de API
Bibliotecas
Notas da versão
Compatibilidade com o OpenAI
Fórum de desenvolvedores
Modelos
Todos os modelos
Preço
Limites de taxas
Informações de faturamento
Recursos
Geração de texto
Geração de imagens
Visão
Compreensão de áudio
Contexto longo
Execução do código
Saída estruturada
Pensando
Chamadas de função
Entendimento de documentos
Embasamento com a Pesquisa Google
Ajuste de detalhes
Embeddings
Guias
API Live
O armazenamento em cache de contexto
Engenharia de comando
Contagem de tokens
Segurança
Outros recursos
Gemini para pesquisa
Programa acadêmico da Gemini
Casos de uso
Aplicativos
Solução de problemas
Solução de problemas com APIs
Solução de problemas do AI Studio
Google Workspace
Jurídico
Termos de Serviço
Regiões disponíveis
Outras políticas de uso
O Gemini 2.5 Pro Experimental, nosso modelo mais avançado, já está disponível. Saiba mais
Esta página foi traduzida pela API Cloud Translation.
Switch to English
Página inicial
Gemini API
Modelos
API Gemini Developer
Gerar uma chave da API Gemini
Receba uma chave da API Gemini e faça sua primeira solicitação de API em minutos.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Conheça os modelos
Usar o Gemini no Google AI Studio
2.5 Pro experiment
Nosso modelo de pensamento mais poderoso, com recursos para raciocínio complexo e muito mais
2.0 Flash spark
Nosso modelo multimodal mais recente, com recursos de última geração e recursos aprimorados
2.0 Flash-Lite bolt
Nosso modelo multimodal mais rápido e econômico com ótimo desempenho para tarefas de alta frequência
Explore a API
Geração de imagens nativas
Gere e edite imagens altamente contextuais de forma nativa com o Gemini 2.0 Flash.
Explorar o contexto longo
Insira milhões de tokens nos modelos do Gemini e extraia insights de imagens, vídeos e documentos não estruturados.
Gerar saídas estruturadas
Limite o Gemini para responder com JSON, um formato de dados estruturado adequado para processamento automatizado.
Comece a criar com a API Gemini
Primeiros passos
Exceto em caso de indicação contrária, o conteúdo desta página é licenciado de acordo com a Licença de atribuição 4.0 do Creative Commons, e as amostras de código são licenciadas de acordo com a Licença Apache 2.0. Para mais detalhes, consulte as políticas do site do Google Developers. Java é uma marca registrada da Oracle e/ou afiliadas.
Última atualização 2025-04-04 UTC.
Termos de Serviço
Privacidade
Português – Brasil

--- Content from: page_79.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=de

Modelle
/
Deutsch
Anmelden
Gemini API-Dokumentation
API-Referenz
Kochbuch
Übersicht
Los gehts
Schnelleinstieg
API-Schlüssel
Bibliotheken
Versionshinweise
Kompatibilität mit OpenAI
Entwicklerforum
Modelle
Alle Modelle
Preise
Ratenlimits
Rechnungsinformationen
Leistungsspektrum
Textgenerierung
Bilderstellung
Vision
Audioverständnis
Langer Kontext
Codeausführung
Strukturierte Ausgabe
Denken
Funktionsaufrufe
Verständnis von Dokumenten
Fundierung mit der Google Suche
Abstimmung
Einbettungen
Leitfäden
Live-API
Kontext-Caching
Prompt Engineering
Tokenzählung
Sicherheit
Zusätzliche Ressourcen
Gemini für Forschung
Gemini Academic Program
Anwendungsfälle
Anwendungen
Fehlerbehebung
API-Fehlerbehebung
Fehlerbehebung in AI Studio
Google Workspace
Rechtliche Informationen
Nutzungsbedingungen
Verfügbare Regionen
Zusätzliche Nutzungsrichtlinien
Gemini 2.5 Pro Experimental, unser fortschrittlichstes Modell, ist jetzt verfügbar. Weitere Informationen
Diese Seite wurde von der Cloud Translation API übersetzt.
Switch to English
Startseite
Gemini API
Modelle
Gemini Developer API
Gemini API-Schlüssel anfordern
Sie können innerhalb weniger Minuten einen Gemini API-Schlüssel abrufen und Ihre erste API-Anfrage senden.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Die Modelle kennenlernen
Gemini in Google AI Studio verwenden
2.5 Pro experiment
Unser leistungsstärkstes Modell für das Denken mit Funktionen für komplexes Denken und vielem mehr
2.0 Flash spark
Unser neuestes multimodales Modell mit Funktionen der nächsten Generation und verbesserten Fähigkeiten
2.0 Flash-Lite bolt
Unser schnellstes und kosteneffizientestes multimodales Modell mit hoher Leistung für häufige Aufgaben
Die API erkunden
Native Bildgenerierung
Mit Gemini 2.0 Flash können Sie hochgradig kontextbezogene Bilder nativ generieren und bearbeiten.
Langformatige Inhalte ansehen
Geben Sie Millionen von Tokens in Gemini-Modelle ein und gewinnen Sie Erkenntnisse aus unstrukturierten Bildern, Videos und Dokumenten.
Strukturierte Ausgaben generieren
Sie können Gemini dazu zwingen, mit JSON zu antworten, einem strukturierten Datenformat, das für die automatisierte Verarbeitung geeignet ist.
Mit der Gemini API entwickeln
Jetzt starten
Sofern nicht anders angegeben, sind die Inhalte dieser Seite unter der Creative Commons Attribution 4.0 License und Codebeispiele unter der Apache 2.0 License lizenziert. Weitere Informationen finden Sie in den Websiterichtlinien von Google Developers. Java ist eine eingetragene Marke von Oracle und/oder seinen Partnern.
Zuletzt aktualisiert: 2025-04-04 (UTC).
Nutzungsbedingungen
Datenschutz
Deutsch

--- Content from: page_80.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=es-419

Modelos
/
Español – América Latina
Acceder
Documentos de la API de Gemini
Referencia de la API
Guía de soluciones
Descripción general
Comenzar
Guía de inicio rápido
Claves de API
Bibliotecas
Notas de la versión
Compatibilidad con OpenAI
Foro de desarrolladores
Modelos
Todos los modelos
Precios
Límites de frecuencia
Información de facturación
Funciones
Generación de texto
Generación de imágenes
Vision
Comprensión de audio
Contexto largo
Ejecución de código
Salida estructurada
Pensando
Llamada a función
Comprensión de documentos
Grounding with Google Search
Ajuste
Incorporaciones
Guías
API en vivo
El almacenamiento de contexto en caché
Ingeniería de mensajes
Recuento de tokens
Seguridad
Recursos adicionales
Gemini para la investigación
Programa académico de Gemini
Casos de uso
Aplicaciones
Solución de problemas
Solución de problemas de la API
Solución de problemas de AI Studio
Google Workspace
Datos legales
Condiciones del Servicio
Regiones disponibles
Políticas de uso adicionales
Gemini 2.5 Pro Experimental, nuestro modelo más avanzado, ya está disponible. Más información
Se usó la API de Cloud Translation para traducir esta página.
Switch to English
Página principal
Gemini API
Modelos
API para desarrolladores de Gemini
Obtén una clave de API de Gemini
Obtén una clave de API de Gemini y realiza tu primera solicitud a la API en minutos.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Conoce a los modelos
Cómo usar Gemini en Google AI Studio
2.5 Pro experiment
Nuestro modelo de pensamiento más potente con funciones para el razonamiento complejo y mucho más
2.0 Flash spark
Nuestro modelo multimodal más reciente, con funciones de nueva generación y capacidades mejoradas
2.0 Flash-Lite bolt
Nuestro modelo multimodal más rápido y rentable con un gran rendimiento para tareas de alta frecuencia
Explora la API
Generación de imágenes nativas
Genera y edita imágenes altamente contextuales de forma nativa con Gemini 2.0 Flash.
Explora el contexto largo
Ingresa millones de tokens a los modelos de Gemini y extrae información de imágenes, videos y documentos no estructurados.
Genera resultados estructurados
Limita Gemini para que responda con JSON, un formato de datos estructurados adecuado para el procesamiento automatizado.
Comienza a crear con la API de Gemini
Comenzar
Salvo que se indique lo contrario, el contenido de esta página está sujeto a la licencia Atribución 4.0 de Creative Commons, y los ejemplos de código están sujetos a la licencia Apache 2.0. Para obtener más información, consulta las políticas del sitio de Google Developers. Java es una marca registrada de Oracle o sus afiliados.
Última actualización: 2025-04-04 (UTC)
Condiciones
Privacidad
Español – América Latina

--- Content from: page_81.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=fr

Modèles
/
Français
Connexion
Documentation de l'API Gemini
Documentation de référence de l'API
Liste de recettes
Aperçu
Premiers pas
Guide de démarrage rapide
Clés API
Bibliothèques
Notes de version
Compatibilité OpenAI
Forum des développeurs
Modèles
Tous les modèles
Tarifs
Limites de débit
Infos de facturation
Capacités
Génération de texte
Génération d'images
Vision
Compréhension audio
Contexte long
Exécution du code
Sortie structurée
Penser
Appel de fonction
Compréhension des documents
Ancrage avec la recherche Google
Affinage
Embeddings
Guides
API Live
mise en cache du contexte
Ingénierie des invites
Comptage de jetons
Sécurité
Ressources supplémentaires
Gemini pour la recherche
Programme Gemini pour les établissements d'enseignement
Cas d'utilisation
Applications
Dépannage
Dépannage de l'API
Résoudre les problèmes liés à AI Studio
Google Workspace
Juridique
Conditions d'utilisation
Régions disponibles
Autres règles d'utilisation
Gemini 2.5 Pro Experimental, notre modèle le plus avancé, est désormais disponible. En savoir plus
Cette page a été traduite par l'API Cloud Translation.
Switch to English
Accueil
Gemini API
Modèles
API Gemini pour les développeurs
Obtenir une clé API Gemini
Obtenez une clé API Gemini et effectuez votre première requête API en quelques minutes.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Rencontrez les modèles
Utiliser Gemini dans Google AI Studio
2.5 Pro experiment
Notre modèle de pensée le plus puissant, avec des fonctionnalités de raisonnement complexe et bien plus
2.0 Flash spark
Notre tout dernier modèle multimodal, avec des fonctionnalités de nouvelle génération et des fonctionnalités améliorées
2.0 Flash-Lite bolt
Notre modèle multimodal le plus rapide et le plus économique, offrant d'excellentes performances pour les tâches à haute fréquence
Explorer l'API
Génération d'images natives
Générez et modifiez des images hautement contextuelles en mode natif avec Gemini 2.0 Flash.
Explorer le contexte long
Importez des millions de jetons dans les modèles Gemini et tirez des insights des images, vidéos et documents non structurés.
Générer des sorties structurées
Contraignez Gemini à répondre au format JSON, un format de données structurées adapté au traitement automatisé.
Commencer à créer avec l'API Gemini
Commencer
Sauf indication contraire, le contenu de cette page est régi par une licence Creative Commons Attribution 4.0, et les échantillons de code sont régis par une licence Apache 2.0. Pour en savoir plus, consultez les Règles du site Google Developers. Java est une marque déposée d'Oracle et/ou de ses sociétés affiliées.
Dernière mise à jour le 2025/04/04 (UTC).
Conditions d'utilisation
Règles de confidentialité
Français

--- Content from: page_82.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=id

Model
Lainnya
/
Indonesia
Masuk
Dokumen Gemini API
Referensi API
Cookbook
Ringkasan
Mulai
Panduan memulai
Kunci API
Library
Catatan rilis
Kompatibilitas OpenAI
Forum developer
Model
Semua model
Harga
Batas kapasitas
Info penagihan
Kemampuan
Pembuatan teks
Pembuatan gambar
Vision
Pemahaman audio
Konteks panjang
Eksekusi kode
{i>Output<i} terstruktur
Berpikir
Panggilan fungsi
Pemahaman dokumen
Perujukan dengan Google Penelusuran
Fine tuning
Embeddings
Panduan
API Live
Cache konteks
Engineering prompt
Penghitungan token
Keamanan
Referensi lain
Gemini untuk Riset
Program Akademik Gemini
Kasus penggunaan
Aplikasi
Pemecahan masalah
Pemecahan masalah API
Pemecahan masalah AI Studio
Google Workspace
Hukum
Persyaratan layanan
Wilayah yang tersedia
Kebijakan penggunaan tambahan
Gemini 2.5 Pro Experimental, model kami yang paling canggih, kini tersedia. Pelajari lebih lanjut
Halaman ini diterjemahkan oleh Cloud Translation API.
Switch to English
Beranda
Gemini API
Model
Gemini Developer API
Mendapatkan Kunci Gemini API
Dapatkan kunci Gemini API dan buat permintaan API pertama Anda dalam hitungan menit.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Temui model
Menggunakan Gemini di Google AI Studio
2.5 Pro experiment
Model pemikiran kami yang paling canggih dengan fitur untuk penalaran kompleks dan banyak lagi
2.0 Flash spark
Model multimodal terbaru kami, dengan fitur generasi berikutnya dan kemampuan yang lebih baik
2.0 Flash-Lite bolt
Model multimodal tercepat dan paling hemat biaya kami dengan performa yang luar biasa untuk tugas berfrekuensi tinggi
Menjelajahi API
Pembuatan Gambar Native
Buat dan edit gambar yang sangat kontekstual secara native dengan Gemini 2.0 Flash.
Menjelajahi konteks panjang
Masukkan jutaan token ke model Gemini dan dapatkan pemahaman dari gambar, video, dan dokumen yang tidak terstruktur.
Membuat output terstruktur
Batasi Gemini untuk merespons dengan JSON, format data terstruktur yang cocok untuk pemrosesan otomatis.
Mulai membangun aplikasi dengan Gemini API
Mulai
Kecuali dinyatakan lain, konten di halaman ini dilisensikan berdasarkan Lisensi Creative Commons Attribution 4.0, sedangkan contoh kode dilisensikan berdasarkan Lisensi Apache 2.0. Untuk mengetahui informasi selengkapnya, lihat Kebijakan Situs Google Developers. Java adalah merek dagang terdaftar dari Oracle dan/atau afiliasinya.
Terakhir diperbarui pada 2025-04-04 UTC.
Persyaratan
Privasi
Indonesia

--- Content from: page_83.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=it

Modelli
Altro
/
Italiano
Accedi
Documentazione dell'API Gemini
Riferimento API
Libro di ricette
Panoramica
Per iniziare
Guida rapida
Chiavi API
Biblioteche
Note di rilascio
Compatibilità con OpenAI
Forum per sviluppatori
Modelli
Tutti i modelli
Prezzi
Limiti di frequenza
Dati di fatturazione
Funzionalità
Generazione di testo
Generazione di immagini
Visione artificiale
Comprensione audio
Contesto lungo
Esecuzione di codice
Output strutturato
Faccina che pensa
Chiamata di funzione
Document understanding
Grounding con la Ricerca Google
Ottimizzazione
Incorporamenti
Guide
API Live
Memorizzazione nella cache del contesto
Prompt engineering
Conteggio token
Sicurezza
Risorse aggiuntive
Gemini per la ricerca
Programma accademico Gemini
Casi d'uso
Applicazioni
Risoluzione dei problemi
Risoluzione dei problemi relativi all'API
Risoluzione dei problemi di AI Studio
Google Workspace
Legale
Termini di servizio
Aree geografiche disponibili
Norme di utilizzo aggiuntive
Gemini 2.5 Pro Experimental, il nostro modello più avanzato, è ora disponibile. Scopri di più
Questa pagina è stata tradotta dall'API Cloud Translation.
Switch to English
Home page
Gemini API
Modelli
API Gemini Developer
Ottieni una chiave API Gemini
Ottieni una chiave API Gemini ed effettua la tua prima richiesta API in pochi minuti.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Incontra i modelli
Utilizzare Gemini in Google AI Studio
2.5 Pro experiment
Il nostro modello di pensiero più potente con funzionalità per il ragionamento complesso e molto altro
2.0 Flash spark
Il nostro modello multimodale più recente, con funzionalità di nuova generazione e funzionalità migliorate
2.0 Flash-Lite bolt
Il nostro modello multimodale più veloce ed economico con ottime prestazioni per attività ad alta frequenza
Esplora l'API
Generazione di immagini native
Genera e modifica immagini altamente contestuali in modo nativo con Gemini 2.0 Flash.
Esplorare il contesto lungo
Inserisci milioni di token nei modelli Gemini e ricava informazioni da immagini, video e documenti non strutturati.
Genera output strutturati
Costrignere Gemini a rispondere con JSON, un formato di dati strutturati adatto all'elaborazione automatica.
Inizia a creare con l'API Gemini
Inizia
Salvo quando diversamente specificato, i contenuti di questa pagina sono concessi in base alla licenza Creative Commons Attribution 4.0, mentre gli esempi di codice sono concessi in base alla licenza Apache 2.0. Per ulteriori dettagli, consulta le norme del sito di Google Developers. Java è un marchio registrato di Oracle e/o delle sue consociate.
Ultimo aggiornamento 2025-04-04 UTC.
Termini
Privacy
Italiano

--- Content from: page_84.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=pl

Modele
Więcej
/
Polski
Zaloguj się
Dokumentacja Gemini API
Jak korzystać z interfejsu API
Książka kucharska
Przegląd
Rozpocznij
Krótkie wprowadzenie
Klucze interfejsu API
Biblioteki
Informacje o wersjach
Zgodność z OpenAI
Forum dla deweloperów
Modele
Wszystkie modele
Ceny
Ograniczenia liczby żądań
Dane do rozliczeń
Uprawnienia
Generowanie tekstu
Generowanie obrazów
Vision
Rozumienie mowy
Długi kontekst
Wykonanie kodu
Uporządkowane dane wyjściowe
Myślenie
Wywoływanie funkcji
rozumienie dokumentów;
Grounding z użyciem wyszukiwarki Google
Dostrajanie
Wektory
Przewodniki
Interfejs API Live
Buforowanie kontekstu
Tworzenie promptów
Liczenie tokenów
Bezpieczeństwo
Dodatkowe materiały
Gemini do badań
Program edukacyjny Gemini
Przypadki użycia
Aplikacje
Rozwiązywanie problemów
Rozwiązywanie problemów z interfejsem API
Rozwiązywanie problemów z AI Studio
Google Workspace
Legal
Warunki korzystania z usługi
Regiony, w których działa ta usługa
Dodatkowe zasady dotyczące użytkowania
Gemini 2.5 Pro Experimental, nasz najbardziej zaawansowany model, jest już dostępny. Więcej informacji
Ta strona została przetłumaczona przez Cloud Translation API.
Switch to English
Strona główna
Gemini API
Modele
Gemini Developer API
Uzyskiwanie klucza interfejsu Gemini API
Uzyskaj klucz interfejsu Gemini API i w kilka minut prześlij pierwsze żądanie interfejsu API.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Poznaj modele
Korzystanie z Gemini w Google AI Studio
2.5 Pro experiment
Nasz najmocniejszy model myślenia z funkcjami do złożonego rozumowania i wiele więcej
2.0 Flashspark
Nasz najnowszy model multimodalny z funkcjami nowej generacji i ulepszonymi możliwościami
2.0 Flash-Lite bolt
Nasz najszybszy i najbardziej ekonomiczny model multimodalny o wysokiej wydajności do zadań o wysokiej częstotliwości
Poznaj interfejs API
Natywne generowanie obrazów
Generuj i edytuj obrazy o wysokiej trafności w ramach Gemini 2.0 Flash.
Dowiedz się więcej o długim kontekście
Przesyłaj miliony tokenów do modeli Gemini i uzyskiwać informacje na podstawie nieuporządkowanych obrazów, filmów i dokumentów.
Generowanie uporządkowanych danych wyjściowych
Ogranicz Gemini do odpowiadania w formacie JSON, czyli formacie danych strukturalnych odpowiednim do przetwarzania automatycznego.
Rozpocznij tworzenie aplikacji z użyciem Gemini API
Rozpocznij
O ile nie stwierdzono inaczej, treść tej strony jest objęta licencją Creative Commons – uznanie autorstwa 4.0, a fragmenty kodu są dostępne na licencji Apache 2.0. Szczegółowe informacje na ten temat zawierają zasady dotyczące witryny Google Developers. Java jest zastrzeżonym znakiem towarowym firmy Oracle i jej podmiotów stowarzyszonych.
Ostatnia aktualizacja: 2025-04-04 UTC.
Warunki
Prywatność
Polski

--- Content from: page_85.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=sq

Modelet
/
Shqip
Identifikohu
Dokumentet e Gemini API
Referenca API
Libër gatimi
Vështrim i përgjithshëm
Filloni
Fillimi i shpejtë
Çelësat API
Bibliotekat
Shënimet e publikimit
Përputhshmëria me OpenAI
Forumi i zhvilluesve
Modelet
Të gjitha modelet
Çmimet
Kufijtë e tarifave
Informacioni i faturimit
aftësitë
Gjenerimi i tekstit
Gjenerimi i imazhit
Vizioni
Kuptimi audio
Konteksti i gjatë
Ekzekutimi i kodit
Prodhimi i strukturuar
duke menduar
Thirrja e funksionit
Kuptimi i dokumentit
Tokëzimi me Google Search
Rregullimi i imët
Embeddings
Udhëzues
API e drejtpërdrejtë
Memoria e kontekstit
Inxhinieri e shpejtë
Numërimi i shenjave
Siguria
Burime shtesë
Binjakët për Kërkime
Programi Akademik Binjakët
Rastet e përdorimit
Aplikacionet
Zgjidhja e problemeve
Zgjidhja e problemeve të API
Zgjidhja e problemeve të AI Studio
Google Workspace
Ligjore
Kushtet e shërbimit
Rajonet e disponueshme
Politika shtesë të përdorimit
Gemini 2.5 Pro Experimental, modeli ynë më i avancuar, tani është në dispozicion! Mësoni më shumë
Kjo faqe është përkthyer nga Cloud Translation API.
Switch to English
Faqja kryesore
Gemini API
Modelet
Gemini Developer API
Merrni një çelës API Gemini
Merrni një çelës Gemini API dhe bëni kërkesën tuaj të parë API në pak minuta.
Python
JavaScript
PUSHIMI
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Njihuni me modelet
Përdorni Gemini në Google AI Studio
experiment 2.5 Pro
Modeli ynë më i fuqishëm i të menduarit me veçori për arsyetim kompleks dhe shumë më tepër
2.0 Blic spark
Modeli ynë më i ri multimodal, me karakteristika të gjeneratës së ardhshme dhe aftësi të përmirësuara
Bulon 2.0 Flash- bolt
Modeli ynë multimodal më i shpejtë dhe më ekonomik me performancë të shkëlqyer për detyra me frekuencë të lartë
Eksploroni API-në
Gjenerimi i imazhit vendas
Gjeneroni dhe modifikoni imazhe shumë kontekstuale në mënyrë origjinale me Gemini 2.0 Flash.
Eksploroni kontekstin e gjatë
Futni miliona argumente në modelet e Gemini dhe nxirrni të kuptuarit nga imazhet, videot dhe dokumentet e pastrukturuara.
Gjeneroni rezultate të strukturuara
Kufizoni Binjakët të përgjigjet me JSON, një format i strukturuar i të dhënave i përshtatshëm për përpunim të automatizuar.
Filloni të ndërtoni me Gemini API
Filloni
Përveçse siç përcaktohet ndryshe, përmbajtja e kësaj faqeje është e licencuar sipas licencës së atribuimit 4.0 të Creative Commons dhe kampionët e kodit janë licencuar sipas licencës së Apache 2.0. Për detaje, shiko Politikat e sajtit të Google Developers. Java është një markë tregtare e regjistruar e Oracle dhe/ose filialeve të tij.
Përditësimi i fundit: 2025-04-04 UTC.
Kushtet
Privatësia
Shqip

--- Content from: page_86.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=vi

Mô hình
/
Tiếng Việt
Đăng nhập
Tài liệu về Gemini API
Tài liệu tham khảo API
Sổ tay nấu ăn
Tổng quan
Bắt đầu
Bắt đầu nhanh
Khóa API
Thư viện
Ghi chú phát hành
Khả năng tương thích với OpenAI
Diễn đàn dành cho nhà phát triển
Mô hình
Tất cả mẫu xe
Mức giá
Giới hạn số lượng yêu cầu
Thông tin về việc lập hóa đơn
Chức năng
Tạo văn bản
Tạo hình ảnh
Vision
Hiểu âm thanh
Ngữ cảnh dài
Thực thi mã
Kết quả có cấu trúc
Đang suy nghĩ
Gọi hàm
Hiểu tài liệu
Tìm hiểu thông tin cơ bản trên Google Tìm kiếm
Tinh chỉnh
Nhúng
Hướng dẫn
API trực tiếp
Lưu ngữ cảnh vào bộ nhớ đệm
Kỹ thuật gợi ý
Tính số lượng mã thông báo
An toàn
Tài nguyên khác
Gemini cho nghiên cứu
Chương trình học thuật của Gemini
Trường hợp sử dụng
Ứng dụng
Khắc phục sự cố
Khắc phục sự cố API
Khắc phục sự cố với AI Studio
Google Workspace
Pháp lý
Điều khoản dịch vụ
Khu vực khả dụng
Các chính sách khác về việc sử dụng
Gemini 2.5 Pro Experimental, mô hình tiên tiến nhất của chúng tôi, hiện đã ra mắt! Tìm hiểu thêm
Trang này được dịch bởi Cloud Translation API.
Switch to English
Trang chủ
Gemini API
Mô hình
API dành cho nhà phát triển Gemini
Lấy khoá Gemini API
Nhận khoá API Gemini và tạo yêu cầu API đầu tiên trong vài phút.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Giới thiệu về các mô hình
Sử dụng Gemini trong Google AI Studio
2.5 Pro experiment
Mô hình tư duy mạnh mẽ nhất của chúng tôi với các tính năng cho hoạt động suy luận phức tạp và nhiều tính năng khác
2.0 Flash spark
Mô hình đa phương thức mới nhất của chúng tôi, với các tính năng thế hệ mới và khả năng cải tiến
2.0 Flash-Lite bolt
Mô hình đa phương thức nhanh nhất và tiết kiệm chi phí nhất của chúng tôi, với hiệu suất cao cho các tác vụ có tần suất cao
Khám phá API
Tạo hình ảnh gốc
Tạo và chỉnh sửa hình ảnh có tính ngữ cảnh cao ngay trong Gemini 2.0 Flash.
Khám phá ngữ cảnh dài
Nhập hàng triệu mã thông báo vào các mô hình Gemini và hiểu được hình ảnh, video và tài liệu không có cấu trúc.
Tạo đầu ra có cấu trúc
Ràng buộc Gemini phản hồi bằng JSON, một định dạng dữ liệu có cấu trúc phù hợp để xử lý tự động.
Bắt đầu xây dựng bằng Gemini API
Bắt đầu
Trừ phi có lưu ý khác, nội dung của trang này được cấp phép theo Giấy phép ghi nhận tác giả 4.0 của Creative Commons và các mẫu mã lập trình được cấp phép theo Giấy phép Apache 2.0. Để biết thông tin chi tiết, vui lòng tham khảo Chính sách trang web của Google Developers. Java là nhãn hiệu đã đăng ký của Oracle và/hoặc các đơn vị liên kết với Oracle.
Cập nhật lần gần đây nhất: 2025-04-04 UTC.
Điều khoản
Quyền riêng tư
Tiếng Việt

--- Content from: page_87.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=tr

Modeller
/
Türkçe
Oturum aç
Gemini API belgeleri
API Referansı
Tarif Defteri
Genel bakış
Başlama
Hızlı Başlangıç
API anahtarları
Kütüphaneler
Sürüm notları
OpenAI uyumluluğu
Geliştirici forumu
Modeller
Tüm modeller
Fiyatlandırma
Hız sınırları
Fatura bilgisi
İşlemler
Metin oluşturma
Resim üretimi
Vision
Sesleri anlama
Uzun bağlam
Kod yürütme
Yapılandırılmış çıkış
Düşünüyorum
İşlev çağırma
Belge anlama
Google Arama temeli
İnce ayar
Yerleşimler
Rehberler
Canlı API
Bağlamı önbelleğe alma
Hızlı yanıt mühendisliği
Jeton sayımı
Güvenlik
Ek kaynaklar
Araştırma için Gemini
Gemini Akademik Programı
Kullanım örnekleri
Uygulamalar
Sorun giderme
API sorunlarını giderme
AI Studio ile ilgili sorunları giderme
Google Workspace
Hukuk
Hizmet şartları
Kullanılabildiği bölgeler
Ek kullanım politikaları
En gelişmiş modelimiz Gemini 2.5 Pro Experimental kullanıma sunuldu. Daha fazla bilgi
Bu sayfa, Cloud Translation API ile çevrilmiştir.
Switch to English
Ana Sayfa
Gemini API
Modeller
Gemini Developer API
Gemini API anahtarı alma
Gemini API anahtarı edinin ve ilk API isteğinizi birkaç dakika içinde gönderin.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Modellerle tanışın
Google AI Studio'da Gemini'yi kullanma
2.5 Pro experiment
Karmaşık akıl yürütme ve daha pek çok özellik içeren en güçlü düşünme modelimiz
2.0 Flash spark
Yeni nesil özellikleri ve gelişmiş özellikleri olan en yeni çok modlu modelimiz
2.0 Flash-Lite bolt
Yüksek sıklıktaki görevler için mükemmel performans sunan en hızlı ve en uygun maliyetli çok modlu modelimiz
API'yi keşfetme
Yerel Görüntü Üretme
Gemini 2.0 Flash ile yerel olarak yüksek bağlama dayalı resimler oluşturun ve düzenleyin.
Uzun bağlamı keşfetme
Gemini modellerine milyonlarca jeton girin ve yapılandırılmamış resimlerden, videolardan ve dokümanlardan bilgi edinin.
Yapılandırılmış çıkışlar oluşturma
Gemini'yi, otomatik işlemeye uygun yapılandırılmış bir veri biçimi olan JSON ile yanıt vermeye zorlama.
Gemini API ile uygulama geliştirmeye başlama
Başlayın
Aksi belirtilmediği sürece bu sayfanın içeriği Creative Commons Atıf 4.0 Lisansı altında ve kod örnekleri Apache 2.0 Lisansı altında lisanslanmıştır. Ayrıntılı bilgi için Google Developers Site Politikaları'na göz atın. Java, Oracle ve/veya satış ortaklarının tescilli ticari markasıdır.
Son güncelleme tarihi: 2025-04-04 UTC.
Şartlar
Gizlilik
Türkçe

--- Content from: page_88.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=ru

Модели
Ещё
/
Русский
Войти
Документация по API Gemini
Документация по API
Кулинарная книга
Обзор
Начать
Краткое руководство
ключи API
Библиотеки
Примечания к выпускам
Совместимость с OpenAI
Форум разработчиков
Модели
Все модели
Цена
Ограничения ставок
Платежная информация
Возможности
Генерация текста
Генерация изображения
Зрение
Понимание звука
Длинный контекст
Выполнение кода
Структурированный вывод
мышление
Вызов функции
Понимание документа
Заземление с помощью Google Поиска
Тонкая настройка
Вложения
Руководства
Живой API
Кэширование контекста
Оперативное проектирование
Подсчет токенов
Безопасность
Дополнительные ресурсы
Близнецы для исследований
Академическая программа Близнецов
Примеры использования
Приложения
Устранение неполадок
Устранение неполадок API
Устранение неполадок AI Studio
Google Workspace
Юридический
Условия использования
Доступные регионы
Дополнительные политики использования
Gemini 2.5 Pro Experimental, наша самая совершенная модель, уже доступна! Узнать больше
Эта страница переведена с помощью Cloud Translation API.
Switch to English
Главная
Gemini API
Модели
API-интерфейс разработчика Gemini
Получите ключ API Gemini
Получите ключ API Gemini и сделайте свой первый запрос API за считанные минуты.
Питон
JavaScript
ОТДЫХ
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
Познакомьтесь с моделями
Используйте Gemini в Google AI Studio
2.5 Профессиональный experiment
Наша самая мощная модель мышления с функциями для сложных рассуждений и многим другим.
2.0 Вспышка spark
Наша новейшая мультимодальная модель с функциями нового поколения и улучшенными возможностями.
2.0 bolt Flash-Lite
Наша самая быстрая и экономичная мультимодальная модель с отличной производительностью для высокочастотных задач.
Изучите API
Генерация собственных изображений
Создавайте и редактируйте контекстно-зависимые изображения прямо с помощью Gemini 2.0 Flash.
Исследуйте длинный контекст
Вводите миллионы токенов в модели Gemini и извлекайте информацию из неструктурированных изображений, видео и документов.
Генерация структурированных результатов
Заставьте Gemini отвечать в формате JSON — структурированном формате данных, подходящем для автоматической обработки.
Начните разработку с помощью Gemini API
Начать
Если не указано иное, контент на этой странице предоставляется по лицензии Creative Commons "С указанием авторства 4.0", а примеры кода – по лицензии Apache 2.0. Подробнее об этом написано в правилах сайта. Java – это зарегистрированный товарный знак корпорации Oracle и ее аффилированных лиц.
Последнее обновление: 2025-04-04 UTC.
Условия использования
Конфиденциальность
Русский

--- Content from: page_89.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=he

דגמים
עוד
/
עברית
היכנס
מסמכי העזרה של Gemini API
מקורות ל-API
ספר המתכונים
סקירה כללית
מתחילים
מדריך למתחילים
מפתחות API
ספריות
נתוני גרסה
תאימות ל-OpenAI
פורום למפתחים
דגמים
כל הדגמים
תמחור
הגבלות קצב של יצירת בקשות
פרטי החיוב
יכולות
יצירת טקסט
יצירת תמונות
Vision
הבנת אודיו
הקשר ארוך
ביצוע קוד
פלט מובנה
מעבד
הפעלת פונקציה
הבנת מסמכים
התבססות על חיפוש Google
כוונון עדין
הטמעות (embeddings)
מדריכים
ממשק API פעיל
שמירת הקשר במטמון
הנדסת פרומפטים
ספירת אסימונים
סייפטי
מקורות מידע נוספים
Gemini למחקר
תוכנית Gemini Academic
תרחישים לדוגמה
אפליקציות
פתרון בעיות
פתרון בעיות ב-API
פתרון בעיות ב-AI Studio
Google Workspace
משפטי
תנאים והגבלות
אזורים זמינים
כללי מדיניות שימוש נוספים
Gemini 2.5 Pro Experimental, המודל המתקדם ביותר שלנו, זמין עכשיו! מידע נוסף
דף זה תורגם על ידי Cloud Translation API.
Switch to English
דף הבית
Gemini API
דגמים
Gemini Developer API
קבלת מפתח Gemini API
קבלת מפתח Gemini API ושליחת הבקשה הראשונה ל-API תוך דקות ספורות.
Python
JavaScript
REST
google import genai

  genai.Client(api_key="
YOUR_API_KEY")

  client.models.generate_content(
    "gemini-2.0-flash",
    contents="Explain how AI works",


response.text)
הכירו את המודלים
שימוש ב-Gemini ב-Google AI Studio
2.5 Pro experiment
מודל החשיבה החזק ביותר שלנו, עם תכונות להסקת מסקנות מורכבות ועוד
2.0 Flash spark
המודל החדש ביותר שלנו עם תכונות מהדור הבא ויכולות משופרות
2.0 Flash-Lite bolt
המודל המהיר והחסכוני ביותר שלנו שמשתמש במגוון סוגי נתונים, עם ביצועים מעולים למשימות בתדירות גבוהה
סקירה כללית של ה-API
יצירת קובצי אימג' מקומיים
יצירת תמונות שמתבססות על הקשר ועריכתן באופן מקורי באמצעות Gemini 2.0 Flash.
חלון הקשר ארוך
להזין מיליוני אסימונים למודלים של Gemini ולהפיק הבנה מתמונות, מסרטונים וממסמכים לא מובנים.
יצירת פלט מובנה
להגביל את Gemini כך שתגיב ב-JSON, פורמט של נתונים מובְנים שמתאים לעיבוד אוטומטי.
תחילת העבודה עם Gemini API
שנתחיל?
אלא אם צוין אחרת, התוכן של דף זה הוא ברישיון Creative Commons Attribution 4.0 ודוגמאות הקוד הן ברישיון Apache 2.0. לפרטים, ניתן לעיין במדיניות האתר Google Developers. Java הוא סימן מסחרי רשום של חברת Oracle ו/או של השותפים העצמאיים שלה.
עדכון אחרון: 2025-04-04 (שעון UTC).
תנאים
פרטיות
עברית

--- Content from: page_90.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=ar

الطرُز
المزيد
/
العربيّة
تسجيل الدخول
مستندات Gemini API
مرجع حول API
كتاب الطبخ
نظرة عامة
البدء
التشغيل السريع
مفاتيح واجهة برمجة التطبيقات
المكتبات
ملاحظات حول الإصدار
التوافق مع OpenAI
منتدى المطوّرين
الطرُز
كل الطرز
الأسعار
حدود المعدل
معلومات الفوترة
الإمكانات
إنشاء النص
إنشاء الصور
Vision
فهم الصوت
سياق طويل
تنفيذ الرمز البرمجي
إخراج منظَّم
جارٍ التفكير
استدعاء الدالة
فهم المستندات
الأساسيات باستخدام "بحث Google"
التوليف الدقيق
عمليات التضمين
الأدلة
واجهة برمجة التطبيقات للبث المباشر
التخزين المؤقت للسياق
هندسة الطلبات
احتساب الرموز المميّزة
دفاع
مصادر إضافية
‫Gemini لأغراض البحث
البرنامج الأكاديمي في Gemini
حالات الاستخدام
التطبيقات
تحديد المشاكل وحلّها
تحديد المشاكل في واجهة برمجة التطبيقات وحلّها
تحديد المشاكل وحلّها في AI Studio
Google Workspace
شؤون قانونية
بنود الخدمة
المناطق المتاحة
سياسات الاستخدام الإضافية
أصبح الإصدار التجريبي من Gemini 2.5 Pro، وهو النموذج الأكثر تطورًا لدينا، متاحًا الآن. مزيد من المعلومات
تمت ترجمة هذه الصفحة بواسطة Cloud Translation API.
Switch to English
الصفحة الرئيسية
Gemini API
الطرُز
Gemini Developer API
الحصول على مفتاح واجهة برمجة التطبيقات Gemini API
يمكنك الحصول على مفتاح واجهة برمجة التطبيقات Gemini وتقديم طلبك الأول لواجهة برمجة التطبيقات في دقائق.
Python
JavaScript
REST
google import genai

  genai.Client(api_key="
YOUR_API_KEY")

  client.models.generate_content(
    "gemini-2.0-flash",
    contents="Explain how AI works",


response.text)
التعرّف على النماذج
استخدام Gemini في Google AI Studio
2.5 Pro experiment
نموذج التفكير الأكثر فعالية لدينا مع ميزات للاستدلال المعقد وغير ذلك الكثير
2.0 Flash spark
أحدث نموذج متعدّد الوسائط لدينا، مع ميزات الجيل التالي وإمكانات محسَّنة
2.0 Flash-Lite bolt
أسرع نموذج متعدد الوسائط وأكثره فعالية من حيث التكلفة، ويحقّق أداءً رائعًا للمهام ذات معدّل التكرار المرتفع
استكشاف واجهة برمجة التطبيقات
إنشاء الصور الأصلية
أنشئ صورًا ذات سياق عالٍ وعدِّلها بشكلٍ أصلي باستخدام Gemini 2.0 Flash.
استكشاف السياق الطويل
أدخِل ملايين الرموز إلى نماذج Gemini واستخرِج معلومات من الصور والفيديوهات والمستندات غير المهيكلة.
إنشاء نتائج منظَّمة
يمكنك تقييد Gemini للردّ باستخدام تنسيق JSON، وهو تنسيق بيانات منظَّمة مناسب للمعالجة المبرمَجة.
بدء إنشاء التطبيقات باستخدام Gemini API
البدء
إنّ محتوى هذه الصفحة مرخّص بموجب ترخيص Creative Commons Attribution 4.0 ما لم يُنصّ على خلاف ذلك، ونماذج الرموز مرخّصة بموجب ترخيص Apache 2.0. للاطّلاع على التفاصيل، يُرجى مراجعة سياسات موقع Google Developers. إنّ Java هي علامة تجارية مسجَّلة لشركة Oracle و/أو شركائها التابعين.
تاريخ التعديل الأخير: 2025-04-04 (حسب التوقيت العالمي المتفَّق عليه)
البنود
الخصوصية
العربيّة

--- Content from: page_91.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=fa

مدل ها
بیشتر
/
فارسی
ورود به برنامه
اسناد Gemini API
مرجع API
کتاب آشپزی
نمای کلی
شروع به کار
شروع سریع
کلیدهای API
کتابخانه ها
یادداشت های انتشار
سازگاری OpenAI
انجمن توسعه دهندگان
مدل ها
همه مدل ها
قیمت‌گذاری
محدودیت های نرخ
اطلاعات صورتحساب
قابلیت ها
تولید متن
تولید تصویر
چشم انداز
درک صوتی
زمینه طولانی
اجرای کد
خروجی ساختاریافته
فکر کردن
فراخوانی تابع
درک سند
زمینه سازی با جستجوی گوگل
تنظیم دقیق
جاسازی ها
راهنما
Live API
ذخیره‌سازی متن، ذخیره‌سازی متن
مهندسی سریع
رمز شماری
ایمنی
منابع اضافی
جمینی برای تحقیق
برنامه آکادمیک جمینی
موارد استفاده کنید
برنامه های کاربردی
عیب یابی
عیب یابی API
عیب یابی AI Studio
Google Workspace
مجاز
شرایط استفاده از خدمات
مناطق در دسترس
سیاست های استفاده اضافی
Gemini 2.5 Pro Experimental، پیشرفته ترین مدل ما، اکنون در دسترس است! بیشتر بدانید
این صفحه به‌وسیله Cloud Translation API ترجمه شده است.
Switch to English
صفحه اصلی
Gemini API
مدل ها
Gemini Developer API
یک کلید API Gemini دریافت کنید
یک کلید Gemini API دریافت کنید و اولین درخواست API خود را در عرض چند دقیقه انجام دهید.
پایتون
جاوا اسکریپت
استراحت
google import genai

  genai.Client(api_key="
YOUR_API_KEY")

  client.models.generate_content(
    "gemini-2.0-flash",
    contents="Explain how AI works",


response.text)
با مدل ها آشنا شوید
از Gemini در استودیوی هوش مصنوعی گوگل استفاده کنید
experiment 2.5 حرفه ای
قدرتمندترین مدل تفکر ما با ویژگی‌هایی برای استدلال پیچیده و موارد دیگر
2.0 spark فلش
جدیدترین مدل چندوجهی ما، با ویژگی های نسل بعدی و قابلیت های بهبود یافته
bolt 2.0 Flash-Lite
سریع ترین و مقرون به صرفه ترین مدل چند وجهی ما با عملکرد عالی برای کارهای با فرکانس بالا
API را کاوش کنید
نسل تصویر بومی
با Gemini 2.0 Flash تصاویر بسیار متنی را به صورت بومی تولید و ویرایش کنید.
زمینه طولانی را کاوش کنید
میلیون‌ها نشانه را به مدل‌های Gemini وارد کنید و از تصاویر، ویدیوها و اسناد بدون ساختار درک کنید.
خروجی های ساخت یافته تولید کنید
Gemini را محدود کنید تا با JSON، یک قالب داده ساختاریافته مناسب برای پردازش خودکار، پاسخ دهد.
ساختن را با Gemini API شروع کنید
شروع کنید
جز در مواردی که غیر از این ذکر شده باشد،‌محتوای این صفحه تحت مجوز Creative Commons Attribution 4.0 License است. نمونه کدها نیز دارای مجوز Apache 2.0 License است. برای اطلاع از جزئیات، به خطمشی‌های سایت Google Developers مراجعه کنید. جاوا علامت تجاری ثبت‌شده Oracle و/یا شرکت‌های وابسته به آن است.
تاریخ آخرین به‌روزرسانی 2025-04-04 به‌وقت ساعت هماهنگ جهانی.
شرایط
حریم خصوصی
فارسی

--- Content from: page_92.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=hi

मॉडल
ज़्यादा
/
हिंदी
प्रवेश करें
Gemini API के दस्तावेज़
एपीआई का संदर्भ
कुकबुक
खास जानकारी
शुरू करना
क्विकस्टार्ट
एपीआई कुंजियां
पुस्तकालय
रिलीज़ टिप्पणियां
OpenAI की सुविधा के साथ काम करता है
डेवलपर फ़ोरम
मॉडल
सभी मॉडल
कीमत तय करना
दर की सीमाएं
बिलिंग की जानकारी
मिलने वाली अनुमतियां
टेक्स्ट जनरेट करना
Image generation
Vision
ऑडियो को समझना
लंबा संदर्भ
कोड लागू करें
स्ट्रक्चर्ड आउटपुट
Gemini जवाब ढूँढ रहा है
फ़ंक्शन कॉलिंग
दस्तावेज़ को समझना
Google Search के आधार पर जानकारी देना
फ़ाइन-ट्यूनिंग
एम्बेड करना
गाइड
लाइव एपीआई
कॉन्टेक्स्ट कैश मेमोरी
प्रॉम्प्ट इंजीनियरिंग
टोकन की गिनती
सुरक्षा
अन्य संसाधन
Gemini for Research
Gemini Academic Program
इस्तेमाल के उदाहरण
ऐप्स
समस्या का हल
एपीआई से जुड़ी समस्या हल करना
AI Studio से जुड़ी समस्याएं हल करना
Google Workspace
कानूनी
सेवा की शर्तें
उपलब्ध क्षेत्र
इस्तेमाल से जुड़ी अन्य नीतियां
हमारा सबसे बेहतर मॉडल, Gemini 2.5 Pro Experimental अब उपलब्ध है! ज़्यादा जानें
इस पेज का अनुवाद Cloud Translation API से किया गया है.
Switch to English
होम पेज
Gemini API
मॉडल
Gemini Developer API
Gemini API पासकोड पाना
Gemini API पासकोड पाएं और कुछ ही मिनटों में अपना पहला एपीआई अनुरोध करें.
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
मॉडल के बारे में जानकारी
Google AI Studio में Gemini का इस्तेमाल करना
2.5 Pro experiment
हमारा सबसे बेहतरीन थिंकिंग मॉडल, जिसमें मुश्किल रीज़निंग और अन्य सुविधाएं शामिल हैं
2.0 Flash spark
अगली पीढ़ी की सुविधाओं और बेहतर क्षमताओं वाला, हमारा नया मल्टीमोडल मॉडल
2.0 Flash-Lite bolt
बार-बार होने वाले टास्क के लिए, सबसे तेज़ और किफ़ायती मल्टिमोडल मॉडल, जो बेहतर परफ़ॉर्म करता है
एपीआई के बारे में जानकारी
नेटिव इमेज जनरेशन
Gemini 2.0 Flash की मदद से, कॉन्टेक्स्ट के हिसाब से इमेज जनरेट करें और उनमें बदलाव करें.
लंबे कॉन्टेक्स्ट को एक्सप्लोर करना
Gemini मॉडल में लाखों टोकन डालें और बिना स्ट्रक्चर वाली इमेज, वीडियो, और दस्तावेज़ों से जानकारी पाएं.
स्ट्रक्चर्ड आउटपुट जनरेट करना
Gemini को JSON फ़ॉर्मैट में जवाब देने के लिए कहें. यह स्ट्रक्चर्ड डेटा का एक ऐसा फ़ॉर्मैट है जो अपने-आप प्रोसेस होने के लिए सही है.
Gemini API का इस्तेमाल करके ऐप्लिकेशन बनाना
शुरू करें
जब तक कुछ अलग से न बताया जाए, तब तक इस पेज की सामग्री को Creative Commons Attribution 4.0 License के तहत और कोड के नमूनों को Apache 2.0 License के तहत लाइसेंस मिला है. ज़्यादा जानकारी के लिए, Google Developers साइट नीतियां देखें. Oracle और/या इससे जुड़ी हुई कंपनियों का, Java एक रजिस्टर किया हुआ ट्रेडमार्क है.
आखिरी बार 2025-04-04 (UTC) को अपडेट किया गया.
शर्तें
निजता
हिंदी

--- Content from: page_93.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=bn

মডেল
আরও দেখুন
/
বাংলা
সাইন-ইন করুন
Gemini API ডক্স
API রেফারেন্স
রান্নার বই
ওভারভিউ
শুরু করুন
দ্রুত শুরু
API কী
লাইব্রেরি
রিলিজ নোট
OpenAI সামঞ্জস্য
বিকাশকারী ফোরাম
মডেল
সব মডেল
দাম
হারের সীমা
বিলিং তথ্য
ক্ষমতা
পাঠ্য প্রজন্ম
ইমেজ প্রজন্ম
দৃষ্টি
অডিও বোঝার
দীর্ঘ প্রসঙ্গ
কোড এক্সিকিউশন
স্ট্রাকচার্ড আউটপুট
ভাবছেন
ফাংশন কলিং
নথি বোঝার
Google অনুসন্ধানের সাথে গ্রাউন্ডিং
ফাইন-টিউনিং
এমবেডিং
নির্দেশিকা
লাইভ API
প্রসঙ্গ ক্যাশিং
প্রম্পট ইঞ্জিনিয়ারিং
টোকেন গণনা
নিরাপত্তা
অতিরিক্ত সম্পদ
গবেষণার জন্য মিথুন
মিথুন একাডেমিক প্রোগ্রাম
ব্যবহারের ক্ষেত্রে
অ্যাপ্লিকেশন
সমস্যা সমাধান
API সমস্যা সমাধান
এআই স্টুডিও সমস্যা সমাধান
Google Workspace
আইনি
সেবা পাবার শর্ত
উপলব্ধ অঞ্চল
অতিরিক্ত ব্যবহার নীতি
Gemini 2.5 Pro পরীক্ষামূলক, আমাদের সবচেয়ে উন্নত মডেল, এখন উপলব্ধ! আরও জানুন
এই পৃষ্ঠাটি Cloud Translation API অনুবাদ করেছে।
Switch to English
হোম
Gemini API
মডেল
জেমিনি ডেভেলপার API
একটি Gemini API কী পান
একটি Gemini API কী পান এবং মিনিটের মধ্যে আপনার প্রথম API অনুরোধ করুন৷
পাইথন
জাভাস্ক্রিপ্ট
বিশ্রাম
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
মডেলদের সাথে দেখা করুন
গুগল এআই স্টুডিওতে মিথুন ব্যবহার করুন
2.5 প্রো experiment
জটিল যুক্তি এবং আরও অনেক কিছুর জন্য বৈশিষ্ট্য সহ আমাদের সবচেয়ে শক্তিশালী চিন্তা মডেল
2.0 ফ্ল্যাশ spark
আমাদের নতুন মাল্টিমোডাল মডেল, পরবর্তী প্রজন্মের বৈশিষ্ট্য এবং উন্নত ক্ষমতা সহ
2.0 ফ্ল্যাশ-লাইট bolt
উচ্চ-ফ্রিকোয়েন্সি কাজের জন্য দুর্দান্ত পারফরম্যান্স সহ আমাদের দ্রুততম এবং সবচেয়ে ব্যয়-দক্ষ মাল্টিমোডাল মডেল
API অন্বেষণ করুন
নেটিভ ইমেজ জেনারেশন
জেমিনি 2.0 ফ্ল্যাশের সাথে নেটিভভাবে অত্যন্ত প্রাসঙ্গিক ছবি তৈরি এবং সম্পাদনা করুন।
দীর্ঘ প্রসঙ্গ অন্বেষণ
জেমিনি মডেলগুলিতে লক্ষ লক্ষ টোকেন ইনপুট করুন এবং অসংগঠিত ছবি, ভিডিও এবং নথি থেকে বোঝার চেষ্টা করুন৷
কাঠামোগত আউটপুট তৈরি করুন
স্বয়ংক্রিয় প্রক্রিয়াকরণের জন্য উপযুক্ত একটি স্ট্রাকচার্ড ডেটা ফর্ম্যাট JSON-এর সাথে প্রতিক্রিয়া জানাতে জেমিনিকে সীমাবদ্ধ করুন।
Gemini API দিয়ে বিল্ডিং শুরু করুন
শুরু করুন
অন্য কিছু উল্লেখ না করা থাকলে, এই পৃষ্ঠার কন্টেন্ট Creative Commons Attribution 4.0 License-এর অধীনে এবং কোডের নমুনাগুলি Apache 2.0 License-এর অধীনে লাইসেন্স প্রাপ্ত। আরও জানতে, Google Developers সাইট নীতি দেখুন। Java হল Oracle এবং/অথবা তার অ্যাফিলিয়েট সংস্থার রেজিস্টার্ড ট্রেডমার্ক।
2025-04-04 UTC-তে শেষবার আপডেট করা হয়েছে।
শর্তাবলী
গোপনীয়তা
বাংলা

--- Content from: page_94.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=th

โมเดล
เพิ่มเติม
/
ภาษาไทย
ลงชื่อเข้าใช้
เอกสารประกอบ Gemini API
ข้อมูลอ้างอิงของ API
ตำราอาหาร
ภาพรวม
เริ่มใช้งาน
คู่มือเริ่มใช้งานฉบับย่อ
คีย์ API
ห้องสมุด
บันทึกประจำรุ่น
ความเข้ากันได้กับ OpenAI
ฟอรัมสำหรับนักพัฒนาแอป
โมเดล
ทุกรุ่น
การกำหนดราคา
ขีดจำกัดอัตรา
ข้อมูลสำหรับการเรียกเก็บเงิน
ความสามารถ
การสร้างข้อความ
การสร้างรูปภาพ
Vision
ความเข้าใจเกี่ยวกับเสียง
บริบทแบบยาว
การเรียกใช้โค้ด
เอาต์พุตที่มีโครงสร้าง
กำลังคิด
กำลังเรียกฟังก์ชัน
การทำความเข้าใจเอกสาร
พื้นฐานด้วย Google Search
การปรับแต่ง
การฝัง
คำแนะนำ
API ที่เผยแพร่อยู่
การแคชบริบท
บริการวิศวกรรมทันที
การนับโทเค็น
ความปลอดภัย
แหล่งข้อมูลเพิ่มเติม
Gemini สำหรับงานวิจัย
โปรแกรมการศึกษาของ Gemini
กรณีการใช้งาน
แอปพลิเคชัน
การแก้ปัญหา
การแก้ปัญหา API
การแก้ปัญหาเกี่ยวกับ AI Studio
Google Workspace
กฎหมาย
ข้อกำหนดในการให้บริการ
ภูมิภาคที่สามารถใช้บริการได้
นโยบายการใช้งานเพิ่มเติม
Gemini 2.5 Pro Experimental ซึ่งเป็นโมเดลที่ล้ำสมัยที่สุดของเราพร้อมให้ใช้งานแล้ว ดูข้อมูลเพิ่มเติม
หน้านี้ได้รับการแปลโดย Cloud Translation API
Switch to English
หน้าแรก
Gemini API
โมเดล
Gemini Developer API
รับคีย์ Gemini API
รับคีย์ Gemini API และส่งคําขอ API รายการแรกได้ในไม่กี่นาที
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
พบกับโมเดล
ใช้ Gemini ใน Google AI Studio
2.5 Pro experiment
โมเดลการคิดที่มีประสิทธิภาพสูงสุดของเราพร้อมฟีเจอร์สําหรับการให้เหตุผลที่ซับซ้อนและอื่นๆ อีกมากมาย
2.0 Flash spark
โมเดลแบบหลายรูปแบบใหม่ล่าสุดของเราที่มีฟีเจอร์รุ่นถัดไปและความสามารถที่ปรับปรุงแล้ว
2.0 Flash-Lite bolt
โมเดลมัลติโมดัลที่เร็วที่สุดและคุ้มค่าที่สุดของเราที่มีประสิทธิภาพยอดเยี่ยมสำหรับงานที่มีความถี่สูง
สำรวจ API
การสร้างรูปภาพเนทีฟ
สร้างและแก้ไขรูปภาพที่ตรงตามบริบทสูงได้โดยตรงด้วย Gemini 2.0 Flash
สำรวจบริบทแบบยาว
ป้อนโทเค็นหลายล้านรายการลงในโมเดล Gemini และดึงข้อมูลเชิงลึกจากรูปภาพ วิดีโอ และเอกสารที่ไม่มีโครงสร้าง
สร้างเอาต์พุตที่มีโครงสร้าง
จำกัดให้ Gemini ตอบกลับด้วย JSON ซึ่งเป็นรูปแบบ Structured Data ที่เหมาะสำหรับการประมวลผลอัตโนมัติ
เริ่มสร้างด้วย Gemini API
เริ่มต้นใช้งาน
เนื้อหาของหน้าเว็บนี้ได้รับอนุญาตภายใต้ใบอนุญาตที่ต้องระบุที่มาของครีเอทีฟคอมมอนส์ 4.0 และตัวอย่างโค้ดได้รับอนุญาตภายใต้ใบอนุญาต Apache 2.0 เว้นแต่จะระบุไว้เป็นอย่างอื่น โปรดดูรายละเอียดที่นโยบายเว็บไซต์ Google Developers Java เป็นเครื่องหมายการค้าจดทะเบียนของ Oracle และ/หรือบริษัทในเครือ
อัปเดตล่าสุด 2025-04-04 UTC
ข้อกำหนด
ความเป็นส่วนตัว
ภาษาไทย

--- Content from: page_95.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=zh-cn

模型
更多
/
中文 – 简体
登录
Gemini API 文档
API 参考文档
实战宝典
概览
开始使用
快速入门
API 密钥
库
版本说明
OpenAI 兼容性
开发者论坛
模型
所有模型
价格
速率限制
账单信息
功能
文本生成
图片生成
视觉
音频理解
长上下文
代码执行
结构化输出
做思考状
函数调用
文档理解
使用 Google 搜索建立依据
微调
Embeddings
指南
Live API
上下文缓存
提示工程
令牌计数
安全
其他资源
Gemini for Research
Gemini 学术计划
用例
应用
问题排查
API 问题排查
AI Studio 问题排查
Google Workspace
法律
服务条款
可用区域
其他使用政策
我们最先进的模型 Gemini 2.5 Pro Experimental 现已推出！了解详情
此页面由 Cloud Translation API 翻译。
Switch to English
首页
Gemini API
模型
Gemini Developer API
获取 Gemini API 密钥
只需几分钟，即可获取 Gemini API 密钥并发出第一个 API 请求。
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
认识模型
在 Google AI Studio 中使用 Gemini
2.5 Pro experiment
我们最强大的思考模型，具有复杂推理等多种功能
2.0 Flash spark
我们最新的多模态模型，具有新一代功能和增强型功能
2.0 Flash-Lite bolt
我们最快、最具成本效益的多模态模型，适用于高频率任务，并且性能出色
探索 API
原生图片生成
使用 Gemini 2.0 Flash 原生生成和编辑高度贴合情境的图片。
探索长上下文
向 Gemini 模型输入数百万个令牌，从非结构化图片、视频和文档中提取理解。
生成结构化输出
限制 Gemini 以 JSON 格式（一种适合自动处理的结构化数据格式）进行响应。
开始使用 Gemini API 进行构建
开始使用
如未另行说明，那么本页面中的内容已根据知识共享署名 4.0 许可获得了许可，并且代码示例已根据 Apache 2.0 许可获得了许可。有关详情，请参阅 Google 开发者网站政策。Java 是 Oracle 和/或其关联公司的注册商标。
最后更新时间 (UTC)：2025-04-04。
条款
隐私权政策
中文 – 简体

--- Content from: page_96.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=zh-tw

模型
更多選項
/
中文 – 繁體
登入
Gemini API 說明文件
API 參考資料
教戰手冊
總覽
開始使用
快速入門導覽課程
API 金鑰
程式庫
版本資訊
OpenAI 相容性
開發人員論壇
模型
所有模型
定價
頻率限制
帳單資訊
功能
文字生成
圖像生成
Vision
音訊理解
詳細背景資訊
程式碼執行
結構化輸出內容
思考
函式呼叫
文件解讀
以 Google 搜尋建立基準
微調
嵌入
指南
Live API
內容快取
提示工程
符記計數
安全分
其他資源
Gemini for Research
Gemini 學術計畫
用途
應用程式
疑難排解
API 疑難排解
AI Studio 疑難排解
Google Workspace
Legal
服務條款
可用地區
其他使用政策
我們最先進的模型 Gemini 2.5 Pro 實驗版現已推出！瞭解詳情
本頁面由 Cloud Translation API 翻譯而成。
Switch to English
首頁
Gemini API
模型
Gemini Developer API
取得 Gemini API 金鑰
取得 Gemini API 金鑰，幾分鐘內就能發出第一個 API 要求。
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
認識模型
在 Google AI Studio 中使用 Gemini
2.5 Pro experiment
我們最強大的思考模型，提供複雜推理等多項功能
2.0 Flash spark
最新的多模態模型，提供新一代功能和強化功能
2.0 Flash-Lite bolt
這是我們最快速且最具成本效益的多模態模型，可為高頻率工作提供出色的效能
探索 API
原生圖片產生
使用 Gemini 2.0 Flash 原生生成及編輯高度符合情境的圖片。
探索長脈絡
將數百萬個符記輸入 Gemini 模型，從非結構化圖片、影片和文件中擷取理解資訊。
產生結構化輸出內容
限制 Gemini 以 JSON 回應，這是適合自動處理的結構化資料格式。
開始使用 Gemini API 建構
踏出第一步
除非另有註明，否則本頁面中的內容是採用創用 CC 姓名標示 4.0 授權，程式碼範例則為阿帕契 2.0 授權。詳情請參閱《Google Developers 網站政策》。Java 是 Oracle 和/或其關聯企業的註冊商標。
上次更新時間：2025-04-04 (世界標準時間)。
條款
隱私權
中文 – 繁體

--- Content from: page_97.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=ja

モデル
もっと見る
/
日本語
ログイン
Gemini API のドキュメント
API リファレンス
クックブック
概要
使ってみる
クイックスタート
API キー
ライブラリ
リリースノート
OpenAI の互換性
デベロッパー フォーラム
モデル
すべてのモデル
料金
レート制限
お支払い情報
機能
テキスト生成
画像の生成
ビジョン
音声の理解
長いコンテキスト
コードの実行
構造化出力
考えている
関数呼び出し
ドキュメントの理解
Google 検索によるグラウンディング
ファインチューニング
エンベディング
ガイド
ライブ API
コンテキストのキャッシュ保存
プロンプト エンジニアリング
トークンのカウント
安全性
参考情報
Gemini for Research
Gemini アカデミック プログラム
使用例
アプリケーション
トラブルシューティング
API のトラブルシューティング
AI Studio のトラブルシューティング
Google Workspace
法律
利用規約
利用可能なリージョン
その他の利用ポリシー
Google の最先端モデルである Gemini 2.5 Pro 試験運用版が利用可能になりました。詳細
このページは Cloud Translation API によって翻訳されました。
Switch to English
ホーム
Gemini API
モデル
Gemini Developer API
Gemini API キーを取得する
Gemini API キーを取得して、数分で最初の API リクエストを実行できます。
Python
JavaScript
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
モデルの詳細
Google AI Studio で Gemini を使用する
2.5 Pro experiment
複雑な推論機能などを備えた Google の最も強力な思考モデル
2.0 Flash spark
次世代の機能と強化された機能を備えた最新のマルチモーダル モデル
2.0 Flash-Lite bolt
最も高速で費用対効果の高いマルチモーダル モデル。高頻度のタスクで優れたパフォーマンスを発揮します。
API の確認
ネイティブ画像生成
Gemini 2.0 Flash で、コンテキストに沿った画像をネイティブに生成して編集します。
長いコンテキストを確認する
数百万個のトークンを Gemini モデルに入力し、非構造化の画像、動画、ドキュメントから理解を導き出します。
構造化出力を生成する
自動処理に適した構造化データ形式である JSON で応答するように Gemini を制約します。
Gemini API で構築を開始する
ご利用開始
特に記載のない限り、このページのコンテンツはクリエイティブ・コモンズの表示 4.0 ライセンスにより使用許諾されます。コードサンプルは Apache 2.0 ライセンスにより使用許諾されます。詳しくは、Google Developers サイトのポリシーをご覧ください。Java は Oracle および関連会社の登録商標です。
最終更新日 2025-04-04 UTC。
利用規約
プライバシー
日本語

--- Content from: page_98.txt ---

URL: https://ai.google.dev/gemini-api/docs?hl=ko

모델
더보기
/
한국어
로그인
Gemini API 문서
API 참조
설명서
개요
시작하기
빠른 시작
API 키
라이브러리
출시 노트
OpenAI 호환성
개발자 포럼
모델
모든 모델
가격 책정
비율 제한
결제 정보
기능
텍스트 생성
이미지 생성
비전
오디오 이해
긴 컨텍스트
코드 실행
구조화된 출력
생각 중
함수 호출
문서 이해
Google 검색으로 그라운딩
미세 조정
임베딩
가이드
라이브 API
컨텍스트 캐싱
프롬프트 엔지니어링
토큰 수 계산
안전
추가 리소스
연구를 위한 Gemini
Gemini 학술 프로그램
사용 사례
애플리케이션
문제 해결
API 문제 해결
AI Studio 문제 해결
Google Workspace
법률
서비스 약관
사용 가능한 리전
추가 사용 정책
Google의 최첨단 모델인 Gemini 2.5 Pro Experimental을 사용할 수 있습니다. 자세히 알아보기
이 페이지는 Cloud Translation API를 통해 번역되었습니다.
Switch to English
홈
Gemini API
모델
Gemini Developer API
Gemini API 키 가져오기
Gemini API 키를 가져와 몇 분 만에 첫 번째 API 요청을 실행하세요.
Python
자바스크립트
REST
from google import genai

client = genai.Client(api_key="
YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="Explain how AI works",
)

print(response.text)
모델 만나보기
Google AI 스튜디오에서 Gemini 사용하기
2.5 Pro experiment
복잡한 추론을 위한 기능 등 Google의 가장 강력한 사고 모델
2.0 Flash spark
차세대 기능과 향상된 기능을 갖춘 최신 멀티모달 모델
2.0 Flash-Lite bolt
빈번한 작업에 적합한 우수한 성능을 갖춘 가장 빠르고 비용 효율적인 멀티모달 모델
API 살펴보기
네이티브 이미지 생성
Gemini 2.0 Flash를 사용하여 문맥에 맞는 이미지를 기본적으로 생성하고 수정합니다.
긴 컨텍스트 살펴보기
Gemini 모델에 수백만 개의 토큰을 입력하고 비정형 이미지, 동영상, 문서에서 이해를 도출합니다.
구조화된 출력 생성
자동 처리에 적합한 구조화된 데이터 형식인 JSON으로 응답하도록 Gemini를 제한합니다.
Gemini API로 빌드 시작하기
시작하기
달리 명시되지 않는 한 이 페이지의 콘텐츠에는 Creative Commons Attribution 4.0 라이선스에 따라 라이선스가 부여되며, 코드 샘플에는 Apache 2.0 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 Google Developers 사이트 정책을 참조하세요. 자바는 Oracle 및/또는 Oracle 계열사의 등록 상표입니다.
최종 업데이트: 2025-04-04(UTC)
약관
개인정보처리방침
한국어

